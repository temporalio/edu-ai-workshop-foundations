{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Agentic Loop\n",
    "\n",
    "In this section, we'll explore what an agentic loop is and why it's essential for building reliable, production-ready AI agents.\n",
    "\n",
    "You'll learn:\n",
    "- What makes an AI system \"agentic\"\n",
    "- How the event loop pattern enables autonomous decision-making\n",
    "- Why Temporal is the ideal platform for building durable AI agents\n",
    "- How to observe an agent making real-time decisions\n",
    "\n",
    "This is a **conceptual exploration** with a working demonstration—the focus is on understanding the patterns and principles, not on writing code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Your Notebook\n",
    "\n",
    "Run the following code blocks to install various packages and tools necessary to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mermaid renderer, run at the beginning to setup rendering of diagrams\n",
    "import base64\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def render_mermaid(graph_definition):\n",
    "    \"\"\"\n",
    "    Renders a Mermaid diagram in Google Colab using mermaid.ink.\n",
    "\n",
    "    Args:\n",
    "        graph_definition (str): The Mermaid diagram code (e.g., \"graph LR; A-->B;\").\n",
    "    \"\"\"\n",
    "    graph_bytes = graph_definition.encode(\"ascii\")\n",
    "    base64_bytes = base64.b64encode(graph_bytes)\n",
    "    base64_string = base64_bytes.decode(\"ascii\")\n",
    "    display(Image(url=\"https://mermaid.ink/img/\" + base64_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So far in this workshop...\n",
    "\n",
    "In the previous sections of this workshop, we've built a research application that:\n",
    "\n",
    "1. **Accepts user input** - Takes a research topic from the user\n",
    "2. **Calls the LLM for research** - Uses an LLM to generate research content\n",
    "3. **Generates PDF** - Creates a formatted output document\n",
    "4. **Returns success/failure** - Provides execution results\n",
    "5. **Accepts Signals and Queries** - Enables external interaction with running Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIExSCiAgICBBW1VzZXIgY2FsbHMgTExNXQogICAgc2lnbmFsc1tzaWduYWxzXSAtLT4gcHJvY2Vzc1sgXQogICAgQSAtLT4gcHJvY2VzcwogICAgcHJvY2VzcyAtLT4gQltHZW5lcmF0aW5nIGEgUERGIGZyb20gTExNIHJlc3BvbnNlXQogICAgcXVlcmllc1txdWVyaWVzXSAtLT4gcHJvY2Vzcwo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diagram = \"\"\"\n",
    "graph LR\n",
    "    A[User calls LLM]\n",
    "    signals[signals] --> process[ ]\n",
    "    A --> process\n",
    "    process --> B[Generating a PDF from LLM response]\n",
    "    queries[queries] --> process\n",
    "\"\"\"\n",
    "render_mermaid(diagram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Simple Chain to Agentic Loop\n",
    "\n",
    "But what if we wanted to make it more complex? What if we wanted our research application to:\n",
    "\n",
    "- **Decide if it needs more information** after an initial web search\n",
    "- **Execute multiple searches** based on what it learns\n",
    "- **Analyze results** and determine if they're sufficient\n",
    "\n",
    "This is where the **agentic loop** becomes essential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Key Difference\n",
    "\n",
    "### What We Built Before: Chain Workflow\n",
    "\n",
    "**User Input → LLM Call → Generate PDF → Done**\n",
    "\n",
    "This is a **linear process**. The **user** determines when we're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIExSCiAgICBBW1VzZXIgY2FsbHMgTExNXSAtLT4gQltHZW5lcmF0aW5nIGEgUERGIGZyb20gTExNIHJlc3BvbnNlXQo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diagram = \"\"\"\n",
    "graph LR\n",
    "    A[User calls LLM] --> B[Generating a PDF from LLM response]\n",
    "\"\"\"\n",
    "render_mermaid(diagram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With an Agentic Loop: The Agent Decides\n",
    "\n",
    "At a high level, AI agents have an **event loop**, and in that event loop, we make calls out to the LLM to ask it for directions. **The LLM is what drives the flow** of the application.\n",
    "\n",
    "We might invoke some downstream actions (e.g., make microservice requests, query databases, call external APIs). Then we may consult with the user, and then go through the loop again.\n",
    "\n",
    "In the loop, it:\n",
    "- **Plans**: The LLM analyzes the current state and decides what to do next\n",
    "- **Executes**: The agent calls relevant tools or APIs\n",
    "- **Observes**: Reviews results and updates context\n",
    "- **Repeats** until the LLM hits its goal or the user stops it\n",
    "\n",
    "<img src=\"https://i.postimg.cc/1zhMS6YL/Loop.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Chain vs Agentic Loop\n",
    "\n",
    "| Aspect | Chain Workflow | Agentic Loop |\n",
    "|--------|---------------|---------------|\n",
    "| **Decision Maker** | Developer (hardcoded) | LLM (runtime decisions) |\n",
    "| **Execution Path** | Fixed, predetermined | Dynamic, adapts to context |\n",
    "| **Iterations** | Single pass through | Multiple iterations possible |\n",
    "| **When It Stops** | After last step completes | When goal achieved or max iterations hit |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is an AI Agent?\n",
    "\n",
    "An **AI agent** is an autonomous system that pursues goals through **continuous decision-making and action**.\n",
    "\n",
    "Think of an AI agent as an autonomous system that doesn't just respond once, but **continuously** works toward achieving a specific goal. Unlike traditional software that follows predetermined steps, an AI agent makes **decisions dynamically** based on the current situation and available information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Example: Customer Support Agent\n",
    "\n",
    "Imagine a customer contacts support saying: *\"My order hasn't arrived, I need a refund immediately!\"*\n",
    "\n",
    "A traditional application would follow a rigid flowchart. But an AI agent operates differently:\n",
    "\n",
    "**Goal**: Resolve the customer's issue and retain their business\n",
    "\n",
    "**The agent's loop in action**:\n",
    "\n",
    "| Step | Phase | What Happens |\n",
    "|------|-------|-------------|\n",
    "| 1 | **Plan** | \"I should first check the order status\" |\n",
    "| 2 | **Execute** | Queries order database |\n",
    "| 3 | **Observe** | Package is in transit, arriving tomorrow |\n",
    "| 4 | **Plan** | \"Customer needs it urgently, but it's arriving soon—offer expedited upgrade\" |\n",
    "| 5 | **Execute** | Checks if expedited shipping is available |\n",
    "| 6 | **Observe** | Next-day air available for $15 |\n",
    "| 7 | **Plan** | \"Customer lifetime value is $500—offer free upgrade\" |\n",
    "| 8 | **Execute** | Sends free expedited shipping offer |\n",
    "| 9 | **Observe** | Customer accepts offer |\n",
    "| 10 | **Goal Achieved** | Issue resolved, customer retained ✓ |\n",
    "\n",
    "Notice how the agent didn't follow a pre-programmed \"if customer says refund, then refund\" rule. It **autonomously decided** the best path based on the specific situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Agent's Limitation\n",
    "\n",
    "Our customer support agent has a goal: \"resolve dispute and retain customer.\" But here's the problem—**an LLM by itself can only generate text**.\n",
    "\n",
    "It can think through the situation and decide what *should* happen next:\n",
    "- \"I should check the order status\"\n",
    "- \"I need to see if the customer has any previous complaints\"\n",
    "- \"I should offer a refund\"\n",
    "\n",
    "But it can't actually *do* any of those things.\n",
    "\n",
    "**This is where tools come in.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Tool?\n",
    "\n",
    "A **tool** is an external function that AI systems can call to perform specific tasks beyond just generating text. Tools take real actions in the world—they might:\n",
    "- Query databases\n",
    "- Call external APIs\n",
    "- Search for information\n",
    "- Perform calculations\n",
    "- Book reservations\n",
    "- Send emails\n",
    "- Generate files\n",
    "\n",
    "### How Agents Use Tools\n",
    "\n",
    "Agents are **aware of the tools** they have available while attempting to achieve their goal. The agent:\n",
    "1. Evaluates which tools are available\n",
    "2. Decides which tool will help progress toward the goal\n",
    "3. Executes the tool\n",
    "4. Observes the result\n",
    "5. Decides the next action based on what it learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Agents Execute Tools: The Loop in Action\n",
    "\n",
    "Each iteration of the agentic loop follows this pattern:\n",
    "\n",
    "1. **LLM decides what to do** → \"I need to check the order status\"\n",
    "2. **Agent prepares the tool call** → Formats the request: `check_order(order_id=\"12345\")`\n",
    "3. **Tool executes** → Queries the database and returns: `{status: \"shipped\", tracking: \"1Z999...\"}`\n",
    "4. **Agent updates context** → Adds the result to the conversation history\n",
    "5. **Loop continues** → LLM sees the new information and decides the next action\n",
    "\n",
    "This continues until the LLM determines the goal is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIExSCiAgICBHb2FsW3RoZSBnb2FsXSAtLT4gTExNW0xMTTxici8+bWFrZXMgZGVjaXNpb25zIG9uPGJyLz53aGF0IHRvIGRvIG5leHRdCiAgICBMTE0gLS0+IFRvb2xbVG9vbDxici8+ZG9lcyB3aGF0IHRoZSBMTE08YnIvPmRlY2lkZWRdCiAgICBUb29sIC0tPiBMTE0K\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diagram = \"\"\"\n",
    "graph LR\n",
    "    Goal[the goal] --> LLM[LLM<br/>makes decisions on<br/>what to do next]\n",
    "    LLM --> Tool[Tool<br/>does what the LLM<br/>decided]\n",
    "    Tool --> LLM\n",
    "\"\"\"\n",
    "render_mermaid(diagram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Characteristics of AI Agents\n",
    "\n",
    "What makes an application agentic?\n",
    "\n",
    "### 1. Goal-Oriented\n",
    "It has a clear objective (e.g., generate a research report, book a flight, resolve a customer issue)\n",
    "\n",
    "### 2. Tool Usage\n",
    "It combines multiple capabilities (LLM reasoning + external actions like API calls, database queries, or PDF generation)\n",
    "\n",
    "### 3. Autonomous Decision Making\n",
    "The LLM decides how to approach the problem and which tools to use\n",
    "\n",
    "**Important**: Not all agents require loops! Simple agents can be goal-oriented with tool usage and autonomous decision-making without requiring iterative loops. However, **agentic loops** enable more sophisticated behaviors where the agent can reassess and adapt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Agentic Loops Are Harder Than Chains\n",
    "\n",
    "### 2. Complex State Management\n",
    "- **Chain**: Each step only needs output from previous step\n",
    "- **Loop**: Must track entire conversation history, tool results, intermediate decisions\n",
    "\n",
    "### 2. Expensive Retries\n",
    "- **Chain**: If step 3 fails, retry step 3\n",
    "- **Loop**: If iteration 12 fails, it's pricy to redo iterations 1-11 (each might have called expensive APIs or LLMs)\n",
    "\n",
    "### 3. Non-Linear Execution\n",
    "- **Chain**: Always the same sequence\n",
    "- **Loop**: Different execution paths based on what the agent discovers\n",
    "\n",
    "### 4. Long-Running Processes\n",
    "- **Chain**: Might take seconds or minutes\n",
    "- **Loop**: Could run for hours or days (e.g., waiting for user approval between iterations)\n",
    "\n",
    "This is where **Temporal Workflows** come in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo (Expand for instructor notes or to run on your own)\n",
    "<!--\n",
    "1. Clone this repository: `https://github.com/temporalio/edu-ai-workshop-agentic-loop`. The instructions will also be in the README.\n",
    "2. We will now showcase how an AI agent can dynamically choose its own tools with Temporal. Route to the `module_one_04_agentic_loop` directory with `cd module_one_04_agentic_loop`.\n",
    "3. Open three terminal windows.\n",
    "4. In one terminal window, start the Temporal server with `temporal server start-dev --ui-port 8080 --db-filename clusterdata.db` (if not already running from previous demos).\n",
    "5. In another terminal window, navigate to the `module_one_04_agentic_loop` directory and run the worker with `python worker.py`. You'll see output indicating the Worker is listening on the task queue.\n",
    "6. In the third terminal window, execute your Workflow with `python starter.py`.\n",
    "7. You'll be prompted to enter a goal for the AI agent (e.g., \"Book a flight from RDU to London on November 18\").\n",
    "8. Once the Workflow Execution completes, point out on the Web UIL\n",
    "    - Input, output\n",
    "    - The execution of each tool (search_flights, check_availability, book_flight)\n",
    "    - The difference in the tools selected if you do something like \"Book a flight from RDU to NYC on Oct 18, check seat availability first and show me the total cost\" vs. \"Book a flight from RDU to NYC on Oct 18\".\n",
    "    \n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Agent Architecture: Agents Calling Agents\n",
    "\n",
    "In production systems, complexity multiplies when agents coordinate with other agents.\n",
    "\n",
    "### Example: Research Report Generation System\n",
    "\n",
    "Your \"Research Agent\" might:\n",
    "1. Call a **Web Scraper Agent** to gather sources (scrapes 5 research websites)\n",
    "2. Call a **Fact Checker Agent** to verify claims (validates statistics against government data)\n",
    "3. Call a **Citation Generator Agent** to format references\n",
    "4. Call a **PDF Generator Agent** (what you built!)\n",
    "\n",
    "Each of these agents has its own loop:\n",
    "- **Web Scraper Agent**: Plan where to search → Execute scrape → Observe quality → Decide if more sources needed\n",
    "- **Fact Checker Agent**: Plan which claims to verify → Execute verification → Observe results → Decide confidence level\n",
    "\n",
    "<img src=\"https://i.postimg.cc/KzH2vx3y/agents-calling-agents.png\" width=\"500\"/>\n",
    "\n",
    "### Failure Points Multiply\n",
    "\n",
    "Now consider failure scenarios:\n",
    "- Network partition between Research Agent and Web Scraper Agent\n",
    "- Web Scraper Agent's 3rd iteration times out\n",
    "- Fact Checker Agent finds contradictory data and needs human review\n",
    "- PDF Generator runs out of memory\n",
    "\n",
    "**Without durability**: Any failure at any level cascades, and you lose all work across all agents.\n",
    "\n",
    "**With Temporal**: Each agent's loop is independently durable. Failures are isolated and recoverable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Agentic Loop in Temporal\n",
    "\n",
    "In Temporal, an agentic loop is represented as a **Workflow**. \n",
    "\n",
    "### How Temporal Enables Durable Agents\n",
    "\n",
    "When you build an agentic loop with Temporal:\n",
    "\n",
    "#### 1. Every step is recorded\n",
    "If you trigger an LLM invocation, then execute a tool, and finally hand off control to another agent, Temporal records every step of that process in its event history.\n",
    "\n",
    "#### 2. Automatic recovery\n",
    "If something goes wrong—a crash, network glitch, or service interruption—Temporal automatically replays the Workflow from the beginning, using the recorded event history to skip already-completed steps.\n",
    "\n",
    "#### 3. No data loss\n",
    "Temporal persistently records application progress and stores all Activity results in its durable event log.\n",
    "\n",
    "#### 4. No duplicate work\n",
    "Once an Activity completes successfully, its result is recorded. On replay, Temporal returns the stored result instead of re-executing the Activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### What You Learned Today\n",
    "\n",
    "1. **Agentic loops** are fundamentally different from chain workflows:\n",
    "   - Dynamic execution paths\n",
    "   - Unknown number of iterations\n",
    "   - LLM-driven decision making\n",
    "\n",
    "2. **Agents require three core capabilities**:\n",
    "   - Goal-oriented behavior\n",
    "   - Tool usage\n",
    "   - Autonomous decision making\n",
    "\n",
    "3. **The agentic loop pattern**: Plan → Execute → Observe → Repeat\n",
    "\n",
    "4. **Durability is critical** for agentic loops:\n",
    "   - Prevents expensive re-work\n",
    "   - Preserves state across long waits\n",
    "   - Enables reliable multi-agent coordination\n",
    "   - Saves significant costs at scale\n",
    "\n",
    "5. **Temporal makes agentic loops production-ready**:\n",
    "   - Every decision is recorded\n",
    "   - Automatic recovery from failures\n",
    "   - No duplicate work\n",
    "   - Simple code, complex reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "\n",
    "This workshop introduced you to the **concept** of the importance of foundations of AI, human in the loop, agentic loops and why durability matters.\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Temporal Docs](https://docs.temporal.io/)\n",
    "- [Code Repository](https://github.com/temporalio/edu-ai-workshop-agentic-loop)\n",
    "- [Free Temporal 101 Course](https://learn.temporal.io/courses/temporal_101/)\n",
    "\n",
    "### Thank You!\n",
    "\n",
    "Please leave your feedback [here](https://docs.google.com/forms/d/e/1FAIpQLSfkHMev6KCNGFHpVNydyjgAh2ALeHNVYv9TaSrAoBsT0KmNHQ/viewform?usp=header)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (edu-ai-workshop-mcp)",
   "language": "python",
   "name": "edu-ai-workshop-mcp"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
