{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42Spdn4_DuBH"
   },
   "source": [
    "# Human in the Loop\n",
    "\n",
    "In this section, we'll add durable human-in-the-loop capabilities to your application.\n",
    "\n",
    "In this section:\n",
    "- Allow users to supply information to an application\n",
    "- Allow an application to make information available users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Setup\n",
    "\n",
    "Run the following code blocks to install various packages and tools necessary to run this notebook\n",
    "\n",
    "**Be sure to add your .env file again. It doesn't persist across notebooks or sessions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .env file\n",
    "with open(\".env\", \"w\") as fh:\n",
    "  fh.write(\"LLM_API_KEY = YOUR_API_KEY\\nLLM_MODEL = openai/gpt-4o\")\n",
    "\n",
    "  # Now open the file and replace YOUR_API_KEY with your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables and configure LLM settings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Get LLM_API_KEY environment variable and print it to make sure that your .env file is properly loaded.\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"openai/gpt-4o\")\n",
    "LLM_API_KEY = os.getenv(\"LLM_API_KEY\", None)\n",
    "print(\"LLM API Key\", LLM_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Sure Your Temporal Web UI is Running\n",
    "\n",
    "1. You should have the Temporal Server running in your terminal (run `temporal server start-dev` if not).\n",
    "2. Then in your `Ports` tab on the bottom of this screen, find `8233` and click on the Globe icon to open the Temporal Web UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run these code blocks to load our dataclasses and Activities (from the previous chapter) into the program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from temporalio import activity\n",
    "from litellm import completion, ModelResponse\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "\n",
    "# Dataclasses\n",
    "\n",
    "@dataclass\n",
    "class LLMCallInput:\n",
    "  prompt: str\n",
    "\n",
    "@dataclass\n",
    "class PDFGenerationInput:\n",
    "  content: str\n",
    "  filename: str = \"research_pdf.pdf\"\n",
    "\n",
    "@dataclass\n",
    "class GenerateReportInput:\n",
    "    prompt: str\n",
    "\n",
    "@dataclass\n",
    "class GenerateReportOutput:\n",
    "    result: str\n",
    "\n",
    "# Activities\n",
    "\n",
    "@activity.defn\n",
    "def llm_call(input: LLMCallInput) -> ModelResponse:\n",
    "    response = completion(\n",
    "      model=LLM_MODEL,\n",
    "      api_key=LLM_API_KEY,\n",
    "      messages=[{ \"content\": input.prompt,\"role\": \"user\"}]\n",
    "    )\n",
    "    return response\n",
    "\n",
    "@activity.defn\n",
    "def create_pdf(input: PDFGenerationInput) -> str:\n",
    "    print(\"Creating PDF document...\")\n",
    "\n",
    "    doc = SimpleDocTemplate(input.filename, pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "    title_style = ParagraphStyle(\n",
    "        'CustomTitle',\n",
    "        parent=styles['Heading1'],\n",
    "        fontSize=24,\n",
    "        spaceAfter=30,\n",
    "        alignment=1\n",
    "    )\n",
    "\n",
    "    story = []\n",
    "    title = Paragraph(\"Research Report\", title_style)\n",
    "    story.append(title)\n",
    "    story.append(Spacer(1, 20))\n",
    "    paragraphs = input.content.split('\\n\\n')\n",
    "    for para in paragraphs:\n",
    "        if para.strip():\n",
    "          p = Paragraph(para.strip(), styles['Normal'])\n",
    "          story.append(p)\n",
    "          story.append(Spacer(1, 12))\n",
    "\n",
    "    doc.build(story)\n",
    "\n",
    "    print(f\"SUCCESS! PDF created: {input.filename}\")\n",
    "    return input.filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Loop Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudocode: The Feedback Loop Logic\n",
    "(Don't run this - it's just to show the structure!)\n",
    "\n",
    "#### Continue looping until the user approves the research\n",
    "while user_has_not_approved:\n",
    "\n",
    "    # Step 1: Execute the LLM call to generate research based on the current prompt\n",
    "    research_result = call_llm(current_prompt)\n",
    "\n",
    "    # Step 2: Wait for user Signal (KEEP or EDIT)\n",
    "    wait_for_signal()\n",
    "\n",
    "    # Step 3: React to the Signal\n",
    "    if user_decision == \"KEEP\":\n",
    "        # User approved - exit the loop and proceed to PDF generation\n",
    "        create_pdf(research_result)\n",
    "        break  # Exit the loop\n",
    "\n",
    "    elif user_decision == \"EDIT\":\n",
    "        # User wants to modify - update the prompt and loop again\n",
    "        current_prompt = current_prompt + user_additional_instructions\n",
    "        # Loop continues with the updated prompt\n",
    "\n",
    "    # Step 4: Reset the Signal state back to WAIT for the next iteration\n",
    "    user_decision = \"WAIT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Implement a Signal!\n",
    "\n",
    "Now, we need to do three things:\n",
    "\n",
    "1. **Define the structure for the data being supplied by the user** \n",
    "2. **Implement the point(s) in the flow where user input is sought**          \n",
    "3. **Implement a Signal handler that is called when the user supplies the information.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Create a Model\n",
    "\n",
    "- Create a model for the Signal to be stored in\n",
    "- Similar to Activities and Workflows, `dataclasses` are recommended here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This defines a string enum and a dataclass for handling user decisions in a Temporal workflow.\n",
    "# We will send a `UserDecision` as a Signal to our Research Workflow letting the Workflow know if \n",
    "# we want to keep or edit the research or if we want to wait for further decision\n",
    "\n",
    "# Step 1: Set the additional prompt to be a string that default as an empty string\n",
    "# Step 2: Run this code block\n",
    "from dataclasses import dataclass\n",
    "from enum import StrEnum\n",
    "\n",
    "class UserDecision(StrEnum):\n",
    "    KEEP = \"KEEP\"\n",
    "    EDIT = \"EDIT\"\n",
    "    WAIT = \"WAIT\"\n",
    "    \n",
    "@dataclass\n",
    "class UserDecisionSignal: # A data structure to send user decisions via Temporal Signals\n",
    "    decision: UserDecision\n",
    "    additional_prompt: # TODO Set this to be a string that defaults as an empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_03_Human_in_the_Loop\" / \"model_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Storing the Signal State\n",
    "\n",
    "Remember, the workflow needs a place to remember what Signals it has received.\n",
    "\n",
    "- Use instance variables to persist signal data across Workflow Execution\n",
    "- Can be a simple variable, or a Queue for handling many Signals\n",
    "- Initialize with default values that indicates \"no Signal received yet\". In the example above, `WAIT` is the default state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Set the instance variable of the user decision to default to WAIT\n",
    "from temporalio import workflow\n",
    "\n",
    "# sandboxed=False is a Notebook only requirement. You normally don't do this\n",
    "@workflow.defn(sandboxed=False)\n",
    "class GenerateReportWorkflow:\n",
    "    def __init__(self) -> None:\n",
    "        self._current_prompt: str = \"\"\n",
    "        # Instance variable to store Signal data\n",
    "        self._user_decision: UserDecisionSignal = UserDecisionSignal(decision=UserDecision.____) # TODO Set the default state of the user decision to be WAIT\n",
    "\n",
    "    @workflow.run\n",
    "    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n",
    "      self._current_prompt = input.prompt\n",
    "\n",
    "      llm_call_input = LLMCallInput(prompt=self._current_prompt)\n",
    "      # rest of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_03_Human_in_the_Loop\" / \"store_signal_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Defining a Signal Handler\n",
    "- A Signal is defined in your code and handled in your Workflow Definition\n",
    "- A given Workflow Definition can support multiple Signals\n",
    "- To define a Signal, set the Signal decorator `@workflow.signal` on the Signal function inside your Workflow class\n",
    "- Signal methods define what happens when the Signal is received\n",
    "\n",
    "In this example, when a client sends a Signal, this handler receives the UserDecisionSignal data and updates the `self._user_decision` in the Workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Add the `@workflow.signal` decorator above the `user_decision_signal` method\n",
    "# Step 2: Update the instance variable `self._user_decision` by setting it to `decision_data`\n",
    "# Reflection Question: What's still missing for this Signal implementation to work properly?\n",
    "from temporalio import workflow\n",
    "\n",
    "@workflow.defn(sandboxed=False) # sandboxed=False is a Notebook only requirement. You normally don't do this)\n",
    "class GenerateReportWorkflow:\n",
    "    def __init__(self) -> None:\n",
    "        self._current_prompt: str = \"\"\n",
    "        self._user_decision: UserDecisionSignal = UserDecisionSignal(decision=UserDecision.WAIT) # UserDecision Signal starts with WAIT as the default state\n",
    "\n",
    "    # TODO Define the Signal handler with @workflow.signal\n",
    "    async def user_decision_signal(self, decision_data: UserDecisionSignal) -> None:\n",
    "        self._user_decision = # TODO Update instance variable when Signal is received to decision_data\n",
    "\n",
    "    @workflow.run\n",
    "    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n",
    "      self._current_prompt = input.prompt\n",
    "\n",
    "      llm_call_input = LLMCallInput(prompt=self._current_prompt)\n",
    "      # rest of code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_03_Human_in_the_Loop\" / \"signal_handler_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Creating Our Loop\n",
    "\n",
    "As mentioned early in our psuedocode, we now need to create our loop that reacts to the Signal in Workflow logic.\n",
    "\n",
    "- If the Workflow receives `KEEP` as the `UserDecision`, then the Workflow exits the research loop and proceeds to PDF generation.\n",
    "- If the Workflow receives `EDIT` as the `UserDecision`, then the Workflow incorporates any additional feedback into the prompt, updates the research parameters, and resets the Signal state back to `WAIT` so it can loop again to regenerate the research and wait for the next user decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting it together, we see we have set the Signal state, created the Signal handler method, \n",
    "# and have logic in the Workflow to how it will react to the Signal.\n",
    "# Step 1: Start a while loop if the `continue_user_input_loop` is `True`\n",
    "# Step 2: If the Workflow receives `EDIT` as the `UserDecision`, then the Workflow \n",
    "# incorporates any additional feedback into the prompt\n",
    "# Step 3: If the user chooses to edit the research, after they supply a new prompt,\n",
    "# set the user decision back to WAIT for the next loop\n",
    "# Step 4: Run this code block to load it into your program\n",
    "from temporalio import workflow\n",
    "from datetime import timedelta\n",
    "\n",
    "# sandboxed=False is a Notebook only requirement. You normally don't do this\n",
    "@workflow.defn(sandboxed=False)\n",
    "class GenerateReportWorkflow:\n",
    "    def __init__(self) -> None:\n",
    "        self._current_prompt: str = \"\"\n",
    "        self._user_decision: UserDecisionSignal = UserDecisionSignal(decision=UserDecision.WAIT)\n",
    "    \n",
    "    @workflow.signal\n",
    "    async def user_decision_signal(self, decision_data: UserDecisionSignal) -> None:\n",
    "        self._user_decision = decision_data\n",
    "\n",
    "    @workflow.run\n",
    "    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n",
    "        self._current_prompt = input.prompt\n",
    "\n",
    "        llm_call_input = LLMCallInput(prompt=self._current_prompt)\n",
    "        \n",
    "        # Continue looping until the user approves the research\n",
    "        continue_user_input_loop = True\n",
    "\n",
    "        # TODO: Start a while loop for while continue_user_input_loop is True\n",
    "            research_facts = await workflow.execute_activity(\n",
    "                llm_call,\n",
    "                llm_call_input,\n",
    "                start_to_close_timeout=timedelta(seconds=30),\n",
    "            )\n",
    "\n",
    "            # User approved the research - exit the loop and proceed to PDF generation\n",
    "            if self._user_decision.decision == UserDecision.KEEP:\n",
    "                workflow.logger.info(\"User approved the research. Creating PDF...\")\n",
    "                continue_user_input_loop = False\n",
    "            # User wants to edit the research - update the prompt and loop again\n",
    "            elif self._user_decision.decision == # TODO Set this condition to be if the UserDecision is EDIT\n",
    "                workflow.logger.info(\"User requested research modification.\")\n",
    "                if self._user_decision.additional_prompt != \"\":\n",
    "                    # Append the user's additional instructions to the existing prompt\n",
    "                    self._current_prompt = (\n",
    "                        f\"{self._current_prompt}\\n\\nAdditional instructions: {self._user_decision.additional_prompt}\"\n",
    "                    )\n",
    "                else:\n",
    "                    workflow.logger.info(\"No additional instructions provided. Regenerating with original prompt.\")\n",
    "                # Update the Activity input with the modified prompt for the next iteration\n",
    "                llm_call_input.prompt = self._current_prompt\n",
    "                # TODO: Set the user decision back to WAIT for the next loop\n",
    "\n",
    "        pdf_generation_input = PDFGenerationInput(content=research_facts[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "        pdf_filename: str = await workflow.execute_activity(\n",
    "            create_pdf,\n",
    "            pdf_generation_input,\n",
    "            start_to_close_timeout=timedelta(seconds=20),\n",
    "        )\n",
    "\n",
    "        return GenerateReportOutput(result=f\"Successfully created research report PDF: {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_03_Human_in_the_Loop\" / \"loop_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waiting for a Signal\n",
    "- Use `workflow.wait_condition()` to pause until Signal is received (user decides the next step)\n",
    "- Creates a blocking checkpoint where the Workflow stops and waits\n",
    "- Resumes execution only when specified condition becomes true\n",
    "- Optionally accepts a timeout parameter: `workflow.wait_condition(lambda: condition, timeout=timedelta(hours=24))` - waits until Signal received OR timeout elapsed, whichever happens first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Within the `await workflow.wait_condition(lambda: )` code, \n",
    "# set the lambda to when `self._user_decision.decision` is not set to `UserDecision.WAIT`\n",
    "# Step 2: Run this code block\n",
    "from temporalio import workflow\n",
    "\n",
    "@workflow.defn(sandboxed=False)\n",
    "class GenerateReportWorkflow:\n",
    "    def __init__(self) -> None:\n",
    "        self._current_prompt: str = \"\"\n",
    "        # Instance variable to store the Signal in\n",
    "        self._user_decision: UserDecisionSignal = UserDecisionSignal(decision=UserDecision.WAIT)\n",
    "\n",
    "    # Method to handle the Signal\n",
    "    @workflow.signal\n",
    "    async def user_decision_signal(self, decision_data: UserDecisionSignal) -> None:\n",
    "        # Update the instance variable with the received Signal data\n",
    "        self._user_decision = decision_data\n",
    "\n",
    "    @workflow.run\n",
    "    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n",
    "        self._current_prompt = input.prompt\n",
    "\n",
    "        llm_call_input = LLMCallInput(prompt=self._current_prompt)\n",
    "\n",
    "        continue_user_input_loop = True\n",
    "\n",
    "        while continue_user_input_loop:\n",
    "            research_facts = await workflow.execute_activity(\n",
    "                llm_call,\n",
    "                llm_call_input,\n",
    "                start_to_close_timeout=timedelta(seconds=30),\n",
    "            )\n",
    "\n",
    "            self._research_result = research_facts[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "            # Waiting for Signal with user decision\n",
    "            await workflow.wait_condition(lambda: ) # TODO set the lambda to when `self._user_decision.decision` is not set to `UserDecision.WAIT`\n",
    "\n",
    "            if self._user_decision.decision == UserDecision.KEEP:\n",
    "                workflow.logger.info(\"User approved the research. Creating PDF...\")\n",
    "                continue_user_input_loop = False\n",
    "            elif self._user_decision.decision == UserDecision.EDIT:\n",
    "                workflow.logger.info(\"User requested research modification.\")\n",
    "                if self._user_decision.additional_prompt != \"\":\n",
    "                    self._current_prompt = (\n",
    "                        f\"{self._current_prompt}\\n\\nAdditional instructions: {self._user_decision.additional_prompt}\"\n",
    "                    )\n",
    "                else:\n",
    "                    workflow.logger.info(\"No additional instructions provided. Regenerating with original prompt.\")\n",
    "                llm_call_input.prompt = self._current_prompt\n",
    "                self._user_decision = UserDecisionSignal(decision=UserDecision.WAIT)\n",
    "\n",
    "        pdf_generation_input = PDFGenerationInput(content=research_facts[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "        pdf_filename: str = await workflow.execute_activity(\n",
    "            create_pdf,\n",
    "            pdf_generation_input,\n",
    "            start_to_close_timeout=timedelta(seconds=20),\n",
    "        )\n",
    "\n",
    "        return GenerateReportOutput(result=f\"Successfully created research report PDF: {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_03_Human_in_the_Loop\" / \"wait_condition_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Workflow\n",
    "\n",
    "Now that your Signal is implemented, let's run the Worker and start the Workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set up our Worker. Run this code block to load it into the program\n",
    "import concurrent.futures\n",
    "from temporalio.client import Client\n",
    "from temporalio.worker import Worker\n",
    "\n",
    "async def run_worker() -> None:\n",
    "    # Create client connected to server at the given address\n",
    "    client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "    # Run the Worker\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as activity_executor:\n",
    "        worker = Worker(\n",
    "            client,\n",
    "            task_queue=\"research\",\n",
    "            workflows=[GenerateReportWorkflow],\n",
    "            activities=[llm_call, create_pdf],\n",
    "            activity_executor=activity_executor\n",
    "        )\n",
    "        print(f\"Starting the worker..\")\n",
    "        await worker.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to run the Worker\n",
    "import asyncio\n",
    "worker = asyncio.create_task(run_worker())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the Workflow! Run this codeblock\n",
    "import uuid\n",
    "from temporalio.client import Client\n",
    "\n",
    "client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "print(\"Welcome to the Research Report Generator!\")\n",
    "prompt = input(\"Enter your research topic or question: \").strip()\n",
    "\n",
    "if not prompt:\n",
    "    prompt = \"Give me 5 fun and fascinating facts about tardigrades. Make them interesting and educational!\"\n",
    "    print(f\"No prompt entered. Using default: {prompt}\")\n",
    "\n",
    "# Asynchronous start of a Workflow\n",
    "handle = await client.start_workflow(\n",
    "    GenerateReportWorkflow,\n",
    "    GenerateReportInput(prompt=prompt),\n",
    "    id=f\"generate-research-report-workflow-{uuid.uuid4()}\",\n",
    "    task_queue=\"research\",\n",
    ")\n",
    "\n",
    "print(f\"Started workflow. Workflow ID: {handle.id}, RunID {handle.result_run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing Signals in the Web UI\n",
    "\n",
    "Now, look at the Web UI. \n",
    "- The `llm_call` Activity is complete, but the Workflow is still `running`. Why?\n",
    "- Look at the output of the `llm_call` Activity. Do you like the output enough to keep it and create a PDF? Or do you want to edit it? Decide what Signal you want to send: `keep` or `edit`.\n",
    "\n",
    "_To open the Temporal Web UI, go to the `Ports` tab on the bottom of this screen, find `8233` and click on the Globe icon._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending Signals\n",
    "\n",
    "To send a Signal with the Temporal Client, we need to get a \"handle\" to a specific Workflow Execution, which will be used to interact with that Workflow.\n",
    "\n",
    "We'll do this with the [`get_workflow_handle`](https://docs.temporal.io/develop/python/message-passing#send-messages) method.\n",
    "\n",
    "`handle = client.get_workflow_handle(workflow_id)`\n",
    "\n",
    "With the handle on the Workflow Execution we want to Signal, we'll then pass in our Signal:\n",
    "\n",
    "```python\n",
    "signal_data = UserDecisionSignal(decision=UserDecision.KEEP)\n",
    "await handle.signal(\"user_decision_signal\", signal_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's send our Signal from the Client code\n",
    "# Step 1: To get a handle on your Workflow Executon, pass in workflow_id into `get_workflow_handle()`\n",
    "# Step 2: If the input decision was to edit the the prompt, send a Signal to your Workflow Handle with the new Signal data\n",
    "# Step 3: Run this code block to load it into the program\n",
    "async def send_user_decision_signal(client: Client, workflow_id: str) -> None:\n",
    "  loop = asyncio.get_running_loop() # We usually do not need this\n",
    "  handle = client.get_workflow_handle() # TODO Pass in workflow_id (which is an argument passed into this function)\n",
    "\n",
    "  while True:\n",
    "      print(\"\\n\" + \"=\" * 80)\n",
    "      print(\n",
    "          \"Calling LLM! See the response in your Web UI in the output of the `llm_call` Activity. Would you like to keep or edit it?\"\n",
    "      )\n",
    "      print(\"1. Type 'keep' to approve the output and create PDF\")\n",
    "      print(\"2. Type 'edit' to modify the output\")\n",
    "      print(\"=\" * 80)\n",
    "\n",
    "      # When running input in async code, run in an executor to not block the event loop\n",
    "      decision = await loop.run_in_executor(None, input, \"Your decision (keep/edit): \")\n",
    "      decision = decision.strip().lower()\n",
    "\n",
    "      if decision in {\"keep\", \"1\"}:\n",
    "          signal_data = UserDecisionSignal(decision=UserDecision.KEEP)\n",
    "          await handle.signal(\"user_decision_signal\", signal_data) # Send our Keep Signal to our Workflow Execution we have a handle on\n",
    "          print(\"Signal sent to keep output and create PDF\")\n",
    "          break\n",
    "      if decision in {\"edit\", \"2\"}:\n",
    "          additional_prompt_input = input(\"Enter additional instructions to edit the output (optional): \").strip()\n",
    "          signal_data = UserDecisionSignal(decision=UserDecision.EDIT, additional_prompt=additional_prompt_input)\n",
    "          # TODO Send our Signal to our Workflow Execution we have a handle on\n",
    "          print(\"Signal sent to regenerate output\")\n",
    "\n",
    "      else:\n",
    "          print(\"Please enter either 'keep', 'edit'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_03_Human_in_the_Loop\" / \"sending_signal_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now send your Signal by running this code block.\n",
    "send_signal = await send_user_decision_signal(client, handle.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check your file explorer to see your new file\n",
    "\n",
    "To view it, right click, click Download. Open it from your downloads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kill any worker to prepare for Queries now!\n",
    "x = worker.cancel()\n",
    "\n",
    "if x:\n",
    "  print(\"Worker killed\")\n",
    "else:\n",
    "  print(\"Worker was not running. Nothing to kill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Adding Query Support in Temporal\n",
    "\n",
    "Now let's add **[Query](https://docs.temporal.io/develop/python/message-passing#queries)** support to our Workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Handle a Query\n",
    "\n",
    "Let's create a Query which will allow external clients to read the current research content from a running Workflow without interrupting its execution.\n",
    "\n",
    "You can handle Queries by annotating a function within your Workflow with `@workflow.query`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a Query into our Workflow code\n",
    "# Step 1: Initialize the _research_result to be an empty string\n",
    "# Step 2: Decorate your Query handler with `@workflow.query`\n",
    "# Step 3: In your Query handler, returns the `_research_result` field\n",
    "# Step 4: Run your codeblock \n",
    "from temporalio import workflow\n",
    "\n",
    "@workflow.defn(sandboxed=False)\n",
    "class GenerateReportWorkflow:\n",
    "    def __init__(self) -> None:\n",
    "        self._current_prompt: str = \"\"\n",
    "        self._user_decision: UserDecisionSignal = UserDecisionSignal(decision=UserDecision.WAIT)\n",
    "        self._research_result: # TODO Initialize the _research_result to be an empty string\n",
    "\n",
    "    # Method to handle the Signal\n",
    "    @workflow.signal\n",
    "    async def user_decision_signal(self, decision_data: UserDecisionSignal) -> None:\n",
    "        # Update the instance variable with the received Signal data\n",
    "        self._user_decision = decision_data\n",
    "    \n",
    "    # Decorate your Query handler with `@workflow.query`\n",
    "    def get_research_result(self) -> str | None: # Query to get the current research result\n",
    "        # TODO: Return the `_research_result` field\n",
    "\n",
    "    @workflow.run\n",
    "    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n",
    "      self._current_prompt = input.prompt\n",
    "\n",
    "      llm_call_input = LLMCallInput(prompt=self._current_prompt)\n",
    "      # rest of code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_03_Human_in_the_Loop\" / \"handling_query_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### React to Query\n",
    "\n",
    "We now want to fill out the contents of the research result so that the contents can be sent back to the user when the user queries for the research result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a Query into our Workflow code\n",
    "# Step 1: After the LLM call, set `_research_result` field to be the contents of the research (research_facts[\"choices\"][0][\"message\"][\"content\"])\n",
    "# Step 2: Run this code block to load it into the program\n",
    "from datetime import timedelta\n",
    "\n",
    "from temporalio import workflow\n",
    "\n",
    "@workflow.defn(sandboxed=False)\n",
    "class GenerateReportWorkflow:\n",
    "    def __init__(self) -> None:\n",
    "        self._current_prompt: str = \"\"\n",
    "        self._user_decision: UserDecisionSignal = UserDecisionSignal(decision=UserDecision.WAIT)\n",
    "        self._research_result: str = \"\"\n",
    "\n",
    "    # Method to handle the Signal\n",
    "    @workflow.signal\n",
    "    async def user_decision_signal(self, decision_data: UserDecisionSignal) -> None:\n",
    "        # Update the instance variable with the received Signal data\n",
    "        self._user_decision = decision_data\n",
    "\n",
    "    @workflow.query # Query to get the current research result\n",
    "    def get_research_result(self) -> str | None:\n",
    "        return self._research_result\n",
    "\n",
    "    @workflow.run\n",
    "    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n",
    "        self._current_prompt = input.prompt\n",
    "\n",
    "        llm_call_input = LLMCallInput(prompt=self._current_prompt)\n",
    "\n",
    "        continue_user_input_loop = True\n",
    "\n",
    "        while continue_user_input_loop:\n",
    "            research_facts = await workflow.execute_activity(\n",
    "                llm_call,\n",
    "                llm_call_input,\n",
    "                start_to_close_timeout=timedelta(seconds=30),\n",
    "            )\n",
    "\n",
    "            # TODO: Set `_research_result` field to be the contents of the research (research_facts[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "            # Waiting for Signal with user decision\n",
    "            await workflow.wait_condition(lambda: self._user_decision.decision != UserDecision.WAIT)\n",
    "\n",
    "            if self._user_decision.decision == UserDecision.KEEP:\n",
    "                workflow.logger.info(\"User approved the research. Creating PDF...\")\n",
    "                continue_user_input_loop = False\n",
    "            elif self._user_decision.decision == UserDecision.EDIT:\n",
    "                workflow.logger.info(\"User requested research modification.\")\n",
    "                if self._user_decision.additional_prompt != \"\":\n",
    "                    self._current_prompt = (\n",
    "                        f\"{self._current_prompt}\\n\\nAdditional instructions: {self._user_decision.additional_prompt}\"\n",
    "                    )\n",
    "                    workflow.logger.info(f\"Regenerating research with updated prompt: {self._current_prompt}\")\n",
    "                else:\n",
    "                    workflow.logger.info(\"No additional instructions provided. Regenerating with original prompt.\")\n",
    "                llm_call_input.prompt = self._current_prompt\n",
    "\n",
    "                self._user_decision = UserDecisionSignal(decision=UserDecision.WAIT)\n",
    "\n",
    "        pdf_generation_input = PDFGenerationInput(content=research_facts[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "        pdf_filename: str = await workflow.execute_activity(\n",
    "            create_pdf,\n",
    "            pdf_generation_input,\n",
    "            start_to_close_timeout=timedelta(seconds=20),\n",
    "        )\n",
    "\n",
    "        return GenerateReportOutput(result=f\"Successfully created research report PDF: {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_03_Human_in_the_Loop\" / \"react_to_query_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Test Our Query!\n",
    "\n",
    "Now that we've defined our Query handler and client code, let's start a Worker with the updated Workflow and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart the Worker with updated workflow that includes Query support\n",
    "import asyncio\n",
    "worker = asyncio.create_task(run_worker())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a NEW Workflow Execution to test queries\n",
    "import uuid\n",
    "from temporalio.client import Client\n",
    "\n",
    "client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "print(\"Starting a new workflow to test Query functionality...\")\n",
    "prompt = input(\"Enter your research topic or question: \").strip()\n",
    "\n",
    "if not prompt:\n",
    "    prompt = \"Give me 5 fun and fascinating facts about tardigrades.\"\n",
    "    print(f\"Using default prompt: {prompt}\")\n",
    "\n",
    "handle = await client.start_workflow(\n",
    "    GenerateReportWorkflow,\n",
    "    GenerateReportInput(prompt=prompt),\n",
    "    id=f\"generate-research-report-workflow-{uuid.uuid4()}\",\n",
    "    task_queue=\"research\",\n",
    ")\n",
    "\n",
    "print(f\"Workflow started! ID: {handle.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending a Query\n",
    "\n",
    "After defining and setting a handler for the Queries in your Workflow, the next step is to send a Query, which is sent from a Temporal Client. To do this, use the `query` method. We will again:\n",
    "\n",
    "1. Get a handle of the Workflow Execution we will query.\n",
    "2. Send a query with the query method.\n",
    "\n",
    "`research_result = await handle.query(GenerateReportWorkflow.get_research_result)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's send our Query from the Client code and combine it with our Signals\n",
    "# Step 1: Call await query_research_result with your client and workflow_id passed in\n",
    "# Step 2: Run this codeblock\n",
    "\n",
    "async def query_research_result(client: Client, workflow_id: str) -> None:\n",
    "    handle = client.get_workflow_handle(workflow_id)\n",
    "\n",
    "    try:\n",
    "        research_result = await handle.query(GenerateReportWorkflow.get_research_result)\n",
    "        if research_result:\n",
    "            print(f\"Research Result: {research_result}\")\n",
    "        else:\n",
    "            print(\"Research Result: Not yet available\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Query failed: {e}\")\n",
    "\n",
    "\n",
    "async def send_user_decision(client: Client, workflow_id: str) -> None:\n",
    "    handle = client.get_workflow_handle(workflow_id)\n",
    "\n",
    "    while True:\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"Research is complete!\")\n",
    "        print(\"1. Type 'query' to query for research result. Make sure llm_call Activity is complete first.\")\n",
    "        print(\"2. Type 'keep' to approve the research and create PDF\")\n",
    "        print(\n",
    "            \"3. Type 'edit' to modify the research.\"\n",
    "        )\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        decision = input(\"Your decision (query/keep/edit): \").strip().lower()\n",
    "\n",
    "        if decision in {\"query\", \"1\"}:\n",
    "            # TODO Call await query_research_result with your client and workflow_id passed in\n",
    "        elif decision in {\"keep\", \"2\"}:\n",
    "            signal_data = UserDecisionSignal(decision=UserDecision.KEEP)\n",
    "            await handle.signal(\"user_decision_signal\", signal_data)\n",
    "            print(\"Signal sent to keep research and create PDF\")\n",
    "            break\n",
    "        elif decision in {\"edit\", \"3\"}:\n",
    "            additional_prompt_input = input(\"Enter additional instructions for the research (optional): \").strip()\n",
    "            additional_prompt = additional_prompt_input if additional_prompt_input else \"\"\n",
    "            signal_data = UserDecisionSignal(decision=UserDecision.EDIT, additional_prompt=additional_prompt)\n",
    "            await handle.signal(\"user_decision_signal\", signal_data)\n",
    "            print(\"Signal sent to regenerate research\")\n",
    "        else:\n",
    "            print(\"Please enter either 'query', 'keep', or 'edit'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_03_Human_in_the_Loop\" / \"putting_it_together_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now send your decision by running this code block. \n",
    "# 1. Send a Query first. Make sure that the `llm_call` Activity is complete first. See the result output below.\n",
    "# 2. Check the Web UI: Did any new Events appear in the Web UI?\n",
    "# 3. Send a Keep Signal to complete the Workflow Execution.\n",
    "user_decision = await send_user_decision(client, handle.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructor-Led Demo (Expand for instructor notes or to run on your own)\n",
    "<!--\n",
    "1. The instructions will also be in the README at the `demos` level. Follow the `Setup` step first before running.\n",
    "2. From the `demos/module_one_03_human_in_the_loop` directory, in one terminal window, run your Worker with `uv run worker.py`.\n",
    "3. In another terminal window, execute your Workflow with `python starter.py`.\n",
    "4. You'll be prompted to enter a research topic or question in the CLI.\n",
    "5. Once you do, you'll be prompted with the ability to Signal or Query the Workflow.\n",
    "6. Type 'query' and you'll see the output in the terminal window where you started your Workflow Execution.\n",
    "7. Time to demonstrate Signals. Back in the terminal window when you started your Workflow Execution, you'll see that you are prompted to choose one of the two options:\n",
    "    a. Approve of this research and if you would like it to create a PDF (type 'keep' to send a Signal to the Workflow to create the PDF).\n",
    "    b. Modify the research by adding extra info to the prompt (type 'edit' to modify the prompt and send another Signal to the Workflow to prompt the LLM again).\n",
    "8. Demonstrate the modification by typing `edit`.\n",
    "9. Enter additional instructions (e.g.: \"turn this into a poem\") and see the new output in the terminal window by typing `query` again.\n",
    "10. Finally, show that you can keep changing the execution path of your Workflow Execution by typing `keep`. Show that the PDF has appeared in your `module_one_03_human_in_the_loop` directory.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kill any worker to prepare for the exercise.\n",
    "x = worker.cancel()\n",
    "\n",
    "if x:\n",
    "  print(\"Worker killed\")\n",
    "else:\n",
    "  print(\"Worker was not running. Nothing to kill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pbw85OliybvN"
   },
   "source": [
    "---\n",
    "# Exercise 3 - Human in the Loop\n",
    "\n",
    "* In these exercises you will:\n",
    "  * Review a modified version of the previous exercise and investigate the results in the Web UI\n",
    "  * Add a Signal to the exercise to provide the filename you wish to save the research report as\n",
    "  * Add a Query to the exercise to extract the character length of the research request\n",
    "* Go to the **Exercise** Directory and open the **03_Human_in_the_Loop** Directory\n",
    "* Open _03_Human_in_the_Loop-Practice.ipynb_ and follow the instructions\n",
    "* If you get stuck, raise your hand and someone will come by and help. You can also check the `Solution` directory for the answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Next?\n",
    "\n",
    "This chapter introduced you to **interacting with workflows** in Temporal. Further your learning with these resources:\n",
    "\n",
    "- Our [free course](https://learn.temporal.io/courses/interacting_with_workflows/python/) on Signals, Queries, and other ways to interact with Workflows in Temporal \n",
    "- A [Python tutorial](https://learn.temporal.io/tutorials/python/build-an-email-drip-campaign/) to practice handling Signals and Queries\n",
    "- Documentation on [Updates](https://docs.temporal.io/develop/python/message-passing#updates), a feature which combine both Signals and Queries"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (edu-ai-workshop-mcp)",
   "language": "python",
   "name": "edu-ai-workshop-mcp"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
