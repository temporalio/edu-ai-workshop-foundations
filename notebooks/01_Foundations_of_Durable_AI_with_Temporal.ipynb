{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h52a-EFoGu4x"
      },
      "source": [
        "# Foundations of Durable AI with Temporal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyJ9MCfUkdGm"
      },
      "source": [
        "## Hands-on Moments\n",
        "\n",
        "This is a hands-on workshop!\n",
        "\n",
        "All of the instructors slides and code samples are are executable in the workshop notebooks.\n",
        "We encourage you to follow along and play with the samples!\n",
        "\n",
        "At the end of every chapter (notebook) will be a hands-on lab.\n",
        "This a self-guided experience where the instructor gives a prompt (not an llm haha) with a notebook and some starter code and the attendees solve the puzzle.\n",
        "\n",
        "We are going to create a Research Agent that makes a call to the OpenAI API, conducts research on a topic of your choice, and generates a PDF report from that research. Let's go ahead and first set up your notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mbEBnIn7H1Yg",
        "outputId": "bc16c98c-4661-4f53-849d-f84f4ff92d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/azhou/Desktop/edu-ai-workshop-mcp/env/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# We'll first install the necessary packages for this workshop.\n",
        "\n",
        "%pip install --quiet litellm reportlab python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mE2hcw8jugIe"
      },
      "outputs": [],
      "source": [
        "# Mermaid renderer, run at the beginning to setup rendering of diagrams\n",
        "import base64\n",
        "from IPython.display import Image, display\n",
        "\n",
        "def render_mermaid(graph_definition):\n",
        "    \"\"\"\n",
        "    Renders a Mermaid diagram in Google Colab using mermaid.ink.\n",
        "\n",
        "    Args:\n",
        "        graph_definition (str): The Mermaid diagram code (e.g., \"graph LR; A-->B;\").\n",
        "    \"\"\"\n",
        "    graph_bytes = graph_definition.encode(\"ascii\")\n",
        "    base64_bytes = base64.b64encode(graph_bytes)\n",
        "    base64_string = base64_bytes.decode(\"ascii\")\n",
        "    display(Image(url=\"https://mermaid.ink/img/\" + base64_string))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXp3VIAdZuhO"
      },
      "source": [
        "## Create an `.env` File\n",
        "\n",
        "Next you'll create a `.env` file to store your API keys.\n",
        "In the file browser on the left, create a new file and name it `.env`.\n",
        "\n",
        "**Note**: It may disappear as soon as you create it. This is because Google Collab hides hidden files (files that start with a `.`) by default.\n",
        "To make this file appear, click the icon that is a crossed out eye and hidden files will appear.\n",
        "\n",
        "Then double click on the `.env` file and add the following line with your API key.\n",
        "\n",
        "```\n",
        "LLM_API_KEY = YOUR_API_KEY\n",
        "LLM_MODEL = \"openai/gpt-4o\"\n",
        "```\n",
        "\n",
        "By default this notebook uses OpenAI's GPT-4o.\n",
        "If you want to use a different LLM provider, look up the appropriate model name [in their documentation](https://docs.litellm.ai/docs/providers) and change the `LLM_MODEL` field and provide your API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSl-K8ATXLJ3"
      },
      "outputs": [],
      "source": [
        "# Create .env file\n",
        "with open(\".env\", \"w\") as fh:\n",
        "  fh.write(\"LLM_API_KEY = YOUR_API_KEY\\nLLM_MODEL = openai/gpt-4o\")\n",
        "\n",
        "# Now open the file and replace YOUR_API_KEY with your API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy4s0KTRdWxL",
        "outputId": "69af7aa5-c7fb-462e-d3e5-6bf8a4d73a01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM API Key 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\n"
          ]
        }
      ],
      "source": [
        "# Load environment variables and configure LLM settings\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)\n",
        "\n",
        "# Get LLM_API_KEY environment variable and print it to make sure that your .env file is properly loaded.\n",
        "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"openai/gpt-4o\")\n",
        "LLM_API_KEY = os.getenv(\"LLM_API_KEY\", None)\n",
        "print(\"LLM API Key\", LLM_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9zkChjcPptZ"
      },
      "source": [
        "# Building an AI Agent Introduction\n",
        "\n",
        "By now, you've experienced generative AI firsthand. You've used ChatGPT and seen what LLMs can do. They excel at tasks like research, but their real power emerges when we connect them with users and other actions to build more advanced applications that go beyond simple chat interfaces.\n",
        "\n",
        "In this workshop, we'll build toward creating AI agents, but let's start with a simple chain:\n",
        "\n",
        "Use an LLM to generate research -> then produce a PDF from that research."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ChAeilLEBIR"
      },
      "source": [
        "## Key Elements of a Gen-AI Application\n",
        "\n",
        "At their core, Gen-AI applications use an LLM as one component among many. The LLM isn't the application itself. Take ChatGPT as an example—it's an application that wraps an LLM, not an LLM itself. Even this seemingly simple chat interface does much more than just call an LLM:\n",
        "\n",
        "- Displays responses to the user\n",
        "- Captures user input\n",
        "- Maintains conversation history\n",
        "- Orchestrates each subsequent LLM call\n",
        "\n",
        "Applications can look like many different formats. We will start with something like a chain workflow where a series of LLM calls, actions, and user interactions are strung together:\n",
        "\n",
        "<img src=\"https://images.ctfassets.net/0uuz8ydxyd9p/70SBemKQHnqfLxoHgPovQX/33f3a0b6cfc96eae2d17d1a463079560/Screenshot_2025-07-08_at_10.26.26%C3%A2__AM.png\" />\n",
        "\n",
        "Applications can also look like a loop, where the path through the business logic isn't predetermined. Instead, the system determines it at runtime, with the LLM driving the flow decisions.\n",
        "\n",
        "<img src=\"https://images.ctfassets.net/0uuz8ydxyd9p/O0udQjFtCS4RKr3JLcoNQ/589423afb721f595896a978e3d9ca3c2/Screenshot_2025-07-08_at_10.26.59%C3%A2__AM.png\" width=\"500\"/>\n",
        "\n",
        "We'll first look at applications that look like a chain workflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG55jts4HFwj"
      },
      "source": [
        "## Gen-AI Based Applications are Distributed Systems\n",
        "\n",
        "When you combine LLMs with other actions—calling external APIs, querying databases, processing files, you're coordinating multiple services across network boundaries.\n",
        "\n",
        "But challenges can happen:\n",
        "\n",
        "- Resources (APIs and databases) go down\n",
        "- Rate limiting on the LLM might cause it to fail\n",
        "- Networks can go down.\n",
        "- Imagine if the user asks the LLM for something, and the LLM times out. We have to start from the beginning.\n",
        "\n",
        "**Gen-AI based applications are distributed systems**. And we are going to show you how to make these are resilient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAelO1P7frYp"
      },
      "source": [
        "## What Does Durability Mean?\n",
        "\n",
        "- If an LLM call fails halfway through processing, you **don't lose the work already completed**.\n",
        "- If a database query times out, you can **retry just that step** without restarting everything.\n",
        "- If your application crashes, it can **resume from the last successful operation**.\n",
        "- **Long-running processes** can span hours or days without losing context.\n",
        "\n",
        "Without durability, every failure means starting over.\n",
        "With durability, failures become recoverable interruptions instead of catastrophic losses. This is especially critical for Gen-AI applications where LLM calls are expensive, slow, and unpredictable.\n",
        "\n",
        "_Before we dive into building durable workflows, let's start with the first steps: making LLM call_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKQTomi_ODQl"
      },
      "source": [
        "## Prompting the LLM\n",
        "\n",
        "Our agent will use LLM calls to process information and decide what actions to take.\n",
        "\n",
        "We use `litellm` here, which is a unified interface for over 100+ LLM providers. This means that the same code works with different models - you only need to change the model string. All you need to do is provide an API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yhd-464Imwb",
        "outputId": "bc728682-e086-4175-d855-22ef3011cafa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Certainly! Elephants are fascinating creatures with many interesting characteristics:\n",
            "\n",
            "1. **Species**: There are three extant species of elephants: the African bush elephant (Loxodonta africana), the African forest elephant (Loxodonta cyclotis), and the Asian elephant (Elephas maximus).\n",
            "\n",
            "2. **Size**: Elephants are the largest land animals on Earth. African elephants are typically larger than their Asian counterparts. African bush elephants can weigh up to 12,000 pounds (around 5,443 kg), whereas Asian elephants can weigh up to  11,000 pounds (around 4,990 kg).\n",
            "\n",
            "3. **Lifespan**: Elephants can live up to 60 to 70 years in the wild. Their longevity in captivity can be influenced by various factors such as care, diet, and living conditions.\n",
            "\n",
            "4. **Social Structure**: Elephants are highly social animals. They live in matriarchal herds, usually led by the oldest female. Male elephants often live in bachelor groups or alone after leaving their maternal herd.\n",
            "\n",
            "5. **Communication**: Elephants have a complex communication system that includes vocalizations like trumpets and low-frequency rumbles, as well as body language and tactile signals.\n",
            "\n",
            "6. **Intelligence**: Elephants are known for their high intelligence, demonstrated by their abilities in problem-solving, tool use, and exhibiting behaviors that suggest empathy and self-awareness.\n",
            "\n",
            "7. **Trunk**: An elephant's trunk, a fusion of the nose and upper lip, is a highly versatile tool used for breathing, smelling, touching, grasping, and producing sound. It has around 40,000 muscles.\n",
            "\n",
            "8. **Diet**: Elephants are herbivores and spend a significant portion of their day feeding. They eat grasses, leaves, branches, fruits, and bark. An adult elephant can consume 200-600 pounds of food in a single day.\n",
            "\n",
            "9. **Tusks**: Both male and female African elephants typically grow tusks, whereas, in Asian elephants, only some males develop them. Tusks are elongated incisor teeth and are used for digging, foraging, and defense.\n",
            "\n",
            "10. **Conservation Status**: Elephants are under threat from habitat loss and poaching. The African elephant is listed as Vulnerable, while the Asian elephant is Endangered according to the International Union for Conservation of Nature (IUCN).\n",
            "\n",
            "11. **Memory**: Elephants are often noted for their excellent memory. This ability helps them navigate vast territories and remember locations of water sources and seasonal food supplies.\n",
            "\n",
            "12. **Water Dependency**: Elephants are dependent on water for drinking and bathing. They are known to travel great distances to find water, especially during dry seasons.\n",
            "\n",
            "These characteristics highlight the complexity and majesty of elephants, which have intrigued and inspired humans for centuries.\n"
          ]
        }
      ],
      "source": [
        "from litellm import completion, ModelResponse\n",
        "\n",
        "def llm_call(prompt: str, llm_api_key: str, llm_model: str) -> ModelResponse:\n",
        "    response = completion(\n",
        "      model=llm_model,\n",
        "      api_key=llm_api_key,\n",
        "      messages=[{ \"content\": prompt,\"role\": \"user\"}]\n",
        "    )\n",
        "    return response\n",
        "\n",
        "prompt = # TODO Add a prompt here to call your LLM\n",
        "result = llm_call(prompt, LLM_API_KEY, LLM_MODEL)[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQhhd2TcPbyw"
      },
      "source": [
        "## Calling the LLM with Prompts\n",
        "\n",
        "Now that we have our LLM call, we can write the code to get input from the user and send it to the LLM.\n",
        "\n",
        "1. We ask the user for their research topic.\n",
        "2. Their input becomes the prompt sent directly to the LLM.\n",
        "3. The LLM processes the request and returns a research response.\n",
        "4. We display the results back to the user:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO4qfPdSOCyI",
        "outputId": "4a84e587-f273-4216-a7ff-679b352d3275"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the Research Report Generator!\n",
            "Enter your research topic or question: Give me 2 facts about elephants\n",
            "Research complete!\n",
            "--------------------------------------------------------------------------------\n",
            "Certainly! Here are two interesting facts about elephants:\n",
            "\n",
            "1. **Intelligent and Social Creatures**: Elephants are known for their high intelligence, demonstrated through complex social structures, problem-solving skills, and strong memories. They live in herds, typically led by a matriarch, and display behaviors such as empathy, mourning for their dead, and cooperative group dynamics.\n",
            "\n",
            "2. **Eco-Engineers**: Elephants play a crucial role in their ecosystems. By feeding on a wide variety of plants and knocking down trees, they help maintain the habitat for other species and assist in forest and savannah regeneration. Their dung is also vital as it helps in spreading seeds, fostering plant growth, and providing a nutrient-rich habitat for other organisms.\n"
          ]
        }
      ],
      "source": [
        "# Make the API call\n",
        "print(\"Welcome to the Research Report Generator!\")\n",
        "prompt = input(\"Enter your research topic or question: \")\n",
        "result = llm_call(prompt, LLM_API_KEY, LLM_MODEL)\n",
        "\n",
        "# Extract the response content\n",
        "response_content = result[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "print(\"Research complete!\")\n",
        "print(\"-\"*80)\n",
        "print(response_content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38_WrcVgNRNj"
      },
      "source": [
        "## From Prompts to Actions\n",
        "\n",
        "So far, our LLM can only generate text responses - it thinks and responds, but it can't *do* anything in the real world.\n",
        "\n",
        "What if we want our LLM to:\n",
        "- Search the web for the latest information?\n",
        "- Save the research report to a file?\n",
        "- Send the results via email?\n",
        "- Query a database or call an API?\n",
        "\n",
        "This is where **actions** come in."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7pd_Qnwa4BF"
      },
      "source": [
        "## What is an Action?\n",
        "\n",
        "An action is an external function that performs specific tasks beyond just generating text.\n",
        "\n",
        "Examples:\n",
        "- Information retrieval (web search, database query, file reading)\n",
        "- Communication tools (sending emails, post to Slack, sending text messages or notifications)\n",
        "- Data analysis tools (run calculations, generate charts and graphs)\n",
        "- Creative tools (image generation, document creation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FRm6vWYOQjx"
      },
      "source": [
        "## Building Your First Action\n",
        "\n",
        "Let's enhance our research application by adding an action that saves the results to a PDF. This will demonstrate how to move from just generating text to performing concrete actions with that text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "OIWZ5Vm5OW9e",
        "outputId": "92decaef-c152-453a-e75b-6fbe560251ce"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<img src=\"https://mermaid.ink/img/CmdyYXBoIExSCiAgICBBW1VzZXIgY2FsbHMgTExNXSAtLT4gQltHZW5lcmF0aW5nIGEgUERGIGZyb20gTExNIHJlc3BvbnNlXQo=\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "diagram = \"\"\"\n",
        "graph LR\n",
        "    A[User calls LLM] --> B[Generating a PDF from LLM response]\n",
        "\"\"\"\n",
        "render_mermaid(diagram)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFDnI_5GKZVq"
      },
      "source": [
        "## Generating a PDF\n",
        "\n",
        "Once you have your research data, you’ll call an action that takes the results and writes it out to a PDF.\n",
        "\n",
        "Remember, actions can interact with the outside world:\n",
        "- File operations (like this PDF generator)\n",
        "- API calls to external services\n",
        "- Database queries\n",
        "- Email sending\n",
        "- Web scraping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mcZJej_5Y8Nm",
        "outputId": "2f824233-d87e-4331-e512-b4690927d847"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'test.pdf'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Let's create our PDF generation action.\n",
        "## This function takes text content and formats it into a professional-looking PDF document:\n",
        "\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "from reportlab.lib.units import inch\n",
        "\n",
        "def create_pdf(content: str, filename: str = \"research_report.pdf\") -> str:\n",
        "    doc = SimpleDocTemplate(filename, pagesize=letter)\n",
        "\n",
        "    styles = getSampleStyleSheet()\n",
        "    title_style = ParagraphStyle(\n",
        "        'CustomTitle',\n",
        "        parent=styles['Heading1'],\n",
        "        fontSize=24,\n",
        "        spaceAfter=30,\n",
        "        alignment=1\n",
        "    )\n",
        "\n",
        "    story = []\n",
        "    title = Paragraph(\"Research Report\", title_style)\n",
        "    story.append(title)\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    paragraphs = content.split('\\n\\n')\n",
        "    for para in paragraphs:\n",
        "        if para.strip():\n",
        "            p = Paragraph(para.strip(), styles['Normal'])\n",
        "            story.append(p)\n",
        "            story.append(Spacer(1, 12))\n",
        "\n",
        "    doc.build(story)\n",
        "    return filename\n",
        "\n",
        "create_pdf(\"Hello PDF!\", filename=\"test.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf1eZE8LeRB5"
      },
      "source": [
        "## Open the PDF\n",
        "\n",
        "Download the `test.pdf` PDF and open it. You should see a title **Research Report** and the words **Hello PDF!** in the document.\n",
        "\n",
        "We'll next combine this with what we've seen already:\n",
        "1. We'll use the LLM to respond to a prompt\n",
        "2. Then, we'll call the `create_pdf` action to create a PDF with the response to your prompt!\n",
        "\n",
        "See how neat this is? Instead of just printing text to the console, your application now creates a tangible deliverable. You ask a question, get a response, and walk away with a professional PDF report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alyrd1xbiC4N"
      },
      "source": [
        "## Bringing it all Together\n",
        "\n",
        "You now have multiple functions that you can execute to achieve a task.\n",
        "Next, write the code to bring this all together:\n",
        "\n",
        "1. Use the LLM to respond to a prompt\n",
        "2. Call the `create_pdf` action to create a PDF with the response to your prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9dmy84DiQOD",
        "outputId": "0db4a975-b415-4712-85e4-0811d944af82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the Research Report Generator!\n",
            "Enter your research topic or question: Give me 2 facts about elephants\n",
            "SUCCESS! PDF created: research_report.pdf\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Call the `llm_call` function with `prompt`, `LLM_API_KEY`, and `LLM_MODEL` as arguments.\n",
        "# Step 2: Call the `create_pdf` function with `response_content` as the first argument.\n",
        "# Step 3: Run the code block to execute the program.\n",
        "\n",
        "# Make the API call\n",
        "print(\"Welcome to the Research Report Generator!\")\n",
        "prompt = input(\"Enter your research topic or question: \")\n",
        "result = llm_call() # TODO: Call the `llm_call` function with `prompt`, `LLM_API_KEY`, and `LLM_MODEL` as arguments.\n",
        "\n",
        "# Extract the response content\n",
        "response_content: str = result[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "pdf_filename = create_pdf('', \"research_report.pdf\") # Call the `create_pdf` function with `response_content` as the first argument.\n",
        "print(f\"SUCCESS! PDF created: {pdf_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nof__VYQeWJ",
        "outputId": "cd5d9cb4-cd1a-4eaa-c149-e108c6289db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Solution loaded:\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "```python\n",
              "# Expand for the solution\n",
              "\n",
              "# Make the API call\n",
              "print(\"Welcome to the Research Report Generator!\")\n",
              "prompt = input(\"Enter your research topic or question: \")\n",
              "result = llm_call(prompt, LLM_API_KEY, LLM_MODEL)\n",
              "\n",
              "# Extract the response content\n",
              "response_content: str = result[\"choices\"][0][\"message\"][\"content\"]\n",
              "\n",
              "pdf_filename = create_pdf(response_content, \"research_report.pdf\")\n",
              "print(f\"SUCCESS! PDF created: {pdf_filename}\")\n",
              "```"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the Research Report Generator!\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to load and execute the solution\n",
        "from pathlib import Path\n",
        "from IPython.display import display, Markdown\n",
        "import os\n",
        "\n",
        "notebook_dir = Path(os.getcwd())\n",
        "solution_file = notebook_dir / \"Solutions_01_Foundations_of_Durable_AI_with_Temporal\" / \"pdf_generation_solution.py\"\n",
        "\n",
        "if not solution_file.exists():\n",
        "    raise FileNotFoundError(f\"Solution file not found at {solution_file}\")\n",
        "\n",
        "code = solution_file.read_text()\n",
        "\n",
        "print(\"Solution loaded:\")\n",
        "display(Markdown(f\"```python\\n{code}\\n```\"))\n",
        "\n",
        "exec(code)\n",
        "print(\"Solution executed successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run this cell to load and execute the solution\n",
        "from pathlib import Path\n",
        "from IPython.display import display, Markdown\n",
        "import os\n",
        "\n",
        "notebook_dir = Path(os.getcwd())\n",
        "solution_file = notebook_dir / \"notebooks\" / \"02_MCP_Temporal_HITL_Solution\" / \"solution1.py\"\n",
        "\n",
        "if not solution_file.exists():\n",
        "    raise FileNotFoundError(f\"Solution file not found at {solution_file}\")\n",
        "\n",
        "code = solution_file.read_text()\n",
        "\n",
        "print(\"Solution loaded:\")\n",
        "display(Markdown(f\"```python\\n{code}\\n```\"))\n",
        "\n",
        "exec(code)\n",
        "print(\"Solution executed successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3GhdUXmiycf"
      },
      "source": [
        "## The Foundations of a Chain Workflow\n",
        "\n",
        "You now have the foundations of a chain workflow application. We chained an LLM call (`llm_call`) and action together (`create_pdf`) in a defined order (user input → LLM call → PDF generation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_26Y2tjERPHq"
      },
      "source": [
        "## Why Chain Workflows Need Durability\n",
        "\n",
        "Our simple chain workflow works great...until one of these happen:\n",
        "\n",
        "- The LLM call times out halfway through generating the research?\n",
        "- The PDF generation fails due to a file permission error?\n",
        "- Your network connection drops during processing?\n",
        "\n",
        "Right now, you'd have to start completely over. All the work is lost.\n",
        "\n",
        "As workflows grow more complex, this problem compounds:\n",
        "- **Longer chains**: User input → Web search → LLM analysis → Database query → PDF generation → Email delivery\n",
        "- **More failure points**: Each step can fail independently\n",
        "- **Expensive operations**: Re-running a 30-second LLM call because the last step failed wastes time and money\n",
        "- **External dependencies**: When your workflow calls external services or APIs, those can be unreliable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIkENgxorl8I"
      },
      "source": [
        "## Your Chain Workflow in Production\n",
        "\n",
        "What you built:\n",
        "- User input → LLM call → PDF generation\n",
        "- A simple 3-step chain\n",
        "\n",
        "In production, this becomes:\n",
        "- **Longer chains**: User input → Web search → LLM analysis → Database query → LLM refinement → PDF generation → Email delivery\n",
        "- **External dependencies**: APIs, databases, file systems\n",
        "- **Network failures**: Any step can fail\n",
        "- **Expensive retries**: Re-running a 30-second LLM call because step 5 failed\n",
        "\n",
        "When workflows get even more sophisticated, they evolve into **agentic systems** - where the LLM makes decisions about which actions to take next, potentially calling other specialized agents that themselves have complex workflows.\n",
        "\n",
        "For example: Research Agent → Executes web search → Observes results → Decides if it needs more data → Executes another search or moves to analysis → Observes → Decides next step → etc.\n",
        "\n",
        "Each agent has its own event loop (Plan → Execute → Observe):\n",
        "\n",
        "<img src=\"https://i.postimg.cc/1zhMS6YL/Loop.png\" width=\"300\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSvk4rUbaU-h"
      },
      "source": [
        "## Distributed System Issues\n",
        "\n",
        "Increasingly, we are seeing agents calling agents, which are calling other agents.\n",
        "\n",
        "For example, your research application might:\n",
        "a. Call a \"Web Scraper\" agent to gather sources (scrapes 5 research websites)\n",
        "b. Call a \"Fact Checker\" agent to verify claims (validates statistics against government data)\n",
        "c. Call a \"PDF Generator\" agent (what you built!)\n",
        "\n",
        "This means your \"simple\" research request triggers a complex orchestration.\n",
        "\n",
        "Now overlay what can go wrong: network partitions, timeouts, and service failures at any step can break the chain anywhere!\n",
        "\n",
        "<img src=\"https://i.postimg.cc/KzH2vx3y/agents-calling-agents.png\" width=\"500\"/>\n",
        "\n",
        "The bottom line: **What looks like one AI task is actually a distributed system challenge!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hcPLb8GWhpc"
      },
      "source": [
        "## Agents are Distributed Systems!\n",
        "\n",
        "**This is why durability matters.** Without it, complex workflows become fragile and expensive. With it, failures become manageable interruptions instead of catastrophic losses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl6jmr_tvG86"
      },
      "source": [
        "## AI Needs Durability\n",
        "\n",
        "  Your research application needs to:\n",
        "  1. Accept user input\n",
        "    - Possible problems: input validation service, rate limiting\n",
        "  2. Call the LLM for research\n",
        "    - Possible problems: Internet connection, API down, rate limiting, timeout\n",
        "  3. Generate PDF\n",
        "    - Possible problems: Memory limits\n",
        "  4. Return success/failure\n",
        "    - Possible problem: Connection dropped\n",
        "\n",
        "  Each step can fail.\n",
        "  Each step might need different agents.\n",
        "  This is a **workflow** - and workflows need orchestration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbw85OliybvN"
      },
      "source": [
        "---\n",
        "# Exercise 1 - Adding More Tools\n",
        "\n",
        "* In this exercise, you'll:\n",
        "  * Call an action with your agent\n",
        "  * Extract structured information from LLM responses to coordinate between different tools.\n",
        "* Go to the **Exercise** Directory in the Google Drive and open the **Practice** Directory\n",
        "* Open _01_Durable_AI_Foundations_Practice.ipynb.ipynb_ and follow the instructions and filling in the `TODO` statements.\n",
        "* If you get stuck, raise your hand and someone will come by and help. You can also check the `Solution` directory for the answers\n",
        "* **You have 5 mins**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (edu-ai-workshop-mcp)",
      "language": "python",
      "name": "edu-ai-workshop-mcp"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
