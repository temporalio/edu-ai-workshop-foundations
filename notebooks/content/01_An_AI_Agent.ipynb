{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9zkChjcPptZ"
   },
   "source": [
    "# Building an AI Agent\n",
    "\n",
    "In this workshop, we will do the following:\n",
    "- Define Agentic AI\n",
    "- Build an AI agent using tools\n",
    "- Understanding why agents are distributed systems\n",
    "- Identify distributed system challenges for AI agents\n",
    "- Recognize when agents become workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RyJ9MCfUkdGm"
   },
   "source": [
    "## Hands-on Moments\n",
    "\n",
    "This is a hands-on workshop!\n",
    "\n",
    "All of the instructors slides and code samples are are executable in the workshop notebooks.\n",
    "We encourage you to follow along and play with the samples!\n",
    "\n",
    "At the end of every chapter (notebook) will be a hands-on lab.\n",
    "This a self-guided experience where the instructor gives a prompt (not an llm haha) with a notebook and some starter code and the attendees solve the puzzle.\n",
    "\n",
    "We are going to create a Research Agent that makes a call to the OpenAI API, conducts research on a topic of your choice, and generates a PDF report from that research. Let's go ahead and first set up your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "mbEBnIn7H1Yg"
   },
   "outputs": [],
   "source": [
    "# We'll first install the necessary packages for this workshop.\n",
    "\n",
    "%pip install --quiet litellm reportlab python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mE2hcw8jugIe"
   },
   "outputs": [],
   "source": [
    "# Mermaid renderer, run at the beginning to setup rendering of diagrams\n",
    "import base64\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "def render_mermaid(graph_definition):\n",
    "    \"\"\"\n",
    "    Renders a Mermaid diagram in Google Colab using mermaid.ink.\n",
    "\n",
    "    Args:\n",
    "        graph_definition (str): The Mermaid diagram code (e.g., \"graph LR; A-->B;\").\n",
    "    \"\"\"\n",
    "    graph_bytes = graph_definition.encode(\"ascii\")\n",
    "    base64_bytes = base64.b64encode(graph_bytes)\n",
    "    base64_string = base64_bytes.decode(\"ascii\")\n",
    "    display(Image(url=\"https://mermaid.ink/img/\" + base64_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXp3VIAdZuhO"
   },
   "source": [
    "## Create a `.env` File\n",
    "\n",
    "Next you'll create a `.env` file to store your API keys.\n",
    "In the file browser on the left, create a new file and name it `.env`.\n",
    "\n",
    "**Note**: It may disappear as soon as you create it. This is because Google Collab hides hidden files (files that start with a `.`) by default.\n",
    "To make this file appear, click the icon that is a crossed out eye and hidden files will appear.\n",
    "\n",
    "Then double click on the `.env` file and add the following line with your API key.\n",
    "\n",
    "```\n",
    "LLM_API_KEY = YOUR_API_KEY\n",
    "LLM_MODEL = \"openai/gpt-4o\"\n",
    "```\n",
    "\n",
    "By default this notebook uses OpenAI's GPT-4o.\n",
    "If you want to use a different LLM provider, look up the appropriate model name [in their documentation](https://docs.litellm.ai/docs/providers) and change the `LLM_MODEL` field and provide your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tSl-K8ATXLJ3"
   },
   "outputs": [],
   "source": [
    "# Create .env file\n",
    "with open(\".env\", \"w\") as fh:\n",
    "    fh.write(\"LLM_API_KEY = YOUR_API_KEY\\nLLM_MODEL = openai/gpt-4o\")\n",
    "\n",
    "# Now open the file and replace YOUR_API_KEY with your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fy4s0KTRdWxL"
   },
   "outputs": [],
   "source": [
    "# Load environment variables and configure LLM settings\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Get LLM_API_KEY environment variable and print it to make sure that your .env file is properly loaded.\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"openai/gpt-4o\")\n",
    "LLM_API_KEY = os.getenv(\"LLM_API_KEY\", None)\n",
    "print(\"LLM API Key\", LLM_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18qFIGPokZO7"
   },
   "source": [
    "## What is an AI Agent?\n",
    "\n",
    "An autonomous system that pursues goals through continuous decision-making and action\n",
    "\n",
    "Think of an AI agent as an autonomous system that doesn't just respond once, but continuously works toward achieving a specific goal. Unlike traditional software that follows predetermined steps, an AI agent makes decisions dynamically based on the current situation and available information.\n",
    "\n",
    "An example is a customer support AI agent. The agent doesn't just execute a single function - it pursues the goal of \"resolving dispute and retain customer\" through ongoing decision-making until the situation is fully handled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKQTomi_ODQl"
   },
   "source": [
    "## Prompting the LLM\n",
    "\n",
    "Our agent will use LLM calls to process information and decide what actions to take.\n",
    "\n",
    "We use `litellm` here, which is a unified interface for over 100+ LLM providers. This means that the same code works with different models - you only need to change the model string. All you need to do is provide an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "3yhd-464Imwb"
   },
   "outputs": [],
   "source": [
    "from litellm import completion, ModelResponse\n",
    "\n",
    "\n",
    "def llm_call(prompt: str, llm_api_key: str, llm_model: str) -> ModelResponse:\n",
    "    response = completion(model=llm_model, api_key=llm_api_key, messages=[{\"content\": prompt, \"role\": \"user\"}])\n",
    "    return response\n",
    "\n",
    "\n",
    "# Change this to a fun prompt of your choice!\n",
    "prompt = \"Give me 5 fun Tardigrade facts in the form of a sea shanty.\"\n",
    "\n",
    "result = llm_call(prompt, LLM_API_KEY, LLM_MODEL)[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQhhd2TcPbyw"
   },
   "source": [
    "## Prompting the User\n",
    "\n",
    "Now that we have our LLM call, we can write the code to prompt the user for their research topic.\n",
    "\n",
    "1. We can write the code to prompt the user for their research topic.\n",
    "2. Their input becomes the prompt sent directly to the LLM.\n",
    "3. The LLM processes the request and returns a research response\n",
    "4. We display the results back to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dO4qfPdSOCyI"
   },
   "outputs": [],
   "source": [
    "# Make the API call\n",
    "print(\"Welcome to the Research Report Generator!\")\n",
    "prompt = input(\"Enter your research topic or question: \")\n",
    "result = llm_call(prompt, LLM_API_KEY, LLM_MODEL)\n",
    "\n",
    "# Extract the response content\n",
    "response_content = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "print(\"Research complete!\")\n",
    "print(\"-\" * 80)\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7pd_Qnwa4BF"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSZSA31HY2-p"
   },
   "source": [
    "## Generating a PDF\n",
    "\n",
    "Agents become powerful when they can perform actions beyond just generating text, and that is what a tool does.\n",
    "\n",
    "Once you have your research data, you'll write it out to a PDF. We'll use this later as a tool for our Agent to call.\n",
    "\n",
    "Tools are functions the agent can call to interact with the outside world:\n",
    "- File operations (like this PDF generator)\n",
    "- API calls to external services\n",
    "- Database queries\n",
    "- Email sending\n",
    "- Web scraping\n",
    "\n",
    "This transforms our agent from a chatbot into something that produces deliverable outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcZJej_5Y8Nm"
   },
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "\n",
    "\n",
    "def create_pdf(content: str, filename: str = \"research_report.pdf\") -> str:\n",
    "    doc = SimpleDocTemplate(filename, pagesize=letter)\n",
    "\n",
    "    styles = getSampleStyleSheet()\n",
    "    title_style = ParagraphStyle(\"CustomTitle\", parent=styles[\"Heading1\"], fontSize=24, spaceAfter=30, alignment=1)\n",
    "\n",
    "    story = []\n",
    "    title = Paragraph(\"Research Report\", title_style)\n",
    "    story.append(title)\n",
    "    story.append(Spacer(1, 20))\n",
    "\n",
    "    paragraphs = content.split(\"\\n\\n\")\n",
    "    for para in paragraphs:\n",
    "        if para.strip():\n",
    "            p = Paragraph(para.strip(), styles[\"Normal\"])\n",
    "            story.append(p)\n",
    "            story.append(Spacer(1, 12))\n",
    "\n",
    "    doc.build(story)\n",
    "    return filename\n",
    "\n",
    "\n",
    "create_pdf(\"Hello PDF!\", filename=\"test.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lf1eZE8LeRB5"
   },
   "source": [
    "## Open the PDF\n",
    "\n",
    "Download the `test.pdf` PDF and open it. You should see a title **Research Report** and the words **Hello PDF!** in the document.\n",
    "\n",
    "We'll next combine this with what we've seen already - we'll use our agent to respond to your prompt, then call the `create_pdf` tool to create a PDF with the response to your prompt!\n",
    "\n",
    "See how neat this is? Instead of just printing text to the console, your agent now creates a tangible deliverable. You ask a question, get a response, and walk away with a professional PDF report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alyrd1xbiC4N"
   },
   "source": [
    "## Bringing it all together\n",
    "\n",
    "You now have multiple functions that you can execute to achieve a task.\n",
    "Next, write the code to bring this all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9dmy84DiQOD"
   },
   "outputs": [],
   "source": [
    "# Make the API call\n",
    "print(\"Welcome to the Research Report Generator!\")\n",
    "prompt = input(\"Enter your research topic or question: \")\n",
    "result = llm_call(prompt, LLM_API_KEY, LLM_MODEL)\n",
    "\n",
    "# Extract the response content\n",
    "response_content: str = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "pdf_filename = create_pdf(response_content, \"research_report.pdf\")\n",
    "print(f\"SUCCESS! PDF created: {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3GhdUXmiycf"
   },
   "source": [
    "## The Foundations of an Agentic Application\n",
    "\n",
    "You now have the foundations of an Agentic AI application.\n",
    "\n",
    "What makes this agentic?\n",
    "1. It's goal-oriented: it has a clear objective (generate a research report)\n",
    "2. Tool usage: it combines multiple capabilities (LLM reasoning + PDF generation)\n",
    "3. Autonomous decision making: the LLM decides how to structure and present the research\n",
    "\n",
    "The functions you created are your \"tools\": `llm_call` and `create_pdf`. Some may think that an Agentic AI must have a loop, but that's not the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gnTPrw3yNcD"
   },
   "source": [
    "## Agentic Challenges\n",
    "\n",
    "However, there are a few significant challenges to getting production AI at scale.\n",
    "\n",
    "Your simple agent works great in demos, but production environments are messy and unpredictable.\n",
    "\n",
    "- Tool resources (APIs and databases) go down\n",
    "- Rate limitting on the LLM might cause it to fail, even if only intermittently\n",
    "- LLMs are inherently non-deterministic\n",
    "- Networks can go down.\n",
    "\n",
    "Imagine if the user asks for report → LLM times out → half-generated PDF → frustrated user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_26Y2tjERPHq"
   },
   "source": [
    "## Agents Don't Work in Isolation\n",
    "\n",
    "* They can call other agents which call other agents, creating complex networks. Each agent has its own logic and potential failure points.\n",
    "  * Example: Research Agent → Web Search Agent + Data Analysis Agent → Report Generator Agent\n",
    "* What starts as one simple request can cascade through multiple autonomous systems\n",
    "* Each of these nodes has its own event loop: plan/next step -> execute -> observe (see diagram below)\n",
    "* Network partitions, timeouts, and service failures at any step can break the chain anywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CLY0zS6DvjIQ"
   },
   "outputs": [],
   "source": [
    "diagram = \"\"\"\n",
    "graph LR\n",
    "    P[Plan/Next Step] --> E[Execute]\n",
    "    E --> O[Observe]\n",
    "    O --> P\n",
    "\"\"\"\n",
    "render_mermaid(diagram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-cD7kk0rTqL"
   },
   "source": [
    "## Agents Call Other Agents\n",
    "\n",
    " Your research agent might:\n",
    "  * Call a \"Web Scraper\" agent to gather sources\n",
    "  * Call a \"Fact Checker\" agent to verify claims\n",
    "  * Call a \"Citation\" agent to format references\n",
    "  * Call a \"PDF Generator\" agent (what you built!)\n",
    "\n",
    "This means your \"simple\" research request triggers a complex orchestration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zybamv7exKvw"
   },
   "source": [
    "## Example of Complex Orchestration\n",
    "\n",
    "User asks: \"Write a report on renewable energy trends\"\n",
    "\n",
    "1. Research Agent → Web Scraper Agent (scrapes 5 energy websites)\n",
    "2. Research Agent → Fact Checker Agent (validates statistics against government data)\n",
    "3. Research Agent → Citation Agent (formats 12 sources in APA style)\n",
    "4. Research Agent → PDF Generator Agent (creates final 8-page report)\n",
    "\n",
    "The problem: If any agent fails at step 2 or 3, you lose all the work from previous steps and have to start over. This can get expensive!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIkENgxorl8I"
   },
   "source": [
    "## Your Simple Agent in Production\n",
    "\n",
    "  What you built:\n",
    "  - 1 LLM call\n",
    "  - 1 PDF generation\n",
    "\n",
    "  In production, this becomes:\n",
    "  - Multiple LLM calls across different agents\n",
    "  - External API calls (web scraping, databases)\n",
    "  - File system operations\n",
    "  - Network failures at any step\n",
    "  - Need to coordinate responses from multiple agent\n",
    "\n",
    "The bottom line: What looks like one AI task is actually a distributed system challenge!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hcPLb8GWhpc"
   },
   "source": [
    "## Agents are Distributed Systems\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=1yynE1_HDDVuFQjaesFcxyds045MzTkfo' />\n",
    "<figcaption>The Truth About AI Agents</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fl6jmr_tvG86"
   },
   "source": [
    "## This is Why Agents == Workflows\n",
    "\n",
    "  Your research agent is actually:\n",
    "  1. Accept user input\n",
    "    - Possible problems: input validation service, rate limitting\n",
    "  2. Call the LLM for research\n",
    "    - Possible problems: Internet connection, API down, rate limitting, timeout\n",
    "  3. Generate PDF\n",
    "    - Possible problems: Memory limits\n",
    "  4. Return success/failure\n",
    "    - Possible problem: Connection dropped\n",
    "\n",
    "  Each step can fail.\n",
    "  Each step might need different agents.\n",
    "  This is a **workflow** - and workflows need orchestration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pbw85OliybvN"
   },
   "source": [
    "---\n",
    "# Exercise 1 - Adding More Tools\n",
    "\n",
    "* In this exercise, you'll:\n",
    "  * Call tools with your agent\n",
    "  *Extract structured information from LLM responses to coordinate between different tools.\n",
    "* Go to the **Exercise** Directory in the Google Drive and open the **Practice** Directory\n",
    "* Open _01-An-AI-Agent-Practice.ipynb_ and follow the instructions and filling in the `TODO` statements.\n",
    "* If you get stuck, raise your hand and someone will come by and help. You can also check the `Solution` directory for the answers\n",
    "* **You have 5 mins**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}