{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iy6hs6HQZY-Z"
   },
   "source": [
    "# Adding Durability with Temporal\n",
    "\n",
    "You've just built a research application that generates PDF reports. It works perfectly—until it doesn't.\n",
    "\n",
    "Imagine this: Your application conducts expensive research through an LLM call (costing time and money), but then **crashes** during PDF generation due to a network outage. When you restart, everything is lost. You're back to the beginning, paying for the same LLM call again, making your users wait, and burning through your API budget.\n",
    "\n",
    "As these workflows grow more complex—chaining multiple LLM calls, database queries, external APIs—the problem compounds. Every failure means starting over completely.\n",
    "\n",
    "In this section, we'll solve this problem by making your application durable. You'll learn how to build GenAI applications that survive failures, recover automatically, and never lose progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKIuzLjvucLf"
   },
   "source": [
    "### Challenges of GenAI Applications\n",
    "\n",
    "* Networks can be flakey\n",
    "* LLMs are often rate limited\n",
    "* Tool resources (APIs and databases) go down\n",
    "* LLMs are inherently non-deterministic\n",
    "* How do we scale these applications?\n",
    "* What happens when they take a long time to finish?\n",
    "…\n",
    "What else?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQOR9QLGZ_hw"
   },
   "source": [
    "### These Aren't New Problems\n",
    "\n",
    "The challenges you just identified? They're the same problems we've been solving in distributed systems for decades:\n",
    "\n",
    "**Your Research Application in Production Reality:**\n",
    "* **LLM API call** - External service that can timeout, rate limit, or be down.\n",
    "* **PDF generation** - File system operation that can fail due to disk space\n",
    "* **User input/output** - Network operations that can be interrupted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01ZkJPjC7njg"
   },
   "source": [
    "### GenAI Applications are Distributed Systems!\n",
    "\n",
    "**This is a distributed system!** Your \"simple\" application is actually:\n",
    "* Multiple network calls to external services\n",
    "* File system operations\n",
    "* State that needs to persist across failures\n",
    "* Coordination between different steps\n",
    "\n",
    "**The challenge:** Traditional distributed systems tools weren't designed for AI workflows. They don't understand expensive LLM calls, context windows, or long-term state management.\n",
    "\n",
    "**The good news:** You can use a platform that guarantees the _reliable execution_ of your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Normal Execution Gives Us\n",
    "\n",
    "* Every failure means restarting from scratch\n",
    "* Expensive LLM calls are repeated unnecessarily\n",
    "* User experience becomes frustrating and unreliable\n",
    "* No way to resume from where you left off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Developers Actually Want\n",
    "\n",
    "* \"Just fix the disk issue and generate the PDF from the research you already have.\"\n",
    "* \"Don't make me pay for the same LLM call twice!\"\n",
    "* \"Don't lose my work because of a simple file system error!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_1jsgtvaLJ1"
   },
   "source": [
    "### Your Report Generation Application Needs Durability\n",
    "\n",
    "Recall your research application from Notebook 1? Here's what happens in production:\n",
    "\n",
    "**Scenario:** User asks for research on \"sustainable energy trends\":\n",
    "\n",
    "1. LLM call succeeds - generates comprehensive research content ($2.50 in API costs)\n",
    "2. PDF generation fails - disk full, permission error, or process crash\n",
    "3. User has to start over completely - losing expensive work and time\n",
    "\n",
    "We need a way to make our AI applications resilient to these failures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing Temporal\n",
    "\n",
    "- Technology and open source project that delivers resilience for distributed systems in a novel way.\n",
    "- Supports a programming model that allows developers to code the **happy path**, while the platform provides services that compensate for a wide range of distributed system failures.\n",
    "- Platform comes in the form of a service + SDKs\n",
    "- SDK is available for Go, Java, Python, PHP, Typescript, .Net, Ruby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Make Your GenAI Application Durable\n",
    "\n",
    "We're about to transform your simple research application into a durable one. Here's what changes:\n",
    "\n",
    "* Your tools will become crash-proof\n",
    "* Automatic retries and recovery\n",
    "* State persistence\n",
    "\n",
    "This results in a process such as:\n",
    "LLM Decision → Tool A → Result X (Saved in history, then on replay, same result X will result in the same next decision) → Next Decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What stays the same\n",
    "\n",
    "* Your core logic (LLM call → PDF generation)\n",
    "* Your inputs and outputs\n",
    "* Your business requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Our Inputs & Outputs for Ease of Management\n",
    "\n",
    "For ease of use, evolution of parameters, and type checking, Temporal recommends passing and returning a single object from functions. `dataclass` is the recommended structure here, but anything serializable will work.\n",
    "\n",
    "_Read more about inputs and outputs in [this chapter](https://temporal.talentlms.com/unit/view/id:2822) of our free Temporal 102 course._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run this code block to load it into the program\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class LLMCallInput:\n",
    "  prompt: str\n",
    "  llm_api_key: str\n",
    "  llm_model: str\n",
    "\n",
    "@dataclass\n",
    "class PDFGenerationInput:\n",
    "  content: str\n",
    "  filename: str = \"research_pdf.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is an Activity?\n",
    "\n",
    "* Functions that are making external calls are “wrapped” as activities\n",
    "* An Activity is a function that is prone to failure and/or non-deterministic.\n",
    "* Temporal requires all non-deterministic code be run in an Activity\n",
    "\n",
    "Examples:\n",
    "  - External API calls - LLM requests, web scraping, database queries\n",
    "  - File system operations - Reading documents, writing reports, managing storage\n",
    "  - Network operations - HTTP requests, email sending, data transfers\n",
    "  - Resource-intensive computations - Image processing, data analysis, model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Activities Give You\n",
    "\n",
    "* [**Automatic retries**](https://docs.temporal.io/develop/python/failure-detection#activity-retries) when external code fails\n",
    "* [**Timeout handling**](https://docs.temporal.io/develop/python/failure-detection#activity-timeouts) for slow operations and detecting failures\n",
    "* **Detailed visibility** of execution, including inputs/outputs for debugging\n",
    "* **Automatic checkpoints** - if your workflow crashes, Activities aren't re-executed. Instead, your Workflow continues from the last known good state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks/Tools become Activities\n",
    "\n",
    "- To turn a function/method into an Activity, add the `@activity.defn` decorator.\n",
    "- Package activity arguments into a data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As an Activity, Your LLM Call is Now:\n",
    "* Protected against API timeouts\n",
    "* Automatically retried with backoff\n",
    "* Observable for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As an Activity, Your PDF Generation is Now:\n",
    "* Protected against file system errors\n",
    "* Automatically retried if temporary failures\n",
    "* Tracked for completion verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Create Activities.\n",
    "\n",
    "But first, let's set up our notebook. Run the following code blocks to install various packages and tools necessary to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/azhou/Desktop/edu-ai-workshop-mcp/env/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# We'll first install the necessary packages for this workshop.\n",
    "\n",
    "%pip install --quiet temporalio litellm reportlab python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a `.env` File\n",
    "\n",
    "Next you'll create a `.env` file to store your API keys.\n",
    "In the file browser on the left, create a new file and name it `.env`.\n",
    "Note that this file doesn't persist across notebooks or sesions.\n",
    "\n",
    "**Note**: It may disappear as soon as you create it. This is because Google Collab hides hidden files (files that start with a `.`) by default.\n",
    "To make this file appear, click the icon that is a crossed out eye and hidden files will appear.\n",
    "\n",
    "Then double click on the `.env` file and add the following line with your API key.\n",
    "\n",
    "```\n",
    "LLM_API_KEY = YOUR_API_KEY\n",
    "LLM_MODEL = \"openai/gpt-4o\"\n",
    "```\n",
    "\n",
    "By default this notebook uses OpenAI's GPT-4o.\n",
    "If you want to use a different LLM provider, look up the appropriate model name [in their documentation](https://docs.litellm.ai/docs/providers) and change the `LLM_MODEL` field and provide your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .env file\n",
    "with open(\".env\", \"w\") as fh:\n",
    "  fh.write(\"LLM_API_KEY = YOUR_API_KEY\\nLLM_MODEL = openai/gpt-4o\")\n",
    "\n",
    "# Now open the file and replace YOUR_API_KEY with your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM API Key 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\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables and configure LLM settings\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Get LLM_API_KEY environment variable and print it to make sure that your .env file is properly loaded.\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"openai/gpt-4o\")\n",
    "LLM_API_KEY = os.getenv(\"LLM_API_KEY\", None)\n",
    "print(\"LLM API Key\", LLM_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This allows us to run the Temporal Asyncio event loop within the event loop of Jupyter Notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mtemporal:\u001b[0m Downloading Temporal CLI latest\n",
      "\u001b[1mtemporal:\u001b[0m Temporal CLI installed at /Users/azhou/.temporalio/bin/temporal\n",
      "\u001b[1mtemporal:\u001b[0m For convenience, we recommend adding it to your PATH\n",
      "\u001b[1mtemporal:\u001b[0m If using bash, run echo export PATH=\"\\$PATH:/Users/azhou/.temporalio/bin\" >> ~/.bashrc\n"
     ]
    }
   ],
   "source": [
    "# Running this will download the Temporal CLI, which we need for this workshop.\n",
    "\n",
    "!curl -sSf https://temporal.download/cli.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "doN_2Wzganj5"
   },
   "outputs": [],
   "source": [
    "# Let's Create Activities\n",
    "# TODO: Run this code block to load it into the program\n",
    "from temporalio import activity\n",
    "from litellm import completion, ModelResponse\n",
    "\n",
    "@activity.defn\n",
    "def llm_call(input: LLMCallInput) -> ModelResponse:\n",
    "    response = completion(\n",
    "      model=input.llm_model,\n",
    "      api_key=input.llm_api_key,\n",
    "      messages=[{ \"content\": input.prompt,\"role\": \"user\"}]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_OOx3-Y4lkkW"
   },
   "outputs": [],
   "source": [
    "# Step 1: Make the code an Activity. Look at the cell below for the solution.\n",
    "# Step 2: Now run the code to load it into the program\n",
    "\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "\n",
    "def create_pdf_activity(input: PDFGenerationInput) -> str:\n",
    "    print(\"Creating PDF document...\")\n",
    "\n",
    "    doc = SimpleDocTemplate(input.filename, pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "    title_style = ParagraphStyle(\n",
    "        'CustomTitle',\n",
    "        parent=styles['Heading1'],\n",
    "        fontSize=24,\n",
    "        spaceAfter=30,\n",
    "        alignment=1\n",
    "    )\n",
    "\n",
    "    story = []\n",
    "    title = Paragraph(\"Research Report\", title_style)\n",
    "    story.append(title)\n",
    "    story.append(Spacer(1, 20))\n",
    "    paragraphs = input.content.split('\\n\\n')\n",
    "    for para in paragraphs:\n",
    "        if para.strip():\n",
    "          p = Paragraph(para.strip(), styles['Normal'])\n",
    "          story.append(p)\n",
    "          story.append(Spacer(1, 12))\n",
    "\n",
    "    doc.build(story)\n",
    "\n",
    "    print(f\"SUCCESS! PDF created: {input.filename}\")\n",
    "    return input.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution loaded:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from reportlab.lib.pagesizes import letter\n",
       "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
       "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
       "from reportlab.lib.units import inch\n",
       "\n",
       "@activity.defn\n",
       "def create_pdf_activity(input: PDFGenerationInput) -> str:\n",
       "    print(\"Creating PDF document...\")\n",
       "\n",
       "    doc = SimpleDocTemplate(input.filename, pagesize=letter)\n",
       "    styles = getSampleStyleSheet()\n",
       "    title_style = ParagraphStyle(\n",
       "        'CustomTitle',\n",
       "        parent=styles['Heading1'],\n",
       "        fontSize=24,\n",
       "        spaceAfter=30,\n",
       "        alignment=1\n",
       "    )\n",
       "\n",
       "    story = []\n",
       "    title = Paragraph(\"Research Report\", title_style)\n",
       "    story.append(title)\n",
       "    story.append(Spacer(1, 20))\n",
       "    paragraphs = input.content.split('\\n\\n')\n",
       "    for para in paragraphs:\n",
       "        if para.strip():\n",
       "          p = Paragraph(para.strip(), styles['Normal'])\n",
       "          story.append(p)\n",
       "          story.append(Spacer(1, 12))\n",
       "\n",
       "    doc.build(story)\n",
       "\n",
       "    print(f\"SUCCESS! PDF created: {input.filename}\")\n",
       "    return input.filename\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_02_Adding_Durability_with_Temporal\" / \"create_pdf_activity_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KF98wlHSKnak"
   },
   "source": [
    "### Activities Are Called from Workflows\n",
    "\n",
    "- You orchestrate the execution of your Activities from within a [Workflow](https://docs.temporal.io/workflow-definition#workflow-definition).\n",
    "- Workflows contain the decision-making flow, but Activities perform the actual work.\n",
    "- Each Activity call is recorded in the workflow history with inputs and outputs\n",
    "- Workflows can wait for activity completion, handle failures, and make decisions based on results\n",
    "\n",
    "<img src=\"https://i.postimg.cc/yxW08BHD/activity-workflow-chain.png\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Workflow\n",
    "\n",
    "* Activities are orchestrated within a Temporal Workflow.\n",
    "* Workflows must **not** make API calls, file system calls, or anything non-deterministic. That is what Activities are for.\n",
    "* Workflows are async, and you define them as a class decorated with the `@workflow.defn` decorator.\n",
    "* Every Workflow has a **single** entry point, which is an `async` method decorated with `@workflow.run`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlWk6DY63Ehg"
   },
   "source": [
    "### More Input/Output Packaging\n",
    "\n",
    "Just like with Activities, Temporal recommends passing a single object to the Workflow for input and returning a single object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0mesIIXMMkNG"
   },
   "outputs": [],
   "source": [
    "# TODO: Run this code block to load it into the program\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class GenerateReportInput:\n",
    "    prompt: str\n",
    "\n",
    "@dataclass\n",
    "class GenerateReportOutput:\n",
    "    result: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tq0aUW3OQkS"
   },
   "outputs": [],
   "source": [
    "# Step 1: Notice how the Workflow calls the `llm_call` Activity. \n",
    "# Follow the pattern to call the `create_pdf_activity`.\n",
    "# Step 3: Pass in your pdf_generation_input\n",
    "# Step 4: A Start-to-Close timeout is the maximum amount of time a single Activity Execution can take. We recommend always setting this timeout.\n",
    "# Set a Start-to-Close timeout of 10 seconds for the `create_pdf_activity`.\n",
    "# Step 5: Run this code block to load it into the program\n",
    "from datetime import timedelta\n",
    "from temporalio import workflow\n",
    "\n",
    "# sandboxed=False is a Notebook only requirement. You normally don't do this\n",
    "@workflow.defn(sandboxed=False)\n",
    "class GenerateReportWorkflow:\n",
    "\n",
    "    @workflow.run\n",
    "    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n",
    "\n",
    "        llm_call_input = LLMCallInput(prompt=input.prompt, llm_api_key=LLM_API_KEY, llm_model=LLM_MODEL)\n",
    "\n",
    "        research_facts = await workflow.execute_activity(\n",
    "            llm_call,\n",
    "            llm_call_input,\n",
    "            start_to_close_timeout=timedelta(seconds=30), # maximum amount of time a single Activity Execution can take.\n",
    "        )\n",
    "\n",
    "        workflow.logger.info(\"Research complete!\")\n",
    "\n",
    "        pdf_generation_input = PDFGenerationInput(content=research_facts[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "        pdf_filename = await workflow.execute_activity(\n",
    "            # TODO: Call the create_pdf_activity here\n",
    "            # TODO: Pass in your pdf_generation_input\n",
    "            # TODO: Set the Start-to-Close timeout of 10 seconds here\n",
    "        )\n",
    "\n",
    "        return GenerateReportOutput(result=f\"Successfully created research report PDF: {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_02_Adding_Durability_with_Temporal\" / \"generatereportworkflow_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0gKu3eSQxbO"
   },
   "source": [
    "### Temporal Workers\n",
    "\n",
    "* Temporal Workflows are run on [Workers](https://docs.temporal.io/workers)\n",
    "* Workers wait for tasks to do, such as an Activity or Workflow Task, and execute them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a Worker\n",
    "\n",
    "* Workers have Workflows and Activities registered to them so the Worker knows what to execute.\n",
    "* Workers find tasks by listenting on a Task Queue\n",
    "* Any Worker can pick up a registered Workflow or Activity\n",
    "\n",
    "The Worker architecture turns your monolith into a modular, event driven application!\n",
    "\n",
    "<img src=\"https://i.postimg.cc/dQZZNGPg/worker-architecture.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a Temporal Service\n",
    "\n",
    "* The Temporal Service brings it all together\n",
    "* The Temporal Service can be run locally, self-hosted, or you can use Temporal Cloud\n",
    "* The service acts as the supervisor of your Workflows, Activities, and everything else\n",
    "\n",
    "**To run the Temporal Server in this exercise environment**:\n",
    "1. You should have the Temporal Server running in your terminal (run `temporal server start-dev` if not).\n",
    "2. Then in your `Ports` tab on the bottom of this screen, find `8233` and click on the Globe icon to open the Temporal Web UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Durable Execution\n",
    "\n",
    "Instead of event-driven architecture, define your workflow as code and let the system track exactly where you are. Write for the happy path—no need to manage queues, events, retries, rollbacks, or state checkpoints. With durable execution, you can just focus on business logic.\n",
    "\n",
    "<img src=\"https://i.postimg.cc/635g59w5/durable-execution-example.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZB5mZ3HxOk6u"
   },
   "outputs": [],
   "source": [
    "# Here is code for our Worker\n",
    "# Step 1: Pass in our two Activities into the list to register them with the Worker\n",
    "# Step 2: Set the task queue that the Worker is polling to be \"research\"\n",
    "# Step 3: Run this codeblock to load it into the program\n",
    "Run this code block to load it into the program\n",
    "import concurrent.futures\n",
    "from temporalio.client import Client\n",
    "from temporalio.worker import Worker\n",
    "\n",
    "async def run_worker() -> None:\n",
    "    # Create client connected to server at the given address\n",
    "    client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "    # Run the Worker\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as activity_executor:\n",
    "        worker = Worker(\n",
    "            client,\n",
    "            task_queue=\"research\", # TODO Set the task queue that the Worker is polling to be \"research\"\n",
    "            workflows=[GenerateReportWorkflow], # register the Workflow\n",
    "            activities=[llm_call, create_pdf_activity], # TODO register the Activities\n",
    "            activity_executor=activity_executor\n",
    "        )\n",
    "\n",
    "        print(f\"Starting the worker....\")\n",
    "        await worker.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_02_Adding_Durability_with_Temporal\" / \"worker_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FB4oDvu7Nbwm"
   },
   "source": [
    "### Starting the Worker\n",
    "\n",
    "A Workflow can't execute if a Worker isn't running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZiLuWj_Q0XR"
   },
   "outputs": [],
   "source": [
    "# Due to the limitation of Jupyter Notebooks and Google Collab, this is how\n",
    "# you must start the worker in a Notebook environment\n",
    "import asyncio\n",
    "\n",
    "worker = asyncio.create_task(run_worker())\n",
    "\n",
    "# If you are running this code in a typical Python environment, you can start\n",
    "# the Worker by just calling `asyncio.run`\n",
    "# if __name__ == \"__main__\":\n",
    "#    asyncio.run(run_worker())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing the Workflow\n",
    "\n",
    "- Temporal Workflows are executed indirectly\n",
    "- Request execution from the Temporal Service\n",
    "- You do this with the [Temporal Client](https://docs.temporal.io/develop/python/temporal-client)\n",
    "\n",
    "<img src=\"https://i.postimg.cc/76Mdqfjd/client.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTOOaYd8UnBL",
    "outputId": "b23a7ac2-7329-436b-cd65-098549037771"
   },
   "outputs": [],
   "source": [
    "# Step 1: Set the Task Queue to be the Task Queue that your Worker is polling\n",
    "# Step 2: Run this code block to load it into the program\n",
    "from temporalio.client import Client\n",
    "import uuid\n",
    "\n",
    "# Create client connected to server at the given address\n",
    "client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "print(\"Welcome to the Research Report Generator!\")\n",
    "prompt = input(\"Enter your research topic or question: \").strip()\n",
    "\n",
    "if not prompt:\n",
    "    prompt = \"Give me 5 fun and fascinating facts about tardigrades. Make them interesting and educational!\"\n",
    "    print(f\"No prompt entered. Using default: {prompt}\")\n",
    "\n",
    "# Asynchronous start of a Workflow\n",
    "handle = await client.start_workflow(\n",
    "    GenerateReportWorkflow,\n",
    "    GenerateReportInput(prompt=prompt),\n",
    "    id=f\"generate-research-report-workflow-{uuid.uuid4()}\", # user-defined Workflow identifier, which typically has some business meaning\n",
    "    task_queue=\"\", # TODO: Set the Task Queue to be the Task Queue that your Worker is polling\n",
    ")\n",
    "\n",
    "print(f\"Started workflow. Workflow ID: {handle.id}, RunID {handle.result_run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_02_Adding_Durability_with_Temporal\" / \"client_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvM082EAtXZv"
   },
   "source": [
    "### Getting the Result\n",
    "\n",
    "The example above uses async execution. You can `await` the handle to get the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VODi5uGZAj3j",
    "outputId": "50cd4396-b6e6-42ed-8e6a-5dbdefd517cb"
   },
   "outputs": [],
   "source": [
    "# Get the result\n",
    "result = await handle.result()\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "# To download the report: right click `research_pdf.pdf` in your file explore, then click `Download`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4gwjNk6wx-L"
   },
   "source": [
    "### Temporal Web UI\n",
    "\n",
    "- Temporal provides a robust [Web UI](https://docs.temporal.io/web-ui) for managing Workflow Executions\n",
    "- Can gain insights like responses from Activities, execution time, and failures\n",
    "- Great for debugging and understanding what's happening during your Workflow Executions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsOEZDrgGefo"
   },
   "source": [
    "### Exploring the Web UI\n",
    "\n",
    "Can you locate the following items on the Web UI?\n",
    "\n",
    "- The name of the Task Queue\n",
    "- The name of the two Activities called\n",
    "- The inputs and outputs of the called Activities\n",
    "- Input and output of the Workflow Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo (Expand for instructor notes or to run on your own)\n",
    "<!--\n",
    "Normal Execution Demo:\n",
    "1. To demonstrate the power of durable execution, we'll first show the power of running the app with no durable execution. This is the code that we showed in the first notebook.\n",
    "2. Clone this repository: `https://github.com/temporalio/edu-ai-workshop-agentic-loop`. The instructions will also be in the README.\n",
    "2. From the `demos/module_one_01_foundations_aiic_loop/app.py` directory, run `app.py` with `python app.py`.\n",
    "3. When prompted, provide the prompt you want to prompt OpenAI in the command line.\n",
    "4. Before the process generates a PDF, kill the process.\n",
    "5. Rerun the application again with `python app.py` and show that the process restarted and you have to have your application start the research again. Emphasize that from a cost perspective, this could be very costly, because you could have to re-run through many tokens to get to where you left off.\n",
    "\n",
    "Durable Execution Demo:\n",
    "1. Now show the durable version by switching into the ``demos/module_one_02_adding_durability` directory.\n",
    "2. Run the Worker with `python worker.py`.\n",
    "3. Run the Workflow with `python workflow.py`.\n",
    "4. When prompted, provide the prompt you want to prompt OpenAI in the command line.\n",
    "5. Before the process generates a PDF, kill the Worker.\n",
    "6. Rerun the Worker and show that you continue right where you left off.\n",
    "7. Emphasize that you lost no progress or data. The Workflow will continue by generating the PDF (available in the same directory) and completing the process successfully.\n",
    "10. Show the Workflow Execution completion in the Web UI.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Durable Execution?\n",
    "\n",
    "* [Durable execution](https://docs.temporal.io/evaluate/understanding-temporal) is crash-proof execution\n",
    "* Retries upon failure\n",
    "* Maintains application state, resuming after a crash at the point of failure\n",
    "* Can run across a multitude of processes, even on different machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Provides Durable Execution\n",
    "\n",
    "* Handles state, retries, timeouts, state preservation right out the box\n",
    "* Open-source MIT licensed\n",
    "* Code base approach to Workflow design\n",
    "  - Instead of building custom orchestration systems, you write normal functions.\n",
    "  - Since it’s a general purpose programming language, there are no abstractions to get in your way. Since AI patterns will continue to evolve, general-purpose programming languages will be as well-suited to implement these new patterns.\n",
    "* Use your own tools, processes, and libraries\n",
    "* Support for 7 languages (Python, Go, C#, Java, TypeScript, Ruby, PHP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZIR7OS4Nk-U"
   },
   "source": [
    "### Simulating Failure\n",
    "\n",
    "What happens if the Worker process were to crash during execution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stu--jIeNwUY"
   },
   "source": [
    "### Adding a Durable Timer\n",
    "\n",
    "- Timers introduce delays in your Workflow with guaranteed execution.\n",
    "- Durable timers will fire even if there is no Worker running, and persists despite restarts and infrastructure failures\n",
    "- Let's add one to the Workflow to give us time to kill the Worker in the middle of execution.\n",
    "\n",
    "_Read more about durable Timers in [this chapter](https://temporal.talentlms.com/unit/view/id:3077) of our free Temporal 102 course._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RbkxjA4TNvXm"
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "from temporalio import workflow\n",
    "\n",
    "# sandboxed=False is a Notebook only requirement. You normally don't do this\n",
    "@workflow.defn(sandboxed=False)\n",
    "class GenerateReportWorkflow:\n",
    "\n",
    "    @workflow.run\n",
    "    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n",
    "\n",
    "        llm_call_input = LLMCallInput(prompt=input.prompt, llm_api_key=LLM_API_KEY, llm_model=LLM_MODEL)\n",
    "\n",
    "        research_facts = await workflow.execute_activity(\n",
    "            llm_call,\n",
    "            llm_call_input,\n",
    "            start_to_close_timeout=timedelta(seconds=30),\n",
    "        )\n",
    "\n",
    "        workflow.logger.info(\"Research complete!\")\n",
    "\n",
    "        # Adding a Timer here to pause the Workflow Execution\n",
    "        await workflow.sleep(timedelta(seconds=20))\n",
    "\n",
    "        pdf_generation_input = PDFGenerationInput(content=research_facts[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "        pdf_filename = await workflow.execute_activity(\n",
    "            create_pdf_activity,\n",
    "            pdf_generation_input,\n",
    "            start_to_close_timeout=timedelta(seconds=10),\n",
    "        )\n",
    "\n",
    "        return GenerateReportOutput(result=f\"Successfully created research report PDF: {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEMJDMaYOpek"
   },
   "source": [
    "### Restart the Worker\n",
    "\n",
    "- After a Workflow change, you must restart the Worker for the change to take effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miEibF-kT5Ap",
    "outputId": "3b9b5f53-7102-4685-b099-1eb980b17e93"
   },
   "outputs": [],
   "source": [
    "# Run this to kill the current Worker\n",
    "x = worker.cancel()\n",
    "\n",
    "if x:\n",
    "  print(\"Worker killed\")\n",
    "else:\n",
    "  print(\"Worker was not running. Nothing to kill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2AlPpWHBOx4-",
    "outputId": "3aedc295-c157-48f5-f5d3-a0e2f970875e"
   },
   "outputs": [],
   "source": [
    "# Starting the Worker again\n",
    "import asyncio\n",
    "\n",
    "worker = asyncio.create_task(run_worker())\n",
    "\n",
    "# Check if the task is in the set of all tasks\n",
    "if worker in asyncio.all_tasks():\n",
    "    # The sleep is necessary because of the async task scheduling in Jupyter\n",
    "    print(\"Task is currently active.\") # The Worker now registers the updated Workflow changes\n",
    "else:\n",
    "    print(\"Task is not found in active tasks (might have finished or not yet scheduled).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfGUkFh_O4wI"
   },
   "source": [
    "### Start the Workflow and Simulate an Error\n",
    "\n",
    "Start the Workflow again, prompt the LLM, wait about ~5 seconds to let the Timer start, then kill the Worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A9U5eLhjPFzj",
    "outputId": "4439423c-b275-4ea7-96b5-d04776f55ae1"
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "print(\"Welcome to the Research Report Generator!\")\n",
    "prompt = input(\"Enter your research topic or question: \").strip()\n",
    "\n",
    "if not prompt:\n",
    "    prompt = \"Give me 5 fun and fascinating facts about tardigrades. Make them interesting and educational!\"\n",
    "    print(f\"No prompt entered. Using default: {prompt}\")\n",
    "\n",
    "# Asynchronous start of a Workflow\n",
    "handle = await client.start_workflow(\n",
    "    GenerateReportWorkflow.run,\n",
    "    GenerateReportInput(prompt=prompt),\n",
    "    id=f\"generate-research-report-workflow-{uuid.uuid4()}\",\n",
    "    task_queue=\"research\",\n",
    ")\n",
    "\n",
    "print(f\"Started workflow. Wait about ~4 seconds to let the Timer start, then kill the Worker.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hFrX4DPmxYrc",
    "outputId": "ccb72f79-f87a-4b3c-e8e8-63690832209a"
   },
   "outputs": [],
   "source": [
    "# After about 5 seconds, run this to kill the current Worker\n",
    "x = worker.cancel()\n",
    "\n",
    "if x:\n",
    "  print(\"Worker killed\")\n",
    "else:\n",
    "  print(\"Worker was not running. Nothing to kill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0xnVjylPj6k"
   },
   "source": [
    "### Watch the Progress in the Web UI\n",
    "\n",
    "Refresh your Web UI, click on the running Workflow Execution, and watch the progress. What do you observe? Does the Timer complete despite the Worker being kiled?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99gwelS1P4iz"
   },
   "source": [
    "### Restart the Worker to Resume Execution\n",
    "\n",
    "- Restart the Worker and return to the WebUI.\n",
    "  * What do you think will happen?\n",
    "- You will see the Workflow pick up where it left off as if nothing happened!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6czqh6bP-u5"
   },
   "outputs": [],
   "source": [
    "# Starting the Worker again\n",
    "import asyncio\n",
    "\n",
    "worker = asyncio.create_task(run_worker())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Durable execution - State Preservation\n",
    "\n",
    "Temporal relies on a [Replay mechanism](https://docs.temporal.io/encyclopedia/event-history/event-history-python) to recover from failure.\n",
    "As your program progresses, Temporal saves the input and output from function calls to the history.\n",
    "This allows a failed program to restart right where it left off.\n",
    "This can also save us a lot of money since we aren't re-burning through tokens!\n",
    "\n",
    "For example:\n",
    "\n",
    "User request: \"Research sustainable energy trends\"\n",
    "✓ Step 1: LLM research call → Output saved to history\n",
    "✓ Step 2: Generate summary → Output saved to history  \n",
    "✗ Step 3: Create PDF → CRASH!\n",
    "\n",
    "On restart:\n",
    "- Temporal replays Steps 1 & 2 from history (no actual execution)\n",
    "- Continues from Step 3 with the same inputs\n",
    "\n",
    "_Read more about how Replay works in [this chapter](https://temporal.talentlms.com/unit/view/id:2847) of our free Temporal 102 course._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pbw85OliybvN"
   },
   "source": [
    "--\n",
    "\n",
    "# Exercise 2 - Adding Durability\n",
    "\n",
    "* In these exercises you will:\n",
    "  * Transform your LLM calls and your execution of tools to Activities\n",
    "  * Use a Temporal Workflow to orchestrate your Activities\n",
    "  * Observe how Temporal handles your errors\n",
    "  * Debug your error and observe your Workflow Execution successfully complete\n",
    "* Go to the **Exercise** Directory in the Google Drive and open the **Practice** Directory\n",
    "* Open _02-Adding-Durability.ipynb_ and follow the instructions\n",
    "* If you get stuck, raise your hand and someone will come by and help. You can also check the `Solution` directory for the answers\n",
    "* **You have 5 mins**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## What's Next?\n",
    "\n",
    "This workshop introduced you to the **concept** of Temporal. Further your learning with these resources:\n",
    "\n",
    "### Resources\n",
    "\n",
    "- Our free [Temporal 102 Course](https://learn.temporal.io/courses/temporal_102/python/) which covers these concepts (Workflows, Activities, Replay, Timers and more) in more detail\n",
    "- A Temporal [tutorial in the Python SDK](https://learn.temporal.io/getting_started/python/hello_world_in_python/) that showcases how to get started with Temporal"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (edu-ai-workshop-mcp)",
   "language": "python",
   "name": "edu-ai-workshop-mcp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
