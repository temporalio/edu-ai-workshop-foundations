{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agents\n",
    "\n",
    "Up until now we have built some durable GenAI applications that:\n",
    "\n",
    "- Called LLMs and APIs\n",
    "- Allowed for human interaction\n",
    "- Looped\n",
    "\n",
    "But we - the developer - encoded flow decisions into those apps. What if we wanted to make it more complex? What if we wanted our research application to:\n",
    "\n",
    "- **Decide if it needs more information** after an initial web search\n",
    "- **Execute multiple searches** based on what it learns\n",
    "- **Analyze results** and determine if they're sufficient\n",
    "\n",
    "This is where the **agentic loop** becomes essential - where your AI application makes autonomous decisions, executes actions, observes results, and repeats until it achieves its goal. In this section, we'll explore what makes an AI system \"agentic\" and why building these systems reliably is more challenging than simple chains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Makes a GenAI Application Agentic?\n",
    "\n",
    "When we give **agency** to the **LLM** to drive the flow of the application!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo (Expand for instructor notes or to run on your own)\n",
    "<!--\n",
    "1. Clone this repository: `https://github.com/cdavisafc/non-deterministic-ai-agents`. The instructions will also be in the README.\n",
    "2. Run the Worker: `uv run python -m worker`\n",
    "3. Start the agent: `uv run python -m start_workflow`\n",
    "4. Emphasize that this demo showcases the core principle of agentic applications: we give **agency** to the **LLM** to drive the flow of the application. Unlike traditional applications where developers hardcode every decision and branching path, this agent makes its own choices at runtime. The LLM decides which actions to take, when to gather more information, and when the goal has been achieved—all autonomously.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's talk a bit about Models (and APIs)\n",
    "\n",
    "- **The first models** were designed to complete the prompt that was passed in.\n",
    "    - The original OpenAI API was the **Completions API** - you provided text, and it continued that text\n",
    "    - Example: You give it \"The sky is\", it returns \"blue\" or \"filled with clouds\"\n",
    "- Since then, models have been created/optimize to respond in different ways.\n",
    "    - And in March 2025, OpenAI released the **responses API**\n",
    "    - Specifically designed for **agentic workflows**\n",
    "    - Optimized for agents that need to make autonomous decisions and execute tools iteratively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The Responses API\n",
    "\n",
    "resp = await client.responses.create(\n",
    "    model=\"\",  # Choose a model designed for agentic tasks\n",
    "               # Models like gpt-4o, gpt-4o-mini are optimized for tool calling\n",
    "    \n",
    "    instructions=\"You are a helpful weather assistant. Provide clear, concise weather information.\",\n",
    "    # For agents, this describes the role/behavior of the agent\n",
    "    # Defines HOW the agent should behave and make decisions\n",
    "    \n",
    "    input=[\n",
    "        {\"role\": \"user\", \"content\": \"What's the weather in California?\"}\n",
    "    ],\n",
    "    # Gathers the context as the agent progresses (through iterations)\n",
    "    # As the agent loops, this grows to include:\n",
    "    #   - User messages\n",
    "    #   - Agent responses\n",
    "    #   - Tool call requests\n",
    "    #   - Tool call results\n",
    "    \n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"name\": \"get_weather_alerts\",\n",
    "            \"description\": \"Get current weather alerts for a US state\",\n",
    "            \"parameters\": {...}\n",
    "        }\n",
    "    ],\n",
    "    # A list of the APIs available for use by the agent\n",
    "    # The agent will autonomously decide WHEN and IF to use these tools\n",
    "    \n",
    "    timeout=30,  # Maximum time to wait for the API response\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Tool?\n",
    "\n",
    "A **tool** is an external function that AI systems can call to perform specific tasks beyond just generating text. Tools take real actions in the world—they might:\n",
    "- Query databases\n",
    "- Call external APIs\n",
    "- Search for information\n",
    "- Perform calculations\n",
    "- Book reservations\n",
    "- Send emails\n",
    "- Generate files\n",
    "\n",
    "### How Agents Use Tools\n",
    "\n",
    "Agents are **aware of the tools** they have available while attempting to achieve their goal. The agent:\n",
    "1. Evaluates which tools are available\n",
    "2. Decides which tool will help progress toward the goal\n",
    "3. Executes the tool\n",
    "4. Observes the result\n",
    "5. Decides the next action based on what it learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Agents Execute Tools\n",
    "\n",
    "Each iteration of the agent follows the pattern:\n",
    "\n",
    "1. **LLM decides what to do** → \"I need to check the order status\"\n",
    "2. **Agent prepares the tool call** → Formats the request: `check_order(order_id=\"12345\")`\n",
    "3. **Tool executes** → Queries the database and returns: `{status: \"shipped\", tracking: \"1Z999...\"}`\n",
    "4. **Agent updates context** → Adds the result to the conversation history\n",
    "5. **Loop continues** → LLM sees the new information and decides the next action\n",
    "\n",
    "This continues until the LLM determines the goal is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tool Example\n",
    "\n",
    "# Tools are defined as JSON schemas that tell the LLM:\n",
    "# 1. What the tool does (description)\n",
    "# 2. What inputs it needs (parameters)\n",
    "# 3. Which inputs are required vs optional\n",
    "\n",
    "{\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"name\": \"get_weather_alerts\",\n",
    "            # Unique identifier - this is how the LLM refers to the tool\n",
    "            \n",
    "            \"description\": \"Retrieves current weather alerts for a given U.S. state\",\n",
    "            # Clear description helps the LLM decide WHEN to use this tool\n",
    "            # Be specific! \"Get weather\" vs \"Get weather ALERTS\" changes behavior\n",
    "            \n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"state\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The U.S. state to get weather alerts for, e.g. 'California' or 'TX'.\"\n",
    "                        # Examples in the description help the LLM format inputs correctly\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"state\"]  # List of required parameters\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"generate_random_number\",\n",
    "            \"description\": \"Generates a random number with no input parameters\",            \n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {}  # Empty properties = no parameters needed\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Your application then:\n",
    "# 1. Executes the actual function\n",
    "# 2. Returns the result to the LLM\n",
    "# 3. The LLM uses that result to continue toward its goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools Continued\n",
    "\n",
    "Ultimately, your agents need to manage a **registry of tools** that maps tool descriptions to actual API calls.\n",
    "\n",
    "When the LLM returns:\n",
    "```json\n",
    "{\n",
    "  \"type\": \"function_call\",\n",
    "  \"name\": \"get_weather_alerts\",\n",
    "  \"call_id\": \"call_abc123\",\n",
    "  \"arguments\": \"{\\\"state\\\": \\\"CA\\\"}\"\n",
    "}\n",
    "```\n",
    "\n",
    "Your application needs to:\n",
    "1. **Look up** which actual function corresponds to `get_weather_alerts`\n",
    "2. **Parse** the arguments string into the correct data structure\n",
    "3. **Execute** the real function (API call, database query, etc.)\n",
    "4. **Return** the result back to the LLM\n",
    "\n",
    "### Tool Registry Pattern\n",
    "\n",
    "```python\n",
    "# Example tool registry\n",
    "TOOL_REGISTRY = {\n",
    "    \"get_weather_alerts\": get_weather_alerts_function,\n",
    "    \"search_database\": search_database_function,\n",
    "    \"send_email\": send_email_function,\n",
    "}\n",
    "```\n",
    "We will cover this in a dedicated agent workshop where you'll build a robust tool registry system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Engineering\n",
    "\n",
    "Context engineering is the practice of managing what information gets passed to the LLM at each iteration of the agentic loop. Unlike prompt engineering (crafting a single prompt), context engineering deals with an *evolving conversation* that accumulates over **multiple iterations**.\n",
    "\n",
    "<img\n",
    "src=\"https://i.postimg.cc/s27DCXNw/Screenshot-2025-10-08-at-10-50-13-AM.png\"\n",
    "width=\"300\"/>\n",
    "\n",
    "As agents loop, the context grows:\n",
    "\n",
    "```python\n",
    "# Iteration 1:\n",
    "input = [\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather in California?\"}\n",
    "]\n",
    "\n",
    "# Iteration 2 (after tool call):\n",
    "input = [\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather in California?\"},\n",
    "    {\"type\": \"function_call\", \"name\": \"get_weather_alerts\", \"arguments\":\n",
    "'{\"state\": \"CA\"}'},\n",
    "    {\"type\": \"function_call_output\", \"output\": \"{...weather data...}\"}\n",
    "]\n",
    "```\n",
    "\n",
    "<img src=\"https://i.postimg.cc/SQv0V4ZG/context-engineering-cont.png\"\n",
    "width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Build an Agent!\n",
    "\n",
    "Now it's time to put everything together! We are going to build a **weather alert agent**. \n",
    "\n",
    "First, let's set up your notebook. Run the following code blocks to install various packages and tools necessary to run this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/azhou/Desktop/edu-ai-workshop-mcp/env/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# We'll first install the necessary packages for this workshop.\n",
    "\n",
    "%pip install --quiet temporalio litellm python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .env file\n",
    "with open(\".env\", \"w\") as fh:\n",
    "  fh.write(\"LLM_API_KEY = YOUR_API_KEY\\nLLM_MODEL = openai/gpt-4o\")\n",
    "\n",
    "  # Now open the file and replace YOUR_API_KEY with your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables and configure LLM settings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Get LLM_API_KEY environment variable and print it to make sure that your .env file is properly loaded.\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"openai/gpt-4o\")\n",
    "LLM_API_KEY = os.getenv(\"LLM_API_KEY\", None)\n",
    "print(\"LLM API Key\", LLM_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This allows us to run the Temporal Asyncio event loop within the event loop of Jupyter Notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mtemporal:\u001b[0m Downloading Temporal CLI latest\n",
      "\u001b[1mtemporal:\u001b[0m Temporal CLI installed at /Users/azhou/.temporalio/bin/temporal\n",
      "\u001b[1mtemporal:\u001b[0m For convenience, we recommend adding it to your PATH\n",
      "\u001b[1mtemporal:\u001b[0m If using bash, run echo export PATH=\"\\$PATH:/Users/azhou/.temporalio/bin\" >> ~/.bashrc\n"
     ]
    }
   ],
   "source": [
    " # Running this will download the Temporal CLI\n",
    "\n",
    "!curl -sSf https://temporal.download/cli.sh | sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Sure Your Temporal Web UI is Running\n",
    "\n",
    "1. You should have the Temporal Server running in your terminal (run `temporal server start-dev` if not).\n",
    "2. Then in your `Ports` tab on the bottom of this screen, find `8233` and click on the Globe icon to open the Temporal Web UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Our Agent: Step by Step\n",
    "\n",
    "Now we'll build our weather alert agent. Here's what it will do:\n",
    "\n",
    "1. Takes a user query (like \"What's the weather in California?\")\n",
    "2. Decides autonomously whether it needs to fetch weather data:\n",
    "    - If the query requires weather alert information for a U.S. state, it calls the `get_weather_alerts` tool\n",
    "    - If no tools are needed, it responds in haikus (per the system instructions)\n",
    "3. Fetches current weather alerts from the [National Weather Service API](https://www.weather.gov/documentation/services-web-api) for a specific U.S. state when needed\n",
    "4. Returns results in a readable format - taking the raw API data and presenting it clearly to the user\n",
    "\n",
    "Let's start by defining the data structure we'll use to communicate with the OpenAI Responses API.\n",
    "\n",
    "### Step 1 - Create the Request Dataclass\n",
    "\n",
    "First, we'll create a dataclass that packages all the parameters needed for our LLM calls. This groups together the model name, agent instructions, conversation input, and available tools in one structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run this code block to load it into the program\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "@dataclass\n",
    "class OpenAIResponsesRequest:\n",
    "    model: str\n",
    "    instructions: str\n",
    "    input: object\n",
    "    tools: list[dict[str, Any]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Create the Activity for LLM Invocations\n",
    "\n",
    "We will create an Activity which invokes the OpenAI LLM, taking in our `OpenAIResponsesRequest` dataclass.\n",
    "\n",
    "It's a reusable function that handles all communication with OpenAI's LLM throughout our agent's execution.\n",
    "\n",
    "_Why make this an Activity?_ If the LLM fails (e.g., Network timeout, rate limitting), Temporal records the response in its event history. If\n",
    "your workflow crashes after getting the LLM response, on replay Temporal returns the same stored response instead of calling the LLM again (saving time and money!).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Supply the `OpenAIResponsesRequest` we just loaded in as the `request` for the parameter\n",
    "# Step 2: Run this code block to load it into the program\n",
    "from temporalio import activity\n",
    "from openai import AsyncOpenAI\n",
    "from openai.types.responses import Response\n",
    "\n",
    "@activity.defn\n",
    "async def create(request: ) -> Response: # TODO: Supply the `OpenAIResponsesRequest` as the `request` for the parameter\n",
    "    # Temporal best practice: Disable retry logic in OpenAI API client library.\n",
    "    client = AsyncOpenAI(max_retries=0)\n",
    "\n",
    "    resp = await client.responses.create(\n",
    "        model=request.model,\n",
    "        instructions=request.instructions,\n",
    "        input=request.input,\n",
    "        tools=request.tools,\n",
    "        timeout=30,\n",
    "    )\n",
    "\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_04_AI_Agents\" / \"create_activity_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding How the Request Dataclass Evolves\n",
    "\n",
    "The `OpenAIResponsesRequest dataclass` isn't just used once - it's used multiple  times throughout your agent's execution, and the data inside it evolves. \n",
    "\n",
    "Example: \"What's the weather in California?\"\n",
    "\n",
    "First LLM Call - Initial Query\n",
    "\n",
    "When your agent starts, you make the first call with minimal context:\n",
    "\n",
    "#### First LLM call - asking \"What's the weather in California?\"\n",
    "```python\n",
    "result = await workflow.execute_activity(\n",
    "    create,\n",
    "    OpenAIResponsesRequest(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        instructions=\"if no tools seem to be needed, respond in haikus.\",\n",
    "        input=[{\"role\": \"user\", \"content\": \"What's the weather in California?\"}],\n",
    "        tools=[WEATHER_ALERTS_TOOL_OAI]  # Available tool: get_weather_alerts\n",
    "    ),\n",
    "    start_to_close_timeout=timedelta(seconds=30),\n",
    ")\n",
    "```\n",
    "\n",
    "The LLM decides it needs the weather alerts tool to answer this question.\n",
    "\n",
    "Second LLM Call - With Tool Results\n",
    "\n",
    "Now you make a second call, but notice how the input field has grown:\n",
    "\n",
    "#### Second LLM call - with tool results included\n",
    "```python\n",
    "result = await workflow.execute_activity(\n",
    "    create,\n",
    "    OpenAIResponsesRequest(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        instructions=\"return the tool call result in a readable format\",\n",
    "        input=[\n",
    "            {\"role\": \"user\", \"content\": \"What's the weather in California?\"},\n",
    "            {\"type\": \"function_call\", \"name\": \"get_weather_alerts\", \"call_id\":\n",
    "\"call_abc123\", \"arguments\": \"{\\\"state\\\": \\\"CA\\\"}\"},\n",
    "            {\"type\": \"function_call_output\", \"call_id\": \"call_abc123\", \"output\":\n",
    "\"...actual weather data...\"}\n",
    "        ],\n",
    "        tools=[]  # No more tools needed - we have the data!\n",
    "    ),\n",
    "    start_to_close_timeout=timedelta(seconds=30),\n",
    ")\n",
    "```\n",
    "The LLM now has all the information it needs to provide a complete answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Create the Helper Function\n",
    "\n",
    "Before we build our tool that fetches weather alerts, we need a helper function that converts Pydantic models into OpenAI's tool definition format.\n",
    "\n",
    "The `oai_responses_tool_from_model` function accepts a tool name, description, and a Pydantic model, then returns JSON in the format expected by OpenAI's Responses API tool definitions.\n",
    "\n",
    "**Example output format:**\n",
    "```json\n",
    "{\n",
    "  \"type\": \"function\",\n",
    "  \"name\": \"get_weather_alerts\",\n",
    "  \"description\": \"Get current weather alerts for a US state\",\n",
    "  \"parameters\": {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"state\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"Two-letter US state code (e.g. CA, NY)\"\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\"state\"]\n",
    "  },\n",
    "  \"strict\": true\n",
    "}\n",
    "```\n",
    "\n",
    "This helper automatically converts your Pydantic model into the proper tool schema, so you don't have to write JSON manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run this code block\n",
    "from openai.lib._pydantic import to_strict_json_schema\n",
    "from pydantic import BaseModel\n",
    "\n",
    "def oai_responses_tool_from_model(name: str, description: str, model: type[BaseModel]):\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": name,\n",
    "        \"description\": description,\n",
    "        \"parameters\": to_strict_json_schema(model),\n",
    "        \"strict\": True,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Set Up the National Weather Service API Wrapper\n",
    "\n",
    "Before our agent can fetch weather alerts, we need to create helper functions that know how to communicate with the [National Weather Service API](https://www.weather.gov/documentation/services-web-api), specifically for the weather alerts endpoint for a certain state.\n",
    "\n",
    "These helper functions will be used by our Activity in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run this code block\n",
    "from typing import Any\n",
    "import httpx\n",
    "import json\n",
    "\n",
    "# Constants for the National Weather Service API\n",
    "NWS_API_BASE = \"https://api.weather.gov\"\n",
    "USER_AGENT = \"weather-app/1.0\"\n",
    "\n",
    "def _alerts_url(state: str) -> str:\n",
    "    \"\"\"Build the NWS API URL for a given state.\"\"\"\n",
    "    return f\"{NWS_API_BASE}/alerts/active/area/{state}\"\n",
    "\n",
    "# External calls will happen via activities\n",
    "async def _make_nws_request(url: str) -> dict[str, Any] | None:\n",
    "    \"\"\"Make a request to the NWS API with proper error handling.\"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": USER_AGENT,\n",
    "        \"Accept\": \"application/geo+json\"\n",
    "    }\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.get(url, headers=headers, timeout=5.0)\n",
    "        response.raise_for_status()\n",
    "        return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Build the Tool for the OpenAI Responses API\n",
    "\n",
    "Now we'll create the Pydantic model that defines what parameters the tool accepts, then use our helper function to convert it into OpenAI's tool definition format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: In the `description` for state, set it to \"Two-letter US state code (e.g. CA, NY)\"\n",
    "# Step 2: Run this code block\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class GetWeatherAlertsRequest(BaseModel):\n",
    "    state: str = Field(description=\"\")  # TODO: Set the description to be \"Two-letter US state code (e.g. CA, NY)\"\n",
    "\n",
    "WEATHER_ALERTS_TOOL_OAI: dict[str, Any] = oai_responses_tool_from_model(\n",
    "    \"get_weather_alerts\", # name \n",
    "    \"Get weather alerts for a US state.\", # description\n",
    "    GetWeatherAlertsRequest) # model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_04_AI_Agents\" / \"GetWeatherAlertsRequest_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 - Implement the Activity\n",
    "\n",
    "We'll create the Activity function that executes when the LLM decides to use this tool. This function calls the NWS API and returns the weather alert data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: After the `await`, call the `_make_nws_request` Activity you ran earlier.\n",
    "# Remember: External calls will happen via Activities.\n",
    "# Step 2: Run this code block\n",
    "from temporalio import activity\n",
    "\n",
    "@activity.defn\n",
    "async def get_weather_alerts(weather_alerts_request: GetWeatherAlertsRequest) -> str:\n",
    "    \"\"\"Get weather alerts for a US state.\n",
    "\n",
    "    Args:\n",
    "        state: Two-letter US state code (e.g. CA, NY)\n",
    "    \"\"\"\n",
    "    data = await \"\"(_alerts_url(weather_alerts_request.state)) # TODO: Call the `_make_nws_request` Activity you ran earlier\n",
    "    return json.dumps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_04_AI_Agents\" / \"get_weather_alerts_activity_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Create the Agent\n",
    "\n",
    "Now we'll create the agent, which is implemented as the **ToolCallingWorkflow**. This Workflow ties everything together:\n",
    "\n",
    "1. **Makes an initial LLM call** with the user's input and available tools\n",
    "2. **Checks if the LLM wants to call a tool** by examining the response type\n",
    "3. **Executes the tool** if requested\n",
    "4. **Makes a second LLM call** with the tool results to get a final response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Call the `create` Activity for the initial LLM call\n",
    "# Step 2: Fill in the `OpenAIResponsesRequest` with `system_instructions`, `input_list`, and `get_weather_alerts.WEATHER_ALERTS_TOOL_OAI`.\n",
    "# Step 3: Execute the get_weather_alerts activity when a tool is called\n",
    "# Step 4: Run this code block to load it into the program\n",
    "\n",
    "from temporalio import workflow\n",
    "from datetime import timedelta\n",
    "import json\n",
    "\n",
    "# sandboxed=False is a Notebook only requirement. You normally don't do this\n",
    "@workflow.defn(sandboxed=False)\n",
    "class ToolCallingWorkflow:\n",
    "    @workflow.run\n",
    "    async def run(self, input: str) -> str:\n",
    "        input_list = [{\"role\": \"user\", \"content\": input}]\n",
    "        \n",
    "        # Initial LLM call with system instructions and tools\n",
    "        system_instructions = \"if no tools seem to be needed, respond in haikus.\"\n",
    "        result = await workflow.execute_activity(\n",
    "            # TODO: Call the `create` Activity here\n",
    "            OpenAIResponsesRequest(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                instructions=\"\",  # TODO: Fill in with system_instructions\n",
    "                input=\"\",  # TODO: Fill in with input_list\n",
    "                tools=[]  # TODO: Fill in tools list with get_weather_alerts.WEATHER_ALERTS_TOOL_OAI\n",
    "            ),\n",
    "            start_to_close_timeout=timedelta(seconds=30),\n",
    "        )\n",
    "        \n",
    "        # Process the LLM response\n",
    "        item = result.output[0]\n",
    "        \n",
    "        # if the result is a tool call, call the tool\n",
    "        if item.type == \"function_call\":\n",
    "            if item.name == \"get_weather_alerts\":\n",
    "\n",
    "                # serialize the output, which is an OpenAI object\n",
    "                input_list += [\n",
    "                    i.model_dump() if hasattr(i, \"model_dump\") else i\n",
    "                    for i in result.output\n",
    "                ]\n",
    "                \n",
    "                result = await workflow.execute_activity(\n",
    "                    get_weather_alerts.\"\", # TODO: Execute the get_weather_alerts activity\n",
    "                    get_weather_alerts.GetWeatherAlertsRequest(state=json.loads(item.arguments)[\"state\"]),\n",
    "                    start_to_close_timeout=timedelta(seconds=30),\n",
    "                )\n",
    "                \n",
    "                # Add tool call result to input list\n",
    "                input_list.append({\n",
    "                    \"type\": \"function_call_output\",\n",
    "                    \"call_id\": item.call_id,\n",
    "                    \"output\": result\n",
    "                })\n",
    "                \n",
    "                result = await workflow.execute_activity(\n",
    "                    create,\n",
    "                    OpenAIResponsesRequest(\n",
    "                        model=\"gpt-4o-mini\",\n",
    "                        instructions=\"return the tool call result in a readable format\",\n",
    "                        input=input_list,\n",
    "                        tools=[]\n",
    "                    ),\n",
    "                    start_to_close_timeout=timedelta(seconds=30),\n",
    "                )\n",
    "        \n",
    "        result = result.output_text\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_04_AI_Agents\" / \"tool_calling_workflow_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Tool-Calling Agent\n",
    "\n",
    "Now let's run our agent by running our Worker!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Set the Task Queue to be \"tool-calling-python-task-queue\"\n",
    "# Step 2: Register `ToolCallingWorkflow` on this Worker\n",
    "# Step 3: Run this code\n",
    "import asyncio\n",
    "from temporalio.client import Client\n",
    "from temporalio.worker import Worker\n",
    "from temporalio.contrib.pydantic import pydantic_data_converter\n",
    "\n",
    "async def run_worker() -> None:\n",
    "    client = await Client.connect(\n",
    "        \"localhost:7233\",\n",
    "        data_converter=pydantic_data_converter,\n",
    "    )\n",
    "\n",
    "    worker = Worker(\n",
    "        client,\n",
    "        task_queue= \"\", # TODO: Set the Task Queue to be \"tool-calling-python-task-queue\",\n",
    "        workflows=[], # TODO: Register `ToolCallingWorkflow` on this Worker\n",
    "        activities=[\n",
    "            create,\n",
    "            get_weather_alerts.get_weather_alerts,\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    print(f\"Starting the worker....\")\n",
    "    await worker.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_04_AI_Agents\" / \"worker_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Worker\n",
    "worker = asyncio.create_task(run_worker())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate an Interaction with the Agent\n",
    "\n",
    "In order to interact with this simple AI agent, we create a Temporal client and execute a workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Set the task queue of the client to match the task queue the worker is polling\n",
    "# Step 2: Run this code block\n",
    "import sys\n",
    "\n",
    "from temporalio.client import Client\n",
    "from temporalio.contrib.pydantic import pydantic_data_converter\n",
    "\n",
    "async def main():\n",
    "    client = await Client.connect(\n",
    "        \"localhost:7233\",\n",
    "        data_converter=pydantic_data_converter,\n",
    "    )\n",
    "\n",
    "    query = sys.argv[1] if len(sys.argv) > 1 else \"Hello, how are you?\"\n",
    "\n",
    "    # Submit the Tool Calling workflow for execution\n",
    "    result = await client.execute_workflow(\n",
    "        ToolCallingWorkflow.run,\n",
    "        query,\n",
    "        id=\"my-workflow-id\",\n",
    "        task_queue=\"\", # TODO: Set the task queue of the client to match the task queue the worker is polling\n",
    "    )\n",
    "    print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_04_AI_Agents\" / \"client_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTICE...? WEBUI...? FOLLOWUP QUESTIONS...?\n",
    "\n",
    "The key capability is that the LLM decides autonomously whether to use the weather\n",
    "   alerts tool or not. You don't hardcode \"if user mentions a state, call the API\" -\n",
    "   instead, the LLM evaluates the input and decides if calling get_weather_alerts\n",
    "  will help achieve the goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is an Agentic Loop?\n",
    "\n",
    "At a high level, AI agents have an **event loop**, and in that event loop, we make calls out to the LLM to ask it for directions. **The LLM is what drives the flow** of the application.\n",
    "\n",
    "We might invoke some downstream actions (e.g., make microservice requests, query databases, call external APIs). Then we may consult with the user, and then go through the loop again.\n",
    "\n",
    "In the loop, it:\n",
    "- **Plans**: The LLM analyzes the current state and decides what to do next\n",
    "- **Executes**: The agent calls relevant tools or APIs\n",
    "- **Observes**: Reviews results and updates context\n",
    "- **Repeats** until the LLM hits its goal or the user stops it\n",
    "\n",
    "<img src=\"https://i.postimg.cc/MGPGgMH1/the-agentic-loop.png\" width=\"300\"/>\n",
    "\n",
    "Imagine a travel agent. The agent uses tools to search for flights, collect travel details, and then handle bookings. The loop allows the agent to use the output from one tool (e.g., flight search results) to inform the next step, like using flight details to book the trip or charging the user.\n",
    "\n",
    "The agent is generally implemented as an event loop that is kicked off with an expression of some goal, such as \"Book a round-trip flight from New York to Paris for June 15-22 under $800.\"\n",
    "\n",
    "In the loop, it:\n",
    "- **Asks the LLM to determine the next steps in the flow**: The LLM analyzes the current state, available info, and decides what to do next like search for flights, gather user preferences about departure time\n",
    "- **Invokes one or more tools to perform those actions**: The agent calls relevant APIs or tools like flight search engines or payment processors\n",
    "- **Evaluates results and continues**: The agent assesses if the goal has been achieved or if more steps are needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is the Agentic Loop Powerful?\n",
    "\n",
    "- The AI makes its own decisions\n",
    "- Can adapt to different situations dynamically\n",
    "- Can use different tools in different orders based on context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Agentic Loop in Temporal\n",
    "\n",
    "- In Temporal, an agentic loop is represented as a **Workflow**. \n",
    "- We use Activities for LLMs and Tool Calls for automatic retries and durability\n",
    "- Complete step tracking\n",
    "    - If you trigger an LLM invocation, then execute a tool, and finally hand off control to another agent, Temporal records every step of that process in its event history.\n",
    "- Durable Execution\n",
    "    - _Automatic recovery_: If something goes wrong—a crash, network glitch, or service interruption—Temporal automatically replays the Workflow from the beginning, using the recorded event history to skip already-completed steps.\n",
    "    - _No data loss_: Temporal persistently records application progress and stores all Activity results in its durable event log.\n",
    "    - _No duplicate work_: Once an Activity completes successfully, its result is recorded. On replay, Temporal returns the stored result instead of re-executing the Activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you for attending this workshop. Feedback?\n",
    "\n",
    "Please leave your feedback for this workshop [here](https://docs.google.com/forms/d/e/1FAIpQLSfkHMev6KCNGFHpVNydyjgAh2ALeHNVYv9TaSrAoBsT0KmNHQ/viewform?usp=header)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Next?\n",
    "\n",
    "This workshop introduced you to the foundations of AI, human in the loop, agentic loops, and why durability matters.\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Temporal Docs](https://docs.temporal.io/)\n",
    "- [Code Repository](https://github.com/temporalio/edu-ai-workshop-agentic-loop)\n",
    "- [Free Temporal Courses](https://learn.temporal.io/courses/)\n",
    "- Join our [Community Slack](https://t.mp/slack)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (edu-ai-workshop-mcp)",
   "language": "python",
   "name": "edu-ai-workshop-mcp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
