{"cells":[{"cell_type":"markdown","metadata":{"id":"ekQPgGVwQb1a"},"source":["# Exercise #1 - Adding More Tools Exercise [Practice]\n","\n","The research workflow currently performs research with an LLM and writes it to a PDF. To add a little more fun to your research paper, you'll use AI to generate an image of the research subject.\n","\n","The main purpose of this exercise is to familiarize yourself with the flow and code before we add durability to it.\n","\n","Fill in the TODO instructions. Go to the `solution` directory if you need help.\n","\n","In this exercise, you'll:\n","  - Call actions with your GenAI Application\n","  - Extract structured information from LLM responses to coordinate between different actions."]},{"cell_type":"markdown","metadata":{"id":"t_uA13X5SYWe"},"source":["### Setup\n","\n","Before doing the exercise, you need to:\n","\n","* Create your `.env` file and supply your API key\n","* Load the environment variables"]},{"cell_type":"markdown","metadata":{"id":"HXp3VIAdZuhO"},"source":["### Create a `.env` File\n","\n","Next you'll create a `.env` file to store your API keys.\n","In the file browser on the left, create a new file and name it `.env`.\n","Then double click on the `.env` file and add the following line with your API key.\n","\n","```\n","LLM_API_KEY = YOUR_API_KEY\n","LLM_MODEL = \"openai/gpt-4o\"\n","```\n","\n","By default this notebook uses OpenAI's GPT-4o. **To perform image generation, you will need an OpenAI key**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tSl-K8ATXLJ3"},"outputs":[],"source":["# Create .env file at the root of the `exercises` directory\n","with open(\"../../.env\", \"w\") as fh:\n","    fh.write(\"LLM_API_KEY = YOUR_API_KEY\\nLLM_MODEL = openai/gpt-4o\")  \n","\n","# Now open the .env file at the root of `exercises` and replace YOUR_API_KEY with your API key."]},{"cell_type":"markdown","metadata":{},"source":["### Add Your LLM API Key **Before** Running the Following Code Block"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fy4s0KTRdWxL"},"outputs":[],"source":["# Load environment variables and configure LLM settings\n","\n","import os\n","from dotenv import load_dotenv\n","\n","load_dotenv(override=True)\n","\n","\n","# Get LLM_API_KEY environment variable and print it to make sure that your .env file is properly loaded.\n","LLM_MODEL = os.getenv(\"LLM_MODEL\", \"openai/gpt-4o\")\n","LLM_API_KEY = os.getenv(\"LLM_API_KEY\", None)\n","\n","print(\"LLM API Key:\", LLM_API_KEY[:3] + \"*\" * (len(LLM_API_KEY) - 3) if LLM_API_KEY else None)"]},{"cell_type":"markdown","metadata":{"id":"Iw22wN9wX1Ok"},"source":["### Define functions\n","\n","In the content notebook there were two functions defined, `llm_call` and `create_pdf`. Run the codeblocks to define them here."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2FEDm6EiYKB2"},"outputs":[],"source":["# Run this codeblock\n","from litellm import completion, ModelResponse\n","\n","# Sends user prompt to an LLM and returns response\n","\n","def llm_call(prompt: str) -> ModelResponse:\n","    response = completion(\n","      model=LLM_MODEL,\n","      api_key=LLM_API_KEY,\n","      messages=[{ \"content\": prompt,\"role\": \"user\"}]\n","    )\n","    return response"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUuRKXiXYNey"},"outputs":[],"source":["# Run this codeblock\n","from reportlab.lib.pagesizes import letter\n","from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image as RLImage\n","from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n","from reportlab.lib.units import inch\n","import requests\n","from io import BytesIO\n","\n","# Converts text content into a PDF\n","def create_pdf(content: str, filename: str = \"research_report.pdf\", image_url: str = None):\n","    doc = SimpleDocTemplate(filename, pagesize=letter)\n","\n","    styles = getSampleStyleSheet()\n","    title_style = ParagraphStyle(\n","        'CustomTitle',\n","        parent=styles['Heading1'],\n","        fontSize=24,\n","        spaceAfter=30,\n","        alignment=1\n","    )\n","\n","    story = []\n","    title = Paragraph(\"Research Report\", title_style)\n","    story.append(title)\n","    story.append(Spacer(1, 20))\n","\n","    if image_url is not None:\n","      img_response = requests.get(image_url)\n","      img_buffer = BytesIO(img_response.content)\n","      img = RLImage(img_buffer, width=5*inch, height=5*inch)\n","      story.append(img)\n","      story.append(Spacer(1, 20))\n","\n","    paragraphs = content.split('\\n\\n')\n","    for para in paragraphs:\n","        if para.strip():\n","            p = Paragraph(para.strip(), styles['Normal'])\n","            story.append(p)\n","            story.append(Spacer(1, 12))\n","\n","    doc.build(story)\n","    return filename"]},{"cell_type":"markdown","metadata":{"id":"2BE_tNaFU_dP"},"source":["### Part 1 - Getting the Subject from Our Past Prompt\n","\n","In the workflow from the presentation, you provided a prompt to the LLM to generate research. We now want to **create an image** to add some fun to our PDF that illustrates the topic of the prompt. \n","\n","This prompt was likely a complete sentence, with more detail than you will need to create the image. We can use the LLM to get the subject of the original prompt.\n","For example: \"Give me 5 facts about dogs\" -> \"dogs\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"THWJVkMfWzK9"},"outputs":[],"source":["# Run this codeblock\n","research_prompt = input(\"Enter your research topic or question: \")\n","print(research_prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"boGCFsUFZtl0"},"outputs":[],"source":["# Step 1: Call the `llm_call` function with the  `subject_prompt` parameter passed in\n","# Step 2: Run this codeblock\n","subject_prompt = f\"What is the main topic of this sentence? Respond with only the topic in a single word or short phrase. No explanation. The sentence is: {research_prompt}\"\n","research_subject = # TODO Call the `llm_call` function with the subject_prompt parameter passed in\n","print(research_subject[\"choices\"][0][\"message\"][\"content\"])"]},{"cell_type":"markdown","metadata":{"id":"HNrBOqdISGll"},"source":["### Part #2 - Generate an Image of the Subject\n","\n","Now that we have the subect of your prompt, we will generate an image of it by passing it into the `generate_ai_image` as a parameter.\n","\n","1. Create a prompt for the image generation that includes the subject of the research report\n","  * Example prompt: f\"A cute, natural image of {subject}.\"\n","2. Add the missing arguments to the `image_generation` call.\n","3. In the second code block, call the `generate_ai_image` function with the `research_subject` parameter passed in."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nRYQtg_fO-GD"},"outputs":[],"source":["# Run this codeblock\n","from litellm import image_generation\n","\n","def generate_ai_image(subject: str) -> str:\n","\n","    image_prompt = # TODO: Create a prompt for the image generation that includes the subject passed in as a parameter to this function\n","\n","    response = image_generation(\n","        prompt=# TODO: Add the image_prompt you just created\n","        model=\"dall-e-3\",\n","        api_key=LLM_API_KEY\n","    )\n","\n","    return response"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wwHsnzrwRnCb"},"outputs":[],"source":["# Run this codeblock\n","from IPython.display import Image, display\n","\n","research_image = # TODO: Call the generate_ai_image function with the research_subject parameter passed in.\n","research_image_url = research_image[\"data\"][0][\"url\"]\n","\n","display(Image(url=research_image_url))"]},{"cell_type":"markdown","metadata":{"id":"yoMApjFcdT9O"},"source":["### Part 3 - Updating the workflow\n","\n","Now that you have an image, let's create a PDF with your research and image. We want to update the workflow to get the topic, make the LLM call, and generate the report.\n","\n","1. Add a call to `llm_call` to get the topic of your prompt.\n","  * The `llm_call` function takes in your `research_prompt`.\n","2. Add a call to `generate_ai_image` to get an image for your research pdf.\n","  * The `generate_ai_image` function takes in your `research_topic`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QbxWbgrZdipe"},"outputs":[],"source":["# Run this codeblock\n","try:\n","    # Make the API call\n","    print(\"Welcome to the Research Report Generator!\")\n","    research_prompt = input(\"Enter your research topic or question: \")\n","    result = # TODO: Call the `llm_call` function. It takes in `research_prompt`.\n","\n","    # Extract the response content\n","    response_content = result[\"choices\"][0][\"message\"][\"content\"]\n","\n","    subject_prompt = f\"What is the main topic of this sentence? Respond with only the topic in a single word or short phrase. No explanation. The sentence is: {research_prompt}\"\n","\n","    research_topic_llm_response = llm_call(subject_prompt)\n","    research_topic = research_topic_llm_response[\"choices\"][0][\"message\"][\"content\"]\n","\n","    ai_image = # TODO: Call the `generate_ai_image` function. It takes in `research_topic`.\n","    ai_image_url = ai_image[\"data\"][0][\"url\"]\n","\n","    pdf_filename = create_pdf(response_content, f\"{research_topic}.pdf\", ai_image_url)\n","    print(f\"SUCCESS! PDF created: {pdf_filename}\")\n","except Exception as e:\n","    print(f\"Error: {e}\")"]},{"cell_type":"markdown","metadata":{"id":"-OVO0wf-5gY1"},"source":["### Download your image by following these steps:\n","  - Right-click the PDF file in the file explorer\n","  - Select \"Download\"\n","  - Open it locally on your machine\n","\n","Awesome, you're done with the exercise! But think of the things that could go wrong in this application. What if your image generation API went down? What if the PDF creation fails after you've already paid for the LLM call? How can we make this code more durable? \n","\n","We'll find out in the next notebook."]},{"cell_type":"markdown","metadata":{},"source":["### What's Next?\n","\n","This workshop introduced you the importance of durability in GenAI applications. Further your learning with these resources:\n","\n","### Resources\n","\n","- [A mental model for agentic AI Applications blogpost](https://temporal.io/blog/a-mental-model-for-agentic-ai-applications)\n","- [From AI hype to durable reality â€” why agentic flows need distributed-systems discipline blogpost](https://temporal.io/blog/from-ai-hype-to-durable-reality-why-agentic-flows-need-distributed-systems)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1_wuVbg6mp5243HlnYYBx7k1lEFFF99iN","timestamp":1756398235793}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
