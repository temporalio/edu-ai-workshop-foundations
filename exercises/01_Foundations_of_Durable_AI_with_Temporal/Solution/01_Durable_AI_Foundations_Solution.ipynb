{"cells":[{"cell_type":"markdown","metadata":{"id":"ekQPgGVwQb1a"},"source":["# Exercise #1 - Adding More Actions Exercise [Solution]\n","\n","The research workflow currently performs research with an LLM and writes it to a PDF. To add a little more pizaz to your research paper, you'll use AI to generate an image of the research subject.\n","\n","In this exercise, you'll:\n","  - Call actions with your GenAI Application\n","  - Extract structured information from LLM responses to coordinate between different actions."]},{"cell_type":"markdown","metadata":{"id":"t_uA13X5SYWe"},"source":["## Setup\n","\n","Before doing the exercise, you need to:\n","\n","* Install necessary dependencies\n","* Create your `.env` file and supply your API key\n","* Load the environment variables"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20165,"status":"ok","timestamp":1757714962404,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"},"user_tz":240},"id":"m8UH2Il_Sp50","outputId":"1ad95e58-ad27-4390-8379-6c030a65678b"},"outputs":[],"source":["# We'll first install the necessary packages for this workshop.\n","\n","%pip install --quiet litellm reportlab python-dotenv requests"]},{"cell_type":"markdown","metadata":{"id":"HXp3VIAdZuhO"},"source":["## Create a `.env` File\n","\n","Next you'll create a `.env` file to store your API keys.\n","In the file browser on the left, create a new file and name it `.env`.\n","\n","**Note**: It may disappear as soon as you create it. This is because Google Collab hides hidden files (files that start with a `.`) by default.\n","To make this file appear, click the icon that is a crossed out eye and hidden files will appear.\n","\n","Then double click on the `.env` file and add the following line with your API key.\n","\n","```\n","LLM_API_KEY = YOUR_API_KEY\n","LLM_MODEL = \"openai/gpt-4o\"\n","```\n","\n","By default this notebook uses OpenAI's GPT-4o.\n","If you want to use a different LLM provider, look up the appropriate model name [in their documentation](https://docs.litellm.ai/docs/providers) and change the `LLM_MODEL` field and provide your API key.\n","\n","**To perform image generation, you will need an OpenAI key**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1757714967533,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"},"user_tz":240},"id":"tSl-K8ATXLJ3"},"outputs":[],"source":["# Create .env file\n","with open(\".env\", \"w\") as fh:\n","  fh.write(\"LLM_API_KEY = YOUR_API_KEY\\nLLM_MODEL = openai/gpt-4o\")\n","\n","# Now open the file and replace YOUR_API_KEY with your API key"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1757714991049,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"},"user_tz":240},"id":"fy4s0KTRdWxL","outputId":"74af71f0-1408-4d41-9ab7-887551a76fb9"},"outputs":[],"source":["# Load environment variables and configure LLM settings\n","\n","import os\n","from dotenv import load_dotenv\n","\n","load_dotenv(override=True)\n","\n","\n","# Get LLM_API_KEY environment variable and print it to make sure that your .env file is properly loaded.\n","LLM_MODEL = os.getenv(\"LLM_MODEL\", \"openai/gpt-4o\")\n","LLM_API_KEY = os.getenv(\"LLM_API_KEY\", None)\n","\n","print(\"API Key: \", LLM_API_KEY)"]},{"cell_type":"markdown","metadata":{"id":"Iw22wN9wX1Ok"},"source":["## Define functions\n","\n","In the content notebook there were two functions defined, `llm_call` and `create_pdf`. Run the code to define them here"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4167,"status":"ok","timestamp":1757714998003,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"},"user_tz":240},"id":"2FEDm6EiYKB2"},"outputs":[],"source":["# Run this codeblock\n","from litellm import completion, ModelResponse\n","\n","# Sends user prompt to an LLM and returns response\n","def llm_call(prompt: str, llm_api_key: str, llm_model: str) -> ModelResponse:\n","    response = completion(\n","      model=llm_model,\n","      api_key=llm_api_key,\n","      messages=[{ \"content\": prompt,\"role\": \"user\"}]\n","    )\n","    return response"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":378,"status":"ok","timestamp":1757714999115,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"},"user_tz":240},"id":"sUuRKXiXYNey"},"outputs":[],"source":["# Run this codeblock\n","from reportlab.lib.pagesizes import letter\n","from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image as RLImage\n","from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n","from reportlab.lib.units import inch\n","import requests\n","from io import BytesIO\n","\n","# Action: converts text content into a PDF\n","def create_pdf(content: str, filename: str = \"research_report.pdf\", image_url: str = None):\n","    doc = SimpleDocTemplate(filename, pagesize=letter)\n","\n","    styles = getSampleStyleSheet()\n","    title_style = ParagraphStyle(\n","        'CustomTitle',\n","        parent=styles['Heading1'],\n","        fontSize=24,\n","        spaceAfter=30,\n","        alignment=1\n","    )\n","\n","    story = []\n","    title = Paragraph(\"Research Report\", title_style)\n","    story.append(title)\n","    story.append(Spacer(1, 20))\n","\n","    if image_url is not None:\n","      img_response = requests.get(image_url)\n","      img_buffer = BytesIO(img_response.content)\n","      img = RLImage(img_buffer, width=5*inch, height=5*inch)\n","      story.append(img)\n","      story.append(Spacer(1, 20))\n","\n","    paragraphs = content.split('\\n\\n')\n","    for para in paragraphs:\n","        if para.strip():\n","            p = Paragraph(para.strip(), styles['Normal'])\n","            story.append(p)\n","            story.append(Spacer(1, 12))\n","\n","    doc.build(story)\n","    return filename"]},{"cell_type":"markdown","metadata":{"id":"2BE_tNaFU_dP"},"source":["## Part 1 - Getting the Subject from Our Past Prompt\n","\n","In the workflow from the presentation, you provided a prompt to the LLM to generate research. We now want to create an image to add some fun to our PDF that illustrates the topic of the prompt. This prompt was likely a complete sentence, with more detail than you will need to create the image. We can use the LLM to get the subject of the original prompt.\n","\n","* Call the `llm_call` function with the parameters passed in: subject_prompt, LLM_API_KEY, LLM_MODEL"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7635,"status":"ok","timestamp":1757715022116,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"},"user_tz":240},"id":"THWJVkMfWzK9","outputId":"6ee95895-84cd-4ba6-e065-710afa37ca5b"},"outputs":[],"source":["# Run this codeblock\n","research_prompt = input(\"Enter your research topic or question: \")\n","print(research_prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1180,"status":"ok","timestamp":1757715025426,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"},"user_tz":240},"id":"boGCFsUFZtl0","outputId":"bda1aa9f-e3da-4d06-b211-45185b6f3444"},"outputs":[],"source":["# Run this codeblock\n","subject_prompt = f\"What is the main topic of this sentence? Respond with only the topic in a single word or short phrase. No explanation. The sentence is: {research_prompt}\"\n","research_subject = llm_call(subject_prompt, LLM_API_KEY, LLM_MODEL)\n","print(research_subject)[\"choices\"][0][\"message\"][\"content\"]"]},{"cell_type":"markdown","metadata":{"id":"HNrBOqdISGll"},"source":["## Part #2 - Generate an Image of the Subject\n","\n","Now that we have the subect of your prompt, we will generate an image of it by passing it into the `generate_ai_image` as a parameter.\n","\n","* Create a prompt for the image generation that includes the subject of the research report\n","  * Example prompt: f\"A cute, natural image of {subject}.\"\n","* Add the missing key word arguments to the `image_generation` call. The arguments you need to add are:\n","  * `prompt` - The image_prompt you crafted to generate the image\n","  * `model` - Add the LLM Model passed in as a parameter to `generate_ai_image` (`dall-e-3`)\n","  * `api_key` - Add the LLM API Key passed in as a parameter to `generate_ai_image`\n","* In the second code block, call the function and store the result in the variable `research_subject`."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1757715030944,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"},"user_tz":240},"id":"nRYQtg_fO-GD"},"outputs":[],"source":["# TODO: Run this codeblock\n","from litellm import image_generation\n","\n","def generate_ai_image(subject: str, llm_api_key: str, llm_model: str = \"dall-e-3\") -> str:\n","\n","    image_prompt = f\"A cute, natural image of {subject}.\"\n","\n","    response = image_generation(\n","        prompt=image_prompt,\n","        model=llm_model,\n","        api_key=llm_api_key\n","    )\n","\n","    return response"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":17193,"status":"ok","timestamp":1757715051536,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"},"user_tz":240},"id":"wwHsnzrwRnCb","outputId":"b816a716-dedd-448f-e924-c0cdb2e05e2c"},"outputs":[],"source":["# Run this codeblock\n","from IPython.display import Image, display\n","\n","\n","research_image = generate_ai_image(research_subject, LLM_API_KEY)\n","research_image_url = research_image[\"data\"][0][\"url\"]\n","\n","display(Image(url=research_image_url))"]},{"cell_type":"markdown","metadata":{"id":"yoMApjFcdT9O"},"source":["## Part 3 - Updating the workflow\n","\n","Now that you have an image, you can update the workflow to get the topic, make the LLM call, and generate the report.\n","\n","* Add a call to `llm_call` to get the topic of your prompt.\n","  * The `llm_call` function takes in your `resesearch_prompt`, `LLM_API_KEY`, and `LLM_MODEL`.\n","* Add a call to `generate_ai_image` to get an image for your research pdf.\n","  * The `generate_ai_image` function takes in your `research_topic` and `LLM_API_KEY`.\n","* Be sure to extract the appropriate data from the objects returned when calling `llm_call` and `generate_ai_image`\n","  * For `llm_call` it's `[\"choices\"][0][\"message\"][\"content\"]`\n","  * For `generate_ai_image` it's `[\"data\"][0][\"url\"]`\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40516,"status":"ok","timestamp":1757715100047,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"},"user_tz":240},"id":"QbxWbgrZdipe","outputId":"80b11f79-90fd-471a-b20e-52882496a52c"},"outputs":[],"source":["# Run this codeblock\n","try:\n","    # Make the API call\n","    print(\"Welcome to the Research Report Generator!\")\n","    research_prompt = input(\"Enter your research topic or question: \")\n","    result = llm_call(research_prompt, LLM_API_KEY, LLM_MODEL)\n","\n","    # Extract the response content\n","    response_content = result[\"choices\"][0][\"message\"][\"content\"]\n","\n","    subject_prompt = f\"What is the main topic of this sentence? Respond with only the topic in a single word or short phrase. No explanation. The sentence is: {research_prompt}\"\n","\n","    research_topic_llm_response = llm_call(subject_prompt, LLM_API_KEY, LLM_MODEL)\n","    research_topic = research_topic_llm_response[\"choices\"][0][\"message\"][\"content\"]\n","\n","    ai_image = generate_ai_image(research_topic, LLM_API_KEY)\n","    ai_image_url = ai_image[\"data\"][0][\"url\"]\n","\n","    pdf_filename = create_pdf(response_content, f\"{research_topic}.pdf\", ai_image_url)\n","    print(f\"SUCCESS! PDF created: {pdf_filename}\")\n","except Exception as e:\n","    print(f\"Error: {e}\")"]},{"cell_type":"markdown","metadata":{"id":"m9zU16kf5YzP"},"source":["### Download your image by following these steps:\n","  - Right-click the PDF file in the file explorer\n","  - Select \"Download\"\n","  - Open it locally on your machine\n","\n","Awesome, you're done with the exercise! But think of the things that could go wrong in this application. What if your image generation API went down? What if the PDF creation fails after you've already paid for the LLM call? How can we make this code more durable? \n","\n","We'll find out in the next notebook."]},{"cell_type":"markdown","metadata":{},"source":[" ## What's Next?\n","\n","This workshop introduced you the importance of durability in GenAI applications. Further your learning with these resources:\n","\n","### Resources\n","\n","- [A mental model for agentic AI Applications blogpost](https://temporal.io/blog/a-mental-model-for-agentic-ai-applications)\n","- [From AI hype to durable reality â€” why agentic flows need distributed-systems discipline blogpost](https://temporal.io/blog/from-ai-hype-to-durable-reality-why-agentic-flows-need-distributed-systems)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
