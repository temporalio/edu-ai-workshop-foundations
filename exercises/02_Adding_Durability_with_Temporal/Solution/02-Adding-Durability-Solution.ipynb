{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekQPgGVwQb1a"
   },
   "source": [
    "# Exercise #2 - Adding Durability Exercise [Solution]\n",
    "\n",
    "In the first notebook, you created a research workflow which currently performs research with an LLM and writes it to a PDF. To add a little more fun to your research paper, you used AI to generate an image of the research subject.\n",
    "\n",
    "Now, you're going to use Temporal to add durability to this code.\n",
    "\n",
    "In this exercise, you'll:\n",
    "\n",
    "- Transform your LLM calls and your execution of tools to Activities\n",
    "- Use a Temporal Workflow to orchestrate your Activities\n",
    "- Observe how Temporal handles your errors\n",
    "- Debug your error and observe your Workflow Execution successfully complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_uA13X5SYWe"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Before doing the exercise, you need to:\n",
    "\n",
    "- Create your `.env` file and supply your API key\n",
    "- Load the environment variables\n",
    "- Start the Temporal Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXp3VIAdZuhO"
   },
   "source": [
    "### Make Sure Your `.env` File Exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tSl-K8ATXLJ3"
   },
   "outputs": [],
   "source": [
    "# Check if .env file exists at the root of `exercises` directory, if not create one:\n",
    "import os   \n",
    "env_path = \"../../.env\" \n",
    "\n",
    "if not os.path.exists(env_path):   \n",
    "  with open(env_path, \"w\") as fh:\n",
    "    fh.write(\"LLM_API_KEY = YOUR_API_KEY\\nLLM_MODEL = openai/gpt-4o\")\n",
    "\n",
    "# If you just created a new .env file, open the .env file at the root of `exercises` and replace YOUR_API_KEY with your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1757727435260,
     "user": {
      "displayName": "Angela Zhou",
      "userId": "04211316506850475003"
     },
     "user_tz": 240
    },
    "id": "fy4s0KTRdWxL",
    "outputId": "a68d8068-e0ed-4278-8cfd-1a5f05ca9b0b"
   },
   "outputs": [],
   "source": [
    "# Load environment variables and configure LLM settings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Get LLM_API_KEY environment variable and print it to make sure that your .env file is properly loaded.\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"openai/gpt-4o\")\n",
    "LLM_API_KEY = os.getenv(\"LLM_API_KEY\", None)\n",
    "print(\"API Key: \", LLM_API_KEY)\n",
    "# If your LLM_API_Key is empty, go to the .env file at the root of your `exercises` directory \n",
    "# and replace YOUR_API_KEY with your API key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Sure Your Temporal Web UI is Running\n",
    "\n",
    "1. You should have the Temporal Server running in your terminal (run `temporal server start-dev` if not).\n",
    "2. Then in your `Ports` tab on the bottom of this screen, find `8233` and click on the Globe icon to open the Temporal Web UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iw22wN9wX1Ok"
   },
   "source": [
    "### Optional: Part 1 - Review Your First Workflow\n",
    "\n",
    "**Part 1 is a review of what you just practiced in the workshop. Feel free to skip it if you feel comfortable with the material.**\n",
    "\n",
    "In the content notebook, you defined the Models, Activities, and Workflows. Fill in the missing parts, then run the code below again, and to get practice running a Temporal Workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSWFzYyb2UBJ"
   },
   "source": [
    "### Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pMHdjdjL2FlT"
   },
   "outputs": [],
   "source": [
    "# TODO: Run this code to load it into the program\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class LLMCallInput:\n",
    "  prompt: str\n",
    "  \n",
    "@dataclass\n",
    "class PDFGenerationInput:\n",
    "  content: str\n",
    "  image_url: str | None = None\n",
    "  filename: str = \"research_pdf\"\n",
    "\n",
    "@dataclass\n",
    "class GenerateReportInput:\n",
    "    prompt: str\n",
    "\n",
    "@dataclass\n",
    "class GenerateReportOutput:\n",
    "    result: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ys60mB8o2Vib"
   },
   "source": [
    "### Activities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2FEDm6EiYKB2"
   },
   "outputs": [],
   "source": [
    "# TODO: Run this code to load it into the program\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from litellm import completion, ModelResponse\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image as RLImage\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "\n",
    "from temporalio import activity\n",
    "\n",
    "@activity.defn\n",
    "def llm_call(input: LLMCallInput) -> ModelResponse:\n",
    "    response = completion(\n",
    "      model=LLM_MODEL,\n",
    "      api_key=LLM_API_KEY,\n",
    "      messages=[{ \"content\": input.prompt,\"role\": \"user\"}]\n",
    "    )\n",
    "    return response\n",
    "\n",
    "@activity.defn\n",
    "def create_pdf(input: PDFGenerationInput) -> str:\n",
    "    doc = SimpleDocTemplate(f\"{input.filename}.pdf\", pagesize=letter)\n",
    "\n",
    "    styles = getSampleStyleSheet()\n",
    "    title_style = ParagraphStyle(\n",
    "        'CustomTitle',\n",
    "        parent=styles['Heading1'],\n",
    "        fontSize=24,\n",
    "        spaceAfter=30,\n",
    "        alignment=1\n",
    "    )\n",
    "\n",
    "    story = []\n",
    "    title = Paragraph(\"Research Report\", title_style)\n",
    "    story.append(title)\n",
    "    story.append(Spacer(1, 20))\n",
    "\n",
    "    if input.image_url is not None:\n",
    "      img_response = requests.get(input.image_url)\n",
    "      img_buffer = BytesIO(img_response.content)\n",
    "      img = RLImage(img_buffer, width=5*inch, height=5*inch)\n",
    "      story.append(img)\n",
    "      story.append(Spacer(1, 20))\n",
    "\n",
    "    paragraphs = input.content.split('\\n\\n')\n",
    "    for para in paragraphs:\n",
    "        if para.strip():\n",
    "            p = Paragraph(para.strip(), styles['Normal'])\n",
    "            story.append(p)\n",
    "            story.append(Spacer(1, 12))\n",
    "\n",
    "    doc.build(story)\n",
    "    return input.filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uS8SgW472Xto"
   },
   "source": [
    "### Workflow\n",
    "\n",
    "A Workflow coordinates the execution of your Activities.\n",
    "\n",
    "1. In the first `execute_activity` call, call your `llm_call` Activity.\n",
    "2. In the second `execute_activity` call where you call `create_pdf`, set your Start-to-Close Timeout to be 10 seconds. This is the maximum time allowed for a single attempt of an Activity to execute.\n",
    "3. Run this code block to load it into the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUuRKXiXYNey"
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from datetime import timedelta\n",
    "\n",
    "from temporalio import workflow\n",
    "\n",
    "# sandboxed=False is a Notebook only requirement. You normally don't do this\n",
    "@workflow.defn(sandboxed=False)\n",
    "class GenerateReportWorkflow:\n",
    "\n",
    "    @workflow.run\n",
    "    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n",
    "\n",
    "        llm_call_input = LLMCallInput(prompt=input.prompt)\n",
    "\n",
    "        research_facts = await workflow.execute_activity(\n",
    "            llm_call,\n",
    "            llm_call_input,\n",
    "            start_to_close_timeout=timedelta(seconds=30),\n",
    "        )\n",
    "\n",
    "        workflow.logger.info(\"Research complete!\")\n",
    "\n",
    "        pdf_generation_input = PDFGenerationInput(content=research_facts[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "        pdf_filename = await workflow.execute_activity(\n",
    "            create_pdf,\n",
    "            pdf_generation_input,\n",
    "            start_to_close_timeout=timedelta(seconds=10),\n",
    "        )\n",
    "\n",
    "        return GenerateReportOutput(result=f\"Successfully created research report PDF: {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlbhDExL4C1n"
   },
   "source": [
    "### Worker\n",
    "\n",
    "Workers wait for tasks to do, such as an Activity or Workflow Task, and execute them.\n",
    "\n",
    "Workers have Workflows and Activities registered to them so the Worker knows what to execute. \n",
    "1. Pass in your `llm_call` and `create_pdf` Activities into the list so that they are registered to the Worker.\n",
    "2. Run this code block to load it into the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MRaj3kXa4Bpt"
   },
   "outputs": [],
   "source": [
    "from temporalio.client import Client\n",
    "from temporalio.worker import Worker\n",
    "import concurrent.futures\n",
    "\n",
    "async def run_worker() -> None:\n",
    "\n",
    "    # Create client connected to server at the given address\n",
    "    client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "    # Run the Worker\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as activity_executor:\n",
    "        worker = Worker(\n",
    "            client,\n",
    "            task_queue=\"research\", # the task queue the Worker is polling\n",
    "            workflows=[GenerateReportWorkflow], # register the Workflow\n",
    "            activities=[llm_call, create_pdf], # register the Activities\n",
    "            activity_executor=activity_executor\n",
    "        )\n",
    "\n",
    "        print(f\"Starting the worker....\")\n",
    "        await worker.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzJrRRh_IrhO"
   },
   "outputs": [],
   "source": [
    "# Start a new worker\n",
    "import asyncio\n",
    "\n",
    "worker = asyncio.create_task(run_worker())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlSHFgmG70f-"
   },
   "source": [
    "### Client\n",
    "\n",
    "You request execution of your Workflow by using a Temporal Client.\n",
    "\n",
    "1. In the Client that you specfiy your Workflow to run, the data, you need to specify a Task Queue. This Task Queue must exactly match the Task Queue specified in the Worker.\n",
    "2. Run this code to load it into the program.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7586,
     "status": "ok",
     "timestamp": 1757727517843,
     "user": {
      "displayName": "Angela Zhou",
      "userId": "04211316506850475003"
     },
     "user_tz": 240
    },
    "id": "cJMyyRU97oTj",
    "outputId": "9d21e45f-4ecf-4a42-f27e-2d6cb53bf253"
   },
   "outputs": [],
   "source": [
    "from temporalio.client import Client\n",
    "import uuid\n",
    "\n",
    "# Create client connected to server at the given address\n",
    "client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "print(\"Welcome to the Research Report Generator!\")\n",
    "prompt = input(\"Enter your research topic or question: \").strip()\n",
    "\n",
    "if not prompt:\n",
    "    prompt = \"Give me 5 fun and fascinating facts about tardigrades. Make them interesting and educational!\"\n",
    "    print(f\"No prompt entered. Using default: {prompt}\")\n",
    "\n",
    "# Asynchronous start of a Workflow\n",
    "handle = await client.start_workflow(\n",
    "    GenerateReportWorkflow,\n",
    "    GenerateReportInput(prompt=prompt),\n",
    "    id=f\"generate-research-report-workflow-{uuid.uuid4()}\", # user-defined Workflow identifier, which typically has some business meaning\n",
    "    task_queue=\"research\",  # the task-queue that your Worker is polling\n",
    ")\n",
    "\n",
    "print(f\"Started workflow. Workflow ID: {handle.id}, RunID {handle.result_run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTY339F9EuhQ"
   },
   "source": [
    "### Review the Workflow Execution in the Web UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To run the Temporal Server in this exercise environment**:\n",
    "1. You should have the Temporal Server running in your terminal (run `temporal server start-dev` if not).\n",
    "2. Then in your `Ports` tab on the bottom of this screen, find `8233` and click on the Globe icon to open the Temporal Web UI.\n",
    "\n",
    "**Refresh your Web UI.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to kill the current Worker\n",
    "x = worker.cancel()\n",
    "\n",
    "if x:\n",
    "  print(\"Worker killed\")\n",
    "else:\n",
    "  print(\"Worker was not running. Nothing to kill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BE_tNaFU_dP"
   },
   "source": [
    "### Part 2 - Getting the Subject from Our Past Prompt by Calling an Activity\n",
    "\n",
    "In this exercise you'll:\n",
    "\n",
    "- Add a call to the `llm_call` Activity in the Workflow\n",
    "- Modify the subsequent Activity call to pass the topic to the `create_pdf` Activity\n",
    "- Start the Worker\n",
    "- Run the Workflow and see it perform a research task, and create a file where the name of the file is the topic of the research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orchestrate your Activities\n",
    "\n",
    "1. In your Workflow, call the `llm_call` Activity as the first executed Activity.\n",
    "2. When you execute your `llm_call` Activity, pass in the `subject_input` as a parameter.\n",
    "3. When you execute your `llm_call` Activity, set your Start-to-Close Timeout to be 30 seconds.\n",
    "4. In your Workflow, call your `create_pdf` with inputs of `pdf_generation_input` and `Start-to-Close Timeout` of 10 seconds\n",
    "5. Run the code block to load it into the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pOlBt5yd5W36"
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from datetime import timedelta\n",
    "\n",
    "from temporalio import workflow\n",
    "\n",
    "# sandboxed=False is a Notebook only requirement. You normally don't do this\n",
    "@workflow.defn(sandboxed=False)\n",
    "class GenerateReportWorkflow:\n",
    "\n",
    "    @workflow.run\n",
    "    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n",
    "\n",
    "        research_input = LLMCallInput(prompt=input.prompt)\n",
    "\n",
    "        research_facts = await workflow.execute_activity(\n",
    "            llm_call,\n",
    "            research_input,\n",
    "            start_to_close_timeout=timedelta(seconds=30), # maximum duration for the LLM call to complete\n",
    "        )\n",
    "\n",
    "        workflow.logger.info(\"Research complete!\")\n",
    "\n",
    "        # Added the subject prompt\n",
    "        subject_prompt = f\"What is the main topic of this sentence? Respond with only the topic in a single word or short phrase. No explanation. The sentence is: {input.prompt}\"\n",
    "\n",
    "        # Created an object to pass to the Activity\n",
    "        subject_input = LLMCallInput(prompt=subject_prompt)\n",
    "\n",
    "        # Called the llm_call Activity again with a new prompt\n",
    "        topic_call = await workflow.execute_activity(\n",
    "            llm_call,\n",
    "            subject_input,\n",
    "            start_to_close_timeout=timedelta(seconds=30),\n",
    "        )\n",
    "\n",
    "        # Extracted the topic from the response\n",
    "        topic = topic_call[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        # Passed in the topic as the filename so it can be used to name the file\n",
    "        pdf_generation_input = PDFGenerationInput(content=research_facts[\"choices\"][0][\"message\"][\"content\"], filename=topic)\n",
    "\n",
    "        pdf_filename = await workflow.execute_activity(\n",
    "            create_pdf,\n",
    "            pdf_generation_input,\n",
    "            start_to_close_timeout=timedelta(seconds=10),\n",
    "        )\n",
    "\n",
    "        return GenerateReportOutput(result=f\"Successfully created research report PDF: {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRFAWSBa4QZd"
   },
   "outputs": [],
   "source": [
    "# Kill any previous workers that may still be running\n",
    "x = worker.cancel()\n",
    "\n",
    "# Start a new worker\n",
    "worker = asyncio.create_task(run_worker())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4792,
     "status": "ok",
     "timestamp": 1757727599919,
     "user": {
      "displayName": "Angela Zhou",
      "userId": "04211316506850475003"
     },
     "user_tz": 240
    },
    "id": "kgtTTapM6CNy",
    "outputId": "86a1a9b5-3269-4f31-a96e-f2367a6f5768"
   },
   "outputs": [],
   "source": [
    "# Execute your Workflow\n",
    "import uuid\n",
    "\n",
    "client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "print(\"Welcome to the Research Report Generator!\")\n",
    "prompt = input(\"Enter your research topic or question: \").strip()\n",
    "\n",
    "if not prompt:\n",
    "    prompt = \"Give me 5 fun and fascinating facts about tardigrades. Make them interesting and educational!\"\n",
    "    print(f\"No prompt entered. Using default: {prompt}\")\n",
    "\n",
    "# Asynchronous start of a Workflow\n",
    "handle = await client.start_workflow(\n",
    "    GenerateReportWorkflow,\n",
    "    GenerateReportInput(prompt=prompt),\n",
    "    id=f\"generate-research-report-workflow-{uuid.uuid4()}\",\n",
    "    task_queue=\"research\",\n",
    ")\n",
    "\n",
    "print(f\"Started workflow. Workflow ID: {handle.id}, RunID {handle.result_run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaIYuART6KKY"
   },
   "source": [
    "### Watch the Execuction in the Web UI\n",
    "\n",
    "Refresh the Web UI and watch the execution. Find the following items in the Web UI:\n",
    "\n",
    "- What was the output of the `llm_call` Activity?\n",
    "- What was the output of the `create_pdf` Activity?\n",
    "- What was the output of the Workflow Execution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNrBOqdISGll"
   },
   "source": [
    "### Part 3 - Convert the Image Creation Function to an Activity and Recover from an Error\n",
    "\n",
    "In the first exercise, you called a function to create an image of the topic of the prompt. In this exercise you'll:\n",
    "\n",
    "- Update this function to be an Activity\n",
    "- Register the Activity with the Worker\n",
    "- Call the Activity from within the Workflow\n",
    "- Test your Workflow\n",
    "- Observe your retry policy in your Activity\n",
    "- Fix your error and watch your Workflow successfully complete.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85kUXKuDGbWl"
   },
   "outputs": [],
   "source": [
    "# Add a new model for Activity input\n",
    "# Run this code block to load it into the program.\n",
    "@dataclass\n",
    "class GenerateImageInput:\n",
    "    topic: str\n",
    "    llm_model: str = \"dall-e-3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRYQtg_fO-GD"
   },
   "outputs": [],
   "source": [
    "# Step 1: Add the @activity.defn decorator\n",
    "# Step 2: Run the codeblock to load it into the program.\n",
    "from litellm import image_generation\n",
    "from temporalio import activity\n",
    "\n",
    "@activity.defn\n",
    "def generate_ai_image(input: GenerateImageInput) -> ModelResponse:\n",
    "\n",
    "    image_prompt = f\"A cute, natural image of {input.topic}.\"\n",
    "\n",
    "    response = image_generation(\n",
    "        prompt=image_prompt,\n",
    "        api_key=LLM_API_KEY\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CVHUEi9kGuIS"
   },
   "outputs": [],
   "source": [
    "# Step 1: Decorate your `run` method with `@workflow.run`\n",
    "# Step 2: Call your `generate_ai_image` from your Workflow.\n",
    "# Step 3: Pass in your `image_input` into the `execute_activity` call for when you are calling `generate_ai_image`\n",
    "# Step 4: Set the Start-to-Close Timeout to 1 second. \n",
    "# Remember, A Start-to-Close timeout is the maximum amount of time a single Activity Execution can take. \n",
    "# We recommend always setting this timeout.\n",
    "# Step 5: Run the code block to load it into the program.\n",
    "import asyncio\n",
    "from datetime import timedelta\n",
    "\n",
    "from temporalio import workflow\n",
    "\n",
    "# sandboxed=False is a Notebook only requirement. You normally don't do this\n",
    "@workflow.defn(sandboxed=False)\n",
    "class GenerateReportWorkflow:\n",
    "\n",
    "    @workflow.run\n",
    "    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n",
    "\n",
    "        research_input = LLMCallInput(prompt=input.prompt)\n",
    "\n",
    "        research_facts = await workflow.execute_activity(\n",
    "            llm_call,\n",
    "            research_input,\n",
    "            start_to_close_timeout=timedelta(seconds=30),\n",
    "        )\n",
    "\n",
    "        workflow.logger.info(\"Research complete!\")\n",
    "\n",
    "        subject_prompt = f\"What is the main topic of this sentence? Respond with only the topic in a single word or short phrase. No explanation. The sentence is: {input.prompt}\"\n",
    "        subject_input = LLMCallInput(prompt=subject_prompt)\n",
    "\n",
    "        topic_call = await workflow.execute_activity(\n",
    "            llm_call,\n",
    "            subject_input,\n",
    "            start_to_close_timeout=timedelta(seconds=30),\n",
    "        )\n",
    "\n",
    "        topic = topic_call[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        # Used the new GenerateImageInput dataclass to create the input object for the Activity\n",
    "        image_input = GenerateImageInput(topic=topic)\n",
    "\n",
    "        # Called the new generate_ai_image Activity, passing in the image_input parameter made above\n",
    "        ai_image = await workflow.execute_activity(\n",
    "            generate_ai_image,\n",
    "            image_input,\n",
    "            start_to_close_timeout=timedelta(seconds=1),\n",
    "        )\n",
    "\n",
    "        # Extract the image_url form the Activity call\n",
    "        image_url = ai_image[\"data\"][0][\"url\"]\n",
    "\n",
    "        # Add the image_url parameter to the PDF Generation so the image is included\n",
    "        pdf_generation_input = PDFGenerationInput(content=research_facts[\"choices\"][0][\"message\"][\"content\"], image_url=image_url, filename=topic)\n",
    "\n",
    "        pdf_filename = await workflow.execute_activity(\n",
    "            create_pdf,\n",
    "            pdf_generation_input,\n",
    "            start_to_close_timeout=timedelta(seconds=10),\n",
    "        )\n",
    "\n",
    "        return GenerateReportOutput(result=f\"Successfully created research report PDF: {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRD_jfd8HtUS"
   },
   "source": [
    "### Register the Activity with the Worker\n",
    "\n",
    "Don't forget, you have to register your code with the Worker for it to be executed!\n",
    "1. Register your GenerateReportWorkflow\n",
    "2. Register your `llm_call`, `create_pdf`, `generate_ai_image` Activities\n",
    "3. Run the code block to load it into the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ujj6pAGoHsoz"
   },
   "outputs": [],
   "source": [
    "from temporalio.client import Client\n",
    "from temporalio.worker import Worker\n",
    "import concurrent.futures\n",
    "\n",
    "async def run_worker() -> None:\n",
    "\n",
    "    client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "    # Run the Worker\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as activity_executor:\n",
    "        worker = Worker(\n",
    "            client,\n",
    "            task_queue=\"research\",\n",
    "            workflows=[GenerateReportWorkflow],\n",
    "            # Registered the new Activity here\n",
    "            activities=[llm_call, create_pdf, generate_ai_image],\n",
    "            activity_executor=activity_executor\n",
    "        )\n",
    "\n",
    "        print(f\"Starting the worker....\")\n",
    "        await worker.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBAre4bDHVw7"
   },
   "outputs": [],
   "source": [
    "# Kill any previous workers that may still be running\n",
    "x = worker.cancel()\n",
    "\n",
    "# Start a new worker\n",
    "worker = asyncio.create_task(run_worker())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4811,
     "status": "ok",
     "timestamp": 1757727773438,
     "user": {
      "displayName": "Angela Zhou",
      "userId": "04211316506850475003"
     },
     "user_tz": 240
    },
    "id": "ySug_ag_HR-H",
    "outputId": "251b2695-b300-4a33-815e-d1235457ace3"
   },
   "outputs": [],
   "source": [
    "# Run the Workflow\n",
    "import uuid\n",
    "\n",
    "client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "print(\"Welcome to the Research Report Generator!\")\n",
    "prompt = input(\"Enter your research topic or question: \").strip()\n",
    "\n",
    "if not prompt:\n",
    "    prompt = \"Give me 5 fun and fascinating facts about tardigrades. Make them interesting and educational!\"\n",
    "    print(f\"No prompt entered. Using default: {prompt}\")\n",
    "\n",
    "# Asynchronous start of a Workflow\n",
    "handle = await client.start_workflow(\n",
    "    GenerateReportWorkflow,\n",
    "    GenerateReportInput(prompt=prompt),\n",
    "    id=f\"generate-research-report-workflow-{uuid.uuid4()}\",\n",
    "    task_queue=\"research\",\n",
    ")\n",
    "\n",
    "print(f\"Started workflow. Workflow ID: {handle.id}, RunID {handle.result_run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Refresh your Web UI**.\n",
    "\n",
    "1. You should have the Temporal Server running in your terminal (run `temporal server start-dev` if not).\n",
    "2. Then in your `Ports` tab on the bottom of this screen, find `8233` and click on the Globe icon to open the Temporal Web UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOtw63BuPpI9"
   },
   "source": [
    "### Observing Retries\n",
    "\n",
    "You should see that the `generate_ai_image` Activity is retrying over and over. Why do you think that is?\n",
    "\n",
    "Find the answers to these by expanding the `Pending Activity` in your Event History.\n",
    "- What is the message in the Pending Activity?\n",
    "- What retry attempt is it on?\n",
    "- How many seconds until the next retry attempt?\n",
    "\n",
    "It's because the image generation takes longer than the one second that you set the Start-to-Close Timeout to be! Let's increase the timeout to a reasonable value (e.g. 30 seconds).\n",
    "\n",
    "Let's terminate the workflow and test with an increased timeout.\n",
    "1. Click the dropdown on the top right of your screen where it says “Request Cancellation”. Then select “Terminate”. \n",
    "2. Enter \"Bad timeout\" as the termination reason.\n",
    "\n",
    "<img src=\"https://i.postimg.cc/KvHCJMdq/bad-timeout.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSFNObu9QCrW"
   },
   "outputs": [],
   "source": [
    "# Step 1: Increase your Start-to-Close Timeout to be a reasonable value (e.g. 30 seconds)\n",
    "# Step 2: Run this code block.\n",
    "import asyncio\n",
    "from datetime import timedelta\n",
    "\n",
    "from temporalio import workflow\n",
    "\n",
    "# sandboxed=False is a Notebook only requirement. You normally don't do this\n",
    "@workflow.defn(sandboxed=False)\n",
    "class GenerateReportWorkflow:\n",
    "\n",
    "    @workflow.run\n",
    "    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n",
    "\n",
    "        research_input = LLMCallInput(prompt=input.prompt)\n",
    "\n",
    "        research_facts = await workflow.execute_activity(\n",
    "            llm_call,\n",
    "            research_input,\n",
    "            start_to_close_timeout=timedelta(seconds=30),\n",
    "        )\n",
    "\n",
    "        workflow.logger.info(\"Research complete!\")\n",
    "\n",
    "        subject_prompt = f\"What is the main topic of this sentence? Respond with only the topic in a single word or short phrase. No explanation. The sentence is: {input.prompt}\"\n",
    "        subject_input = LLMCallInput(prompt=subject_prompt)\n",
    "\n",
    "        topic_call = await workflow.execute_activity(\n",
    "            llm_call,\n",
    "            subject_input,\n",
    "            start_to_close_timeout=timedelta(seconds=30),\n",
    "        )\n",
    "\n",
    "        topic = topic_call[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        # Used the new GenerateImageInput dataclass to create the input object for the Activity\n",
    "        image_input = GenerateImageInput(topic=topic)\n",
    "\n",
    "        # Called the new generate_ai_image Activity, passing in the image_input parameter made above\n",
    "        ai_image = await workflow.execute_activity(\n",
    "            generate_ai_image,\n",
    "            image_input,\n",
    "            start_to_close_timeout=timedelta(seconds=30),\n",
    "        )\n",
    "\n",
    "        # Extract the image_url form the Activity call\n",
    "        image_url = ai_image[\"data\"][0][\"url\"]\n",
    "\n",
    "        # Add the image_url parameter to the PDF Generation so the image is included\n",
    "        pdf_generation_input = PDFGenerationInput(content=research_facts[\"choices\"][0][\"message\"][\"content\"], image_url=image_url, filename=topic)\n",
    "\n",
    "        pdf_filename = await workflow.execute_activity(\n",
    "            create_pdf,\n",
    "            pdf_generation_input,\n",
    "            start_to_close_timeout=timedelta(seconds=10),\n",
    "        )\n",
    "\n",
    "        return GenerateReportOutput(result=f\"Successfully created research report PDF: {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4m5KPfDWQJPo"
   },
   "outputs": [],
   "source": [
    "# Kill any previous workers that may still be running\n",
    "x = worker.cancel()\n",
    "\n",
    "# Start a new worker\n",
    "worker = asyncio.create_task(run_worker())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this codeblock\n",
    "import uuid\n",
    "\n",
    "client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "print(\"Welcome to the Research Report Generator!\")\n",
    "prompt = input(\"Enter your research topic or question: \").strip()\n",
    "\n",
    "if not prompt:\n",
    "    prompt = \"Give me 5 fun and fascinating facts about tardigrades. Make them interesting and educational!\"\n",
    "    print(f\"No prompt entered. Using default: {prompt}\")\n",
    "\n",
    "# Asynchronous start of a Workflow\n",
    "handle = await client.start_workflow(\n",
    "    GenerateReportWorkflow,\n",
    "    GenerateReportInput(prompt=prompt),\n",
    "    id=f\"generate-research-report-workflow-{uuid.uuid4()}\",\n",
    "    task_queue=\"research\",\n",
    ")\n",
    "\n",
    "print(f\"Started workflow. Workflow ID: {handle.id}, RunID {handle.result_run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZDJD8CuQU7w"
   },
   "source": [
    "### Observing Workflow Completion\n",
    "\n",
    "Go back to your Web UI, and we’ll now see that the Workflow Execution completes successfully! Temporal preserved its Workflow state through failures and replayed with our updated code, continuing exactly where we left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kill any worker to prepare for the next chapter.\n",
    "x = worker.cancel()\n",
    "\n",
    "if x:\n",
    "  print(\"Worker killed\")\n",
    "else:\n",
    "  print(\"Worker was not running. Nothing to kill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Next?\n",
    "\n",
    "This workshop introduced you to the **concept** of Temporal. Further your learning with these resources:\n",
    "\n",
    "### Resources\n",
    "\n",
    "- Our free [Temporal 102 Course](https://learn.temporal.io/courses/temporal_102/python/) which covers these concepts (Workflows, Activities, Replay, and more) in more detail\n",
    "- A Temporal [tutorial in the Python SDK](https://learn.temporal.io/getting_started/python/hello_world_in_python/) that showcases how to get started with Temporal\n",
    "- Our [docs page](https://docs.temporal.io/encyclopedia/event-history/event-history-python#How-History-Replay-Provides-Durable-Execution) describing how Temporal uses Replay to provide durable execution in more detail"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "history_visible": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
